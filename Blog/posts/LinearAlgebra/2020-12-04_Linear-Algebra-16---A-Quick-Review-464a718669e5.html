<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Linear Algebra 16 | A Quick Review</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Linear Algebra 16 | A Quick Review</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Linear Algebra
</section>
<section data-field="body" class="e-content">
<section name="3b1b" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="38c2" id="38c2" class="graf graf--h3 graf--leading graf--title">Linear Algebra 16 | A Quick Review</h3><figure name="e2bb" id="e2bb" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*Yj4DEKztkbPyDrnciYX9dQ.jpeg" data-width="1955" data-height="1296" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*Yj4DEKztkbPyDrnciYX9dQ.jpeg"></figure><ol class="postList"><li name="1523" id="1523" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Vectors</strong></li></ol><p name="9142" id="9142" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Definitions, stacking, slicing</strong></p><ul class="postList"><li name="69dd" id="69dd" class="graf graf--li graf-after--p">Defintion: a vector is an ordered list of numbers</li><li name="7ef9" id="7ef9" class="graf graf--li graf-after--li">Stacked vector (concatenation): A stack vector of b, c, and d is <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">a</em></strong>= [b, c, d]</li><li name="4dfd" id="4dfd" class="graf graf--li graf-after--li">Size: the size of a vector is the number of entities in the vector</li><li name="8209" id="8209" class="graf graf--li graf-after--li">Zeros: the zeros vector is the entities</li><li name="efe1" id="efe1" class="graf graf--li graf-after--li">Ones: the ones vector is the entities</li><li name="f04f" id="f04f" class="graf graf--li graf-after--li">Unit Vector: has one entry 1 and all others 0</li><li name="22f4" id="22f4" class="graf graf--li graf-after--li">Sparsity: a vector is sparse if many of its entries are 0, nnz(<strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">x</em></strong>) is the number of entities that are non-zero</li></ul><p name="41af" id="41af" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Addition/subtraction, scalar multiplication</strong></p><ul class="postList"><li name="815f" id="815f" class="graf graf--li graf-after--p">commutative: a+b = b+a</li><li name="6447" id="6447" class="graf graf--li graf-after--li">associative: (a+b)+c = a+(b+c)</li><li name="9fd8" id="9fd8" class="graf graf--li graf-after--li">zero: a+0=0+a=a</li><li name="b43f" id="b43f" class="graf graf--li graf-after--li">self substraction: a−a=0</li><li name="ba1b" id="ba1b" class="graf graf--li graf-after--li">multiplication: βa = (βa1,…,βan)</li><li name="6633" id="6633" class="graf graf--li graf-after--li">associative: (βγ)a = β(γa)</li><li name="503e" id="503e" class="graf graf--li graf-after--li">left distributive: (β + γ)a = βa + γa</li><li name="4ab4" id="4ab4" class="graf graf--li graf-after--li">right distributive: β(a + b) = βa + βb</li></ul><p name="3848" id="3848" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Inner product, norm, distance, RMS value</strong></p><ul class="postList"><li name="9d30" id="9d30" class="graf graf--li graf-after--p">inner product (or dot product) of n-vectors a and b is: aTb=a1b1 +a2b2 +···+anbn (a value)</li><li name="6d86" id="6d86" class="graf graf--li graf-after--li">aTa=a1² +a2² +···+an² ≥0</li><li name="031e" id="031e" class="graf graf--li graf-after--li">aTa=0 if and only if a=0</li><li name="b090" id="b090" class="graf graf--li graf-after--li">commutative: aTb = bTa</li><li name="97a3" id="97a3" class="graf graf--li graf-after--li">associative with scalar multiplication: (γa)T b = γ(aT b)</li><li name="84a5" id="84a5" class="graf graf--li graf-after--li">distributive with vector addition: (a + b)Tc = aTc + bTc</li><li name="8e1b" id="8e1b" class="graf graf--li graf-after--li">bombination conclusion: (a + b)T(c + d) = aTc + aTd + bTc + bTd</li><li name="b65f" id="b65f" class="graf graf--li graf-after--li">Euclidean norm (norm): used to measure the size or magnitude of a vector</li></ul><figure name="4d14" id="4d14" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*wTSXAM965y-4Uq-btufUlA.png" data-width="962" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*wTSXAM965y-4Uq-btufUlA.png"></figure><ul class="postList"><li name="c938" id="c938" class="graf graf--li graf-after--figure">Norm homogeneity: ∥βx∥ = |β|∥x∥</li><li name="55ac" id="55ac" class="graf graf--li graf-after--li">Norm triangle inequality: ∥x + y∥ ≤ ∥x∥ + ∥y∥</li><li name="35ac" id="35ac" class="graf graf--li graf-after--li">Norm nonnegativity:∥x∥ ≥ 0</li><li name="d5e3" id="d5e3" class="graf graf--li graf-after--li">Norm definiteness: ∥x∥ = 0 only if x = 0</li><li name="0438" id="0438" class="graf graf--li graf-after--li">RMS value: mean-square value of n-vector</li></ul><figure name="c44f" id="c44f" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*Q7r1f8KbBhe04Phd9ZyMLA.png" data-width="962" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*Q7r1f8KbBhe04Phd9ZyMLA.png"></figure><ul class="postList"><li name="d7b7" id="d7b7" class="graf graf--li graf-after--figure">root-mean-square value (RMS value) is</li></ul><figure name="6d22" id="6d22" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*NDuIVo7OSdsYVrt5lyNC-Q.png" data-width="962" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*NDuIVo7OSdsYVrt5lyNC-Q.png"></figure><p name="0b5c" id="0b5c" class="graf graf--p graf-after--figure">Note that the RMS value is useful for comparing vectors of different dimensions</p><ul class="postList"><li name="fe9b" id="fe9b" class="graf graf--li graf-after--p">Norm of block vectors</li></ul><figure name="3496" id="3496" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*a8-PhlkEsZFDmwERFtp63g.png" data-width="962" data-height="140" src="https://cdn-images-1.medium.com/max/800/1*a8-PhlkEsZFDmwERFtp63g.png"></figure><ul class="postList"><li name="48c6" id="48c6" class="graf graf--li graf-after--figure">Euclidean distance</li></ul><figure name="4d99" id="4d99" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*HaK3xSAPjLqIO6oWyBwQyg.png" data-width="962" data-height="72" src="https://cdn-images-1.medium.com/max/800/1*HaK3xSAPjLqIO6oWyBwQyg.png"></figure><ul class="postList"><li name="43ac" id="43ac" class="graf graf--li graf-after--figure">RMS deviation: rms(a -b)</li></ul><p name="0bec" id="0bec" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Mean and standard deviation</strong></p><ul class="postList"><li name="4520" id="4520" class="graf graf--li graf-after--p">average definition vector form:</li></ul><figure name="f16b" id="f16b" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*pg7odXcSmwgng99TiCb4wg.png" data-width="264" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*pg7odXcSmwgng99TiCb4wg.png"></figure><ul class="postList"><li name="a2ef" id="a2ef" class="graf graf--li graf-after--figure">de-meaned vector:</li></ul><figure name="b9a9" id="b9a9" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*y2-hE6wOT-mZwmERHzrBjQ.png" data-width="534" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*y2-hE6wOT-mZwmERHzrBjQ.png"></figure><ul class="postList"><li name="bfbe" id="bfbe" class="graf graf--li graf-after--figure">standard deviation</li></ul><figure name="b07f" id="b07f" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*ubOCN95NNd0vhiJKM2_eug.png" data-width="1016" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*ubOCN95NNd0vhiJKM2_eug.png"></figure><ul class="postList"><li name="50e2" id="50e2" class="graf graf--li graf-after--figure">relationship between standard deviation, average, and rms</li></ul><figure name="d94e" id="d94e" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*umD7ekZiOU5x1_4aY5XCvQ.png" data-width="1016" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*umD7ekZiOU5x1_4aY5XCvQ.png"></figure><p name="0391" id="0391" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(5) Cauchy-Schwarz inequality, angle</strong></p><ul class="postList"><li name="b518" id="b518" class="graf graf--li graf-after--p">Cauchy-Schwarz inequality: can be used to prove the triangle inequality</li></ul><figure name="14ff" id="14ff" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*_CscdJoANnk3oV8V6VWwMA.png" data-width="596" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*_CscdJoANnk3oV8V6VWwMA.png"></figure><ul class="postList"><li name="f7d5" id="f7d5" class="graf graf--li graf-after--figure">angle between two nonzero vectors a, b defined as</li></ul><figure name="0f34" id="0f34" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*A0y6OR6fehExWGNwEQmvgA.png" data-width="850" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*A0y6OR6fehExWGNwEQmvgA.png"></figure><p name="6af2" id="6af2" class="graf graf--p graf-after--figure">This is also,</p><figure name="8091" id="8091" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*EQY1nhgrtL_fTP6I8M9BDA.png" data-width="850" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*EQY1nhgrtL_fTP6I8M9BDA.png"></figure><ul class="postList"><li name="5aff" id="5aff" class="graf graf--li graf-after--figure">orthogonal angle: θ = π/2 = 90°, aTb=0</li><li name="f309" id="f309" class="graf graf--li graf-after--li">aligned: θ = 0, aTb=∥a∥∥b∥</li><li name="6146" id="6146" class="graf graf--li graf-after--li">anti-aligned: θ = π = 180°, aT b = −∥a∥∥b∥</li><li name="5485" id="5485" class="graf graf--li graf-after--li">acute angle: θ ≤ π/2 = 90°, aTb≥0</li><li name="2691" id="2691" class="graf graf--li graf-after--li">obtuse angle: θ ≥ π/2 = 90°, aTb≤0</li></ul><p name="10ec" id="10ec" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(6) Correlation coefficient</strong></p><ul class="postList"><li name="caa5" id="caa5" class="graf graf--li graf-after--p">correlation coefficient (between a and b, with a ̃≠ 0,b ̃ ≠ 0)</li></ul><figure name="1c2f" id="1c2f" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*9n9_6Ioe4WzB40ay-iolcw.png" data-width="850" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*9n9_6Ioe4WzB40ay-iolcw.png"></figure><p name="15c0" id="15c0" class="graf graf--p graf-after--figure">Where,</p><figure name="e9cf" id="e9cf" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*G3_ug8kykdS0J-LMA0xKeg.png" data-width="968" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*G3_ug8kykdS0J-LMA0xKeg.png"></figure><p name="77c0" id="77c0" class="graf graf--p graf-after--figure">This is also,</p><figure name="7443" id="7443" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*eSOVJUXqTrVJbeOGW-p72Q.png" data-width="968" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*eSOVJUXqTrVJbeOGW-p72Q.png"></figure><p name="8cc3" id="8cc3" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">2. Linear Combinations</strong></p><p name="948d" id="948d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Linear combination of vectors</strong></p><p name="1cda" id="1cda" class="graf graf--p graf-after--p">For vectors a1,…,am and scalars β1,…,βm, then β1a1 +···+βmam is a linear combination of vectors.</p><p name="dfd5" id="dfd5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Linear dependence and independence</strong></p><p name="574b" id="574b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Independence-dimension inequality</strong></p><p name="6178" id="6178" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Basis</strong></p><p name="15a3" id="15a3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Orthonormal set of vectors</strong></p><p name="c1bd" id="c1bd" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Gram-Schmidt algorithm</strong></p><p name="cb68" id="cb68" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Matrices</strong></p><p name="ca78" id="ca78" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Definitions, notation, block matrices, submatrices</strong></p><ul class="postList"><li name="7e1a" id="7e1a" class="graf graf--li graf-after--p">Definitions: a matrix is a rectangular array of numbers</li><li name="944e" id="944e" class="graf graf--li graf-after--li">Size: (row dimension) × (column dimension)</li><li name="47c4" id="47c4" class="graf graf--li graf-after--li">Entry: elements also called entries or coefficients</li><li name="efa3" id="efa3" class="graf graf--li graf-after--li">Equality: two matrices are equal (denoted with “=”) if they are the same size and corresponding entries are equal</li><li name="ba70" id="ba70" class="graf graf--li graf-after--li">Tall matrix: if m &gt; n</li><li name="64a9" id="64a9" class="graf graf--li graf-after--li">Wide matrix: if m&lt;n</li><li name="4e87" id="4e87" class="graf graf--li graf-after--li">Square matrix: if m=n</li><li name="0b3e" id="0b3e" class="graf graf--li graf-after--li">Vector and matrix: we consider an n × 1 matrix to be an n-vector</li><li name="dc39" id="dc39" class="graf graf--li graf-after--li">Number and matrix: we consider a 1×1 matrix to be a number</li><li name="1f5c" id="1f5c" class="graf graf--li graf-after--li">Row vector: a 1 × n matrix is called a row vector</li><li name="3fb9" id="3fb9" class="graf graf--li graf-after--li">block matrices: whose entries are matrices, such as</li></ul><figure name="839c" id="839c" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*klG8oKtXkgDOGdXy3J00Yg.png" data-width="968" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*klG8oKtXkgDOGdXy3J00Yg.png"></figure><p name="d8a5" id="d8a5" class="graf graf--p graf-after--figure">where B, C, D, and E are matrices (called submatrices or blocks of A)</p><ul class="postList"><li name="4671" id="4671" class="graf graf--li graf-after--p">directed graph: a relation is a set of pairs of objects, labeled 1,…,n, such as</li></ul><figure name="b90b" id="b90b" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*GMtYNhj5oghed8nnU1OHyw.png" data-width="968" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*GMtYNhj5oghed8nnU1OHyw.png"></figure><figure name="fab5" id="fab5" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*HQEAosrBT2BVxtikzk8TYg.png" data-width="968" data-height="296" src="https://cdn-images-1.medium.com/max/800/1*HQEAosrBT2BVxtikzk8TYg.png"></figure><ul class="postList"><li name="804e" id="804e" class="graf graf--li graf-after--figure">n × n matrix A is adjacency matrix of directed graph:</li></ul><figure name="52d9" id="52d9" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*mrbSwM7Cdah4IoXG0KeAYQ.png" data-width="1150" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*mrbSwM7Cdah4IoXG0KeAYQ.png"></figure><ul class="postList"><li name="1e8f" id="1e8f" class="graf graf--li graf-after--figure">paths in directed graph: (A²)ij is number of paths of length 2 from j to i</li></ul><figure name="7aa8" id="7aa8" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*n-mc31YAe5IDezJSka8Hjw.png" data-width="1150" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*n-mc31YAe5IDezJSka8Hjw.png"></figure><ul class="postList"><li name="b4e6" id="b4e6" class="graf graf--li graf-after--figure">zero matrix: m × n zero matrix has all entries zero</li><li name="f689" id="f689" class="graf graf--li graf-after--li">identity matrix: is square matrix with Iii = 1 and Iij = 0 for i ≠ j</li></ul><figure name="0751" id="0751" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*b4lMtKYncRuZuWPF03zCfg.png" data-width="968" data-height="168" src="https://cdn-images-1.medium.com/max/800/1*b4lMtKYncRuZuWPF03zCfg.png"></figure><ul class="postList"><li name="9cb9" id="9cb9" class="graf graf--li graf-after--figure">sparse matrix: a matrix is sparse if most (almost all) of its entries are zer</li><li name="b957" id="b957" class="graf graf--li graf-after--li">diagonal matrix: square matrix with Aij = 0 when i ≠ j</li><li name="9d2c" id="9d2c" class="graf graf--li graf-after--li">lower triangular matrix: Aij = 0 for i &lt; j</li><li name="3138" id="3138" class="graf graf--li graf-after--li">upper triangular matrix: Aij = 0 for i &gt; j</li><li name="bcf7" id="bcf7" class="graf graf--li graf-after--li">transpose matrix: the transpose of an m × n matrix A is denoted AT , and defined by</li></ul><figure name="e626" id="e626" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*YgvXkYOcXZNmCloZKBYlgQ.png" data-width="968" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*YgvXkYOcXZNmCloZKBYlgQ.png"></figure><ul class="postList"><li name="a323" id="a323" class="graf graf--li graf-after--figure">Difference matrix: (n − 1) × n difference matrix is</li></ul><figure name="dc87" id="dc87" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*XtGIizN1wSe3HIMeigrM9Q.png" data-width="968" data-height="298" src="https://cdn-images-1.medium.com/max/800/1*XtGIizN1wSe3HIMeigrM9Q.png"></figure><ul class="postList"><li name="66c0" id="66c0" class="graf graf--li graf-after--figure">Dirichlet energy: ∥Dx∥² is a measure of wiggliness for x a time series</li></ul><p name="32fd" id="32fd" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Addition/subtraction, scalar multiplication</strong></p><ul class="postList"><li name="c071" id="c071" class="graf graf--li graf-after--p">we can add or subtract matrices of the same size:</li></ul><figure name="00e2" id="00e2" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*gEDG-VFVzc4Mr-LgMfdLcQ.png" data-width="968" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*gEDG-VFVzc4Mr-LgMfdLcQ.png"></figure><ul class="postList"><li name="12db" id="12db" class="graf graf--li graf-after--figure">scalar multiplication:</li></ul><figure name="1923" id="1923" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*JavU0CIeH9HwhpEMiLRmgw.png" data-width="968" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*JavU0CIeH9HwhpEMiLRmgw.png"></figure><ul class="postList"><li name="ed7e" id="ed7e" class="graf graf--li graf-after--figure">many obvious properties, e.g.,</li></ul><figure name="fe2e" id="fe2e" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*BG7CImhp00vPyysHikWDhg.png" data-width="968" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*BG7CImhp00vPyysHikWDhg.png"></figure><ul class="postList"><li name="97e7" id="97e7" class="graf graf--li graf-after--figure">matrix norm (Frobenius norm): for m×n matrix A, we define</li></ul><figure name="affb" id="affb" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*fwqerdYe9EFifIrx3jBmYA.png" data-width="968" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*fwqerdYe9EFifIrx3jBmYA.png"></figure><ul class="postList"><li name="1b95" id="1b95" class="graf graf--li graf-after--figure">Norm properties #1:∥αA∥ = |α|∥A∥</li><li name="34a5" id="34a5" class="graf graf--li graf-after--li">Norm properties #2:∥A + B∥ ≤ ∥A∥ + ∥B∥</li><li name="6870" id="6870" class="graf graf--li graf-after--li">Norm properties #3:∥A∥ ≥ 0</li><li name="d718" id="d718" class="graf graf--li graf-after--li">Norm properties #4:∥A∥=0 onlyif A=0</li><li name="0600" id="0600" class="graf graf--li graf-after--li">matrix distance:∥A − B∥</li></ul><p name="7ad7" id="7ad7" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Matrix-vector multiplication, linear equations</strong></p><ul class="postList"><li name="62d3" id="62d3" class="graf graf--li graf-after--p">matrix-vector product: m × n matrix A, n-vector x, denoted y = Ax, with</li></ul><figure name="a35c" id="a35c" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*m55PCOyJKmAg9TkJ9s90lw.png" data-width="968" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*m55PCOyJKmAg9TkJ9s90lw.png"></figure><ul class="postList"><li name="ca08" id="ca08" class="graf graf--li graf-after--figure">Row interpretation: y = Ax can be expressed as</li></ul><figure name="1234" id="1234" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*yHsEEUZzJB4ytbcgu9j4Lw.png" data-width="968" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*yHsEEUZzJB4ytbcgu9j4Lw.png"></figure><ul class="postList"><li name="8ec6" id="8ec6" class="graf graf--li graf-after--figure">Column interpretation: y = Ax can be expressed as</li></ul><figure name="c086" id="c086" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*vdh7rZxsY6Vfy9xWmqd7Iw.png" data-width="968" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*vdh7rZxsY6Vfy9xWmqd7Iw.png"></figure><p name="aeec" id="aeec" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Matrix multiplication</strong></p><ul class="postList"><li name="4c95" id="4c95" class="graf graf--li graf-after--p">Multiplication: can multiply m×p matrix A and p×n matrix B to get C=AB</li></ul><figure name="ea6c" id="ea6c" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*2xMP19zWO0V0kQ4_rLk0AQ.png" data-width="1074" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*2xMP19zWO0V0kQ4_rLk0AQ.png"></figure><ul class="postList"><li name="ce71" id="ce71" class="graf graf--li graf-after--figure">out product: of m-vector a and n-vector b</li></ul><figure name="23c4" id="23c4" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*xRMONwuFjfqbhloF8qd4fA.png" data-width="1074" data-height="204" src="https://cdn-images-1.medium.com/max/800/1*xRMONwuFjfqbhloF8qd4fA.png"></figure><ul class="postList"><li name="42b3" id="42b3" class="graf graf--li graf-after--figure">matrix multiplication property #1: (AB)C = A(BC)</li><li name="8e72" id="8e72" class="graf graf--li graf-after--li">matrix multiplication property #2:A(B+C)=AB+AC</li><li name="23f4" id="23f4" class="graf graf--li graf-after--li">matrix multiplication property #3:(AB)T =BTAT</li><li name="7d0b" id="7d0b" class="graf graf--li graf-after--li">matrix multiplication property #4:AI = A and IA = A</li><li name="fb39" id="fb39" class="graf graf--li graf-after--li">matrix multiplication property #5:AB ≠ BA in general</li><li name="5e0f" id="5e0f" class="graf graf--li graf-after--li">Block matrix multiplication:</li></ul><figure name="ca55" id="ca55" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*sToXZBziP9Sm2S7MMlNRhQ.png" data-width="1074" data-height="96" src="https://cdn-images-1.medium.com/max/800/1*sToXZBziP9Sm2S7MMlNRhQ.png"></figure><ul class="postList"><li name="2ab1" id="2ab1" class="graf graf--li graf-after--figure">Inner Product</li></ul><figure name="0e98" id="0e98" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*FD6MFAW9aaSKCVnFUzsPsA.png" data-width="1074" data-height="210" src="https://cdn-images-1.medium.com/max/800/1*FD6MFAW9aaSKCVnFUzsPsA.png"></figure><ul class="postList"><li name="5cc7" id="5cc7" class="graf graf--li graf-after--figure">Gram matrix: must be invertible</li></ul><figure name="d522" id="d522" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*a5mou6fw_BQOIC-JpBMXng.png" data-width="1074" data-height="210" src="https://cdn-images-1.medium.com/max/800/1*a5mou6fw_BQOIC-JpBMXng.png"></figure><ul class="postList"><li name="a6f0" id="a6f0" class="graf graf--li graf-after--figure">composition: define,</li></ul><figure name="a181" id="a181" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*T7LYQyuYjK6TyMCljoHcKw.png" data-width="1074" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*T7LYQyuYjK6TyMCljoHcKw.png"></figure><p name="a84b" id="a84b" class="graf graf--p graf-after--figure">then,</p><figure name="93e8" id="93e8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*joAynoCYgtWsaPnRBYIPaA.png" data-width="1074" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*joAynoCYgtWsaPnRBYIPaA.png"></figure><ul class="postList"><li name="4bbf" id="4bbf" class="graf graf--li graf-after--figure">Second difference matrix:</li></ul><figure name="f21b" id="f21b" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*M03x6EjBJVDd9j48cykanQ.png" data-width="1236" data-height="390" src="https://cdn-images-1.medium.com/max/800/1*M03x6EjBJVDd9j48cykanQ.png"></figure><ul class="postList"><li name="4ba5" id="4ba5" class="graf graf--li graf-after--figure">Matrix powers: for square matrix A, A² means AA, and same for higher powers</li></ul><p name="cc75" id="cc75" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) QR factorization</strong></p><ul class="postList"><li name="e999" id="e999" class="graf graf--li graf-after--p">Gram-Schmidt:</li></ul><figure name="828a" id="828a" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*LpvSypjUGPZRuCg1LmVCrA.png" data-width="1150" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*LpvSypjUGPZRuCg1LmVCrA.png"></figure><p name="a1ac" id="a1ac" class="graf graf--p graf-after--figure">where Rij = qiTaj for i &lt; j and Rii = ∥q ̃i∥, so A=QR</p><ul class="postList"><li name="261e" id="261e" class="graf graf--li graf-after--p">QR factorization of A: (1)QTQ=I; (2)R is upper triangular with positive diagonal entries</li></ul><p name="e481" id="e481" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(6) Left and right inverses, pseudo-inverse</strong></p><ul class="postList"><li name="9784" id="9784" class="graf graf--li graf-after--p">Left inverse: a matrix X that satisfies XA = I is called a left inverse of A. If a left inverse exists we say that A is left-invertible</li><li name="6651" id="6651" class="graf graf--li graf-after--li">Property #1: if A has a left inverse C then the columns of A are linearly independent</li></ul><figure name="6266" id="6266" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*w93sVsCLXYfi7zEA2wcXdA.png" data-width="1002" data-height="114" src="https://cdn-images-1.medium.com/max/800/1*w93sVsCLXYfi7zEA2wcXdA.png"></figure><ul class="postList"><li name="6f79" id="6f79" class="graf graf--li graf-after--figure">Right Inverse: a matrix X that satisfies AX = I is a right inverse of A. If a right inverse exists we say that A is right-invertible.</li><li name="dcf2" id="dcf2" class="graf graf--li graf-after--li">A is right-invertible if and only if AT is left-invertible:</li></ul><figure name="0617" id="0617" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*JZ58-tS2BXDcQntUmFeQWA.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*JZ58-tS2BXDcQntUmFeQWA.png"></figure><p name="cbf4" id="cbf4" class="graf graf--p graf-after--figure">Thus, a matrix is right-invertible if and only if its rows are linearly independent</p><ul class="postList"><li name="1621" id="1621" class="graf graf--li graf-after--p">Pseudo-inverse of a tall matrix</li></ul><figure name="40a3" id="40a3" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*ZjVINTZBdhU6SOVHuATtWw.png" data-width="958" data-height="86" src="https://cdn-images-1.medium.com/max/800/1*ZjVINTZBdhU6SOVHuATtWw.png"></figure><figure name="ef28" id="ef28" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*ns2urc3DQsnvMKka-zD1wA.png" data-width="958" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*ns2urc3DQsnvMKka-zD1wA.png"></figure><ul class="postList"><li name="62ac" id="62ac" class="graf graf--li graf-after--figure">Pseudo-inverse of a wide matrix</li></ul><figure name="d21d" id="d21d" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*uDRWmBG8L84LRCnMlKJcTA.png" data-width="958" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*uDRWmBG8L84LRCnMlKJcTA.png"></figure><figure name="6d66" id="6d66" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*rj-EohapS_gaqhSE0giolA.png" data-width="958" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*rj-EohapS_gaqhSE0giolA.png"></figure><ul class="postList"><li name="07bf" id="07bf" class="graf graf--li graf-after--figure">Pseudo-inverse via QR factorization</li></ul><figure name="81e0" id="81e0" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*dQeHxmMqVYHiJPMB2Oxqeg.png" data-width="598" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*dQeHxmMqVYHiJPMB2Oxqeg.png"></figure><figure name="357c" id="357c" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*jo32rlc-TUsoZPcQ5bF1-g.png" data-width="762" data-height="214" src="https://cdn-images-1.medium.com/max/800/1*jo32rlc-TUsoZPcQ5bF1-g.png"></figure><p name="efdb" id="efdb" class="graf graf--p graf-after--figure">pseudo-inverse gives us a method for solving over-determined and under-determined systems of linear equations. If the columns of A are linearly independent, and the over-determined equations Ax = b have a solution, then x = A†b is it. If the rows of A are linearly independent, the under-determined equations Ax = b have a solution for any vector b, and x = A†b is a solution.</p><p name="a523" id="a523" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) Inverse, solving linear equations</strong></p><ul class="postList"><li name="cfdd" id="cfdd" class="graf graf--li graf-after--p">invertible: if A has a left and a right inverse, they are unique and equal. A must be square</li></ul><figure name="30f9" id="30f9" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*eU6qdxq37X6m-NDE2YYJcA.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*eU6qdxq37X6m-NDE2YYJcA.png"></figure><ul class="postList"><li name="038b" id="038b" class="graf graf--li graf-after--figure">suppose A is invertible, for any b, Ax = b has the unique solution</li></ul><figure name="ee08" id="ee08" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*uguLAoDMy3NxKLUuio07bQ.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*uguLAoDMy3NxKLUuio07bQ.png"></figure><ul class="postList"><li name="9fc1" id="9fc1" class="graf graf--li graf-after--figure">inverse property #1</li></ul><figure name="786d" id="786d" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*duP_9vkEg-ymtd6K4MVbaw.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*duP_9vkEg-ymtd6K4MVbaw.png"></figure><ul class="postList"><li name="b894" id="b894" class="graf graf--li graf-after--figure">inverse property #2</li></ul><figure name="aae2" id="aae2" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*7021gNXB_Rov2ROGWUI01g.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*7021gNXB_Rov2ROGWUI01g.png"></figure><ul class="postList"><li name="3697" id="3697" class="graf graf--li graf-after--figure">inverse property #3</li></ul><figure name="68e2" id="68e2" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*Pk8XnPjACDxJSqSbB8EJJw.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*Pk8XnPjACDxJSqSbB8EJJw.png"></figure><ul class="postList"><li name="2f6f" id="2f6f" class="graf graf--li graf-after--figure">inverse property #4</li></ul><figure name="6f77" id="6f77" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*MaKZEKwzpaTckOqXb7wLoQ.png" data-width="1002" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*MaKZEKwzpaTckOqXb7wLoQ.png"></figure><ul class="postList"><li name="e036" id="e036" class="graf graf--li graf-after--figure">Inverse via QR factorization</li></ul><figure name="b132" id="b132" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*V-4h0Dy5GrM7HUYusgJAFQ.png" data-width="870" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*V-4h0Dy5GrM7HUYusgJAFQ.png"></figure><ul class="postList"><li name="b726" id="b726" class="graf graf--li graf-after--figure">The solution of the linear equations</li></ul><figure name="b64f" id="b64f" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*-YUB6qUaVkUYWFkZRogFbA.png" data-width="906" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*-YUB6qUaVkUYWFkZRogFbA.png"></figure><p name="c840" id="c840" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">4. Theory (linear algebra)</strong></p><p name="3075" id="3075" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Columns of A are independent ⇔ Gram matrix ATA is invertible</strong></p><p name="8d3c" id="8d3c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) A has a left inverse ⇔ columns of A are linearly independent</strong></p><p name="bf1d" id="bf1d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) (square) A is invertible ⇔ columns are independent, or rows are independent</strong></p><p name="f6a8" id="f6a8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">5. Least-squares</strong></p><p name="a21f" id="a21f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Basic least squares problem (Regression)</strong></p><ul class="postList"><li name="a8fb" id="a8fb" class="graf graf--li graf-after--p">residual: is r = Ax−b</li><li name="1fae" id="1fae" class="graf graf--li graf-after--li">least-squares problem: choose x to minimize ∥Ax − b∥²</li><li name="7803" id="7803" class="graf graf--li graf-after--li">objective function: ∥Ax − b∥²</li><li name="c07a" id="c07a" class="graf graf--li graf-after--li">least-squares approximate: xˆ called least squares approximate solution of Ax = b</li></ul><p name="8fe3" id="8fe3" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Solution via pseudo-inverse, QR factorization</strong></p><p name="043c" id="043c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Multi-objective least squares via weighted sum</strong></p><p name="9bf3" id="9bf3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Equality-constrained least squares</strong></p><p name="ae1d" id="ae1d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Solution via KKT system</strong></p><p name="8ddc" id="8ddc" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">6. Fitting models to data</strong></p><p name="6c61" id="6c61" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Least squares data fitting</strong></p><p name="039b" id="039b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Regression model</strong></p><ul class="postList"><li name="fcb7" id="fcb7" class="graf graf--li graf-after--p">superposition property: f satisfies the superposition property if f(αx + βy) = αf(x) + βf(y), a function that satisfies superposition is called linear. The inner product function is linear</li></ul><figure name="0d3c" id="0d3c" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*yQhl8HuBtfu-fJyCyYEw2A.png" data-width="962" data-height="210" src="https://cdn-images-1.medium.com/max/800/1*yQhl8HuBtfu-fJyCyYEw2A.png"></figure><ul class="postList"><li name="03c0" id="03c0" class="graf graf--li graf-after--figure">Affine functions: a function that is linear plus a constant is called affine. general form is f(x)=aTx+b,with a an n-vector and b a scalar</li><li name="0fec" id="0fec" class="graf graf--li graf-after--li">Affine approximation: first-order Taylor approximation of f, near point z is,</li></ul><figure name="4f34" id="4f34" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*ufQvOUxGSs53UJqKAItIpQ.png" data-width="962" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*ufQvOUxGSs53UJqKAItIpQ.png"></figure><p name="041e" id="041e" class="graf graf--p graf-after--figure">This is also,</p><figure name="ff7e" id="ff7e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*94C-BkAhem6ZNEiTZhZBiw.png" data-width="962" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*94C-BkAhem6ZNEiTZhZBiw.png"></figure><p name="1d4b" id="1d4b" class="graf graf--p graf-after--figure">Where,</p><figure name="f0de" id="f0de" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*KC6SSU2JOnXka3yGEJohdw.png" data-width="962" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*KC6SSU2JOnXka3yGEJohdw.png"></figure><ul class="postList"><li name="1daa" id="1daa" class="graf graf--li graf-after--figure">Regression model is the affine function of x.</li></ul><figure name="4a10" id="4a10" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*4dK9QKHQqtw5TOGnWS1ItQ.png" data-width="834" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*4dK9QKHQqtw5TOGnWS1ItQ.png"></figure><ul class="postList"><li name="2cdb" id="2cdb" class="graf graf--li graf-after--figure">Jacobian Matrix:</li></ul><figure name="280d" id="280d" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*CUHUNCIopHMYhEJOdLT9uw.png" data-width="1192" data-height="288" src="https://cdn-images-1.medium.com/max/800/1*CUHUNCIopHMYhEJOdLT9uw.png"></figure><ul class="postList"><li name="cf13" id="cf13" class="graf graf--li graf-after--figure">First order Taylor approximation around z = 0</li></ul><figure name="70f3" id="70f3" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*lVRz9RSnVgZ6gnS1W3wYIg.png" data-width="432" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*lVRz9RSnVgZ6gnS1W3wYIg.png"></figure><ul class="postList"><li name="7277" id="7277" class="graf graf--li graf-after--figure">associated predictions</li></ul><figure name="4855" id="4855" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*iu74Rccb_Aanl5VVu2hWQg.png" data-width="1074" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*iu74Rccb_Aanl5VVu2hWQg.png"></figure><ul class="postList"><li name="c16b" id="c16b" class="graf graf--li graf-after--figure">prediction error or residual (vector) is</li></ul><figure name="bbd9" id="bbd9" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*18yRfOZxp7Qi5ttlT8-53w.png" data-width="834" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*18yRfOZxp7Qi5ttlT8-53w.png"></figure><p name="7981" id="7981" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) Validation on a test set</strong></p><p name="fdde" id="fdde" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Regularization</strong></p><p name="f958" id="f958" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Least squares classification</strong></p><p name="35b7" id="35b7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">7. Computational complexity</strong></p><p name="d294" id="d294" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Floating-point operation (flop)</strong></p><ul class="postList"><li name="ada1" id="ada1" class="graf graf--li graf-after--p">flops: basic arithmetic operations (+, −, ∗, /, . . .) are called floating point operations or flops.</li><li name="86fa" id="86fa" class="graf graf--li graf-after--li">running speed: current computers are around 1Gflop/sec</li></ul><p name="2ad7" id="2ad7" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Vector-vector operations (inner product, norm, ...)</strong></p><ul class="postList"><li name="a78f" id="a78f" class="graf graf--li graf-after--p">addition, substraction: n flops</li><li name="b9c4" id="b9c4" class="graf graf--li graf-after--li">scalar multiplication: n flops</li><li name="ad61" id="ad61" class="graf graf--li graf-after--li">inner product: 2n − 1 ≈ 2n flops</li><li name="ef92" id="ef92" class="graf graf--li graf-after--li">norm: 2n − 1 ≈ 2n flops</li></ul><p name="ab5c" id="ab5c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Matrix-vector multiplication, matrix-matrix multiplication</strong></p><ul class="postList"><li name="039a" id="039a" class="graf graf--li graf-after--p">matrix addition, scalar-matrix multiplication cost mn flops</li><li name="ef87" id="ef87" class="graf graf--li graf-after--li">matrix-vector multiplication costs m(2n − 1) ≈ 2mn flops</li><li name="4aae" id="4aae" class="graf graf--li graf-after--li">matrix-matrix multiplication costs mn2p = 2mnp flops</li></ul><p name="2137" id="2137" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) QR factorization</strong></p><ul class="postList"><li name="5641" id="5641" class="graf graf--li graf-after--p">Total is 2n³ flops</li></ul><p name="2c33" id="2c33" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) Inverse, solving linear equations</strong></p><figure name="e581" id="e581" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*15ZRNQydX1V_TtOcOVD1cQ.png" data-width="1172" data-height="436" src="https://cdn-images-1.medium.com/max/800/1*15ZRNQydX1V_TtOcOVD1cQ.png"></figure><p name="36de" id="36de" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(6) Least-squares</strong></p><figure name="f976" id="f976" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pbSQ8hslsWxImlrXTWXiBQ.png" data-width="1114" data-height="330" src="https://cdn-images-1.medium.com/max/800/1*pbSQ8hslsWxImlrXTWXiBQ.png"></figure><p name="d602" id="d602" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(7) Linearly constrained least squares</strong></p><p name="e0de" id="e0de" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(8) Backsubstitution</strong></p><ul class="postList"><li name="0d16" id="0d16" class="graf graf--li graf-after--p graf--trailing">back substitution total is 1+3+···+(2n−1) = n² flops</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/464a718669e5"><time class="dt-published" datetime="2020-12-04T01:09:12.162Z">December 4, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/linear-algebra-16-a-quick-review-464a718669e5" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>