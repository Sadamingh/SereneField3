<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Operating System 15 | Midterm Review</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Operating System 15 | Midterm Review</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Operating System
</section>
<section data-field="body" class="e-content">
<section name="dd36" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="9880" id="9880" class="graf graf--h3 graf--leading graf--title">Operating System 15 | Midterm Review</h3><figure name="ec79" id="ec79" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*OfVNLpmvUpxbmI6o.png" data-width="1508" data-height="794" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*OfVNLpmvUpxbmI6o.png"></figure><ol class="postList"><li name="783e" id="783e" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Operating System Concepts</strong></li></ol><p name="73ef" id="73ef" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(0) Abstraction Vs. Arbitration</strong></p><ul class="postList"><li name="7aba" id="7aba" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Abstraction</strong></li></ul><p name="3320" id="3320" class="graf graf--p graf-after--li">Software that hides lower level details and provides a set of high-level functions. This is because the code needed to control peripheral devices is not standardized.</p><ul class="postList"><li name="80b4" id="80b4" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Arbitration</strong></li></ul><p name="625c" id="625c" class="graf graf--p graf-after--li">The set of rules in a computer’s operating system for allocating the resources of the computer. It allows its peripheral devices or memory to be run by more than one user.</p><p name="676c" id="676c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) OS Key Roles</strong></p><ul class="postList"><li name="c7ad" id="c7ad" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Direct Operational Resources</strong></li></ul><p name="3ab8" id="3ab8" class="graf graf--p graf-after--li">OS controls the resources of operational resources like CPU, memory, peripheral devices.</p><ul class="postList"><li name="2350" id="2350" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Enforce Working Policies</strong></li></ul><p name="0570" id="0570" class="graf graf--p graf-after--li">OS manages fair resource access and imposes certain limits.</p><ul class="postList"><li name="d96e" id="d96e" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Mitigates difficulty of complex tasks</strong></li></ul><p name="60ce" id="60ce" class="graf graf--p graf-after--li">OS <strong class="markup--strong markup--p-strong">simplifies and abstracts</strong> the view of the underlying hardware that’s observed by the applications that are running on that particular platform.</p><p name="d6a0" id="d6a0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) OS Elements</strong></p><ul class="postList"><li name="0f07" id="0f07" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">OS Abstractions</strong></li></ul><p name="4b44" id="4b44" class="graf graf--p graf-after--li">Concepts the OS uses to manage privileged components.</p><ul class="postList"><li name="59d0" id="59d0" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">OS Mechanisms</strong></li></ul><p name="1855" id="1855" class="graf graf--p graf-after--li">Mechanisms are used by abstractions to accomplish tasks.</p><ul class="postList"><li name="ba25" id="ba25" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">OS Policies</strong></li></ul><p name="2f96" id="2f96" class="graf graf--p graf-after--li">Policies determine how mechanisms are used.</p><p name="0432" id="0432" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) OS Designs</strong></p><ul class="postList"><li name="a4f6" id="a4f6" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Monolithic OS</strong></li></ul><p name="6815" id="6815" class="graf graf--p graf-after--li">With all the management codes implemented in the kernel.</p><ul class="postList"><li name="f909" id="f909" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Modular OS</strong></li></ul><p name="91cc" id="91cc" class="graf graf--p graf-after--li">All the management codes can be added to the kernel if needs.</p><ul class="postList"><li name="7e7f" id="7e7f" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Microkernel</strong></li></ul><p name="85e7" id="85e7" class="graf graf--p graf-after--li">A kernel requires only the most basic primitives.</p><p name="b71c" id="b71c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 1-1</strong>. Specify the following statements to OS abstractions (A), OS mechanisms (M), or OS policies (P).</p><ul class="postList"><li name="bcbd" id="bcbd" class="graf graf--li graf-after--p">A process or thread that the OS can execute.</li><li name="2c14" id="2c14" class="graf graf--li graf-after--li">The OS represents communication endpoints as sockets.</li><li name="c13f" id="c13f" class="graf graf--li graf-after--li">Which parts of data will be removed from memory.</li><li name="bc33" id="bc33" class="graf graf--li graf-after--li">Files as data organization on the disk by OS.</li><li name="b7b6" id="b7b6" class="graf graf--li graf-after--li">To open or write to a file.</li><li name="ffa9" id="ffa9" class="graf graf--li graf-after--li">A process can wait for incoming connections on sockets via accept().</li><li name="62b7" id="62b7" class="graf graf--li graf-after--li">To create or schedule a process to run on the CPU.</li><li name="42a3" id="42a3" class="graf graf--li graf-after--li">Memory pages used to mapping the memory.</li><li name="9a25" id="9a25" class="graf graf--li graf-after--li">The OS allocates a range of memory for a data structure.</li><li name="015b" id="015b" class="graf graf--li graf-after--li">A mutex that can be used to lock the critical section.</li><li name="d046" id="d046" class="graf graf--li graf-after--li">A condition variable that allows more fine-grained controls.</li></ul><p name="b974" id="b974" class="graf graf--p graf-after--li">Ans:</p><pre name="0100" id="0100" class="graf graf--pre graf-after--p">A<br>A<br>P            // by LRU or EDF<br>A<br>M<br>M<br>M<br>A<br>M<br>M<br>M</pre><p name="ae4b" id="ae4b" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 1-2</strong>. Select all the <strong class="markup--strong markup--p-strong">TRUE</strong> statements.</p><ul class="postList"><li name="f1b0" id="f1b0" class="graf graf--li graf-after--p">Memory management mechanism might use different policies depending on the situation</li><li name="7624" id="7624" class="graf graf--li graf-after--li">Optimize for the common case answers questions like where will the OS used</li><li name="f232" id="f232" class="graf graf--li graf-after--li">A trap instruction is performed to switch from kernel mode to user mode</li><li name="19b4" id="19b4" class="graf graf--li graf-after--li">User-level thread library is the interface for applications to operating system communications</li><li name="eafa" id="eafa" class="graf graf--li graf-after--li">OS is an interface between the hardware and application programs</li><li name="37b0" id="37b0" class="graf graf--li graf-after--li">Generally, the system calls are functions written in C and C++</li><li name="11c8" id="11c8" class="graf graf--li graf-after--li">Open, Close, Read, Write are some of the most prominently used system calls</li><li name="2140" id="2140" class="graf graf--li graf-after--li">Signals is a mechanism for the operating system to pass notifications to the applications</li></ul><p name="0e06" id="0e06" class="graf graf--p graf-after--li">Ans:</p><pre name="4cf7" id="4cf7" class="graf graf--pre graf-after--p">T<br>F         // not answers, but based on the answer of<br>F         // from user mode to kernel mode with no privilege<br>F         // system calls are the interfaces<br>T         // apps &lt;-&gt; syscalls &lt;-&gt; OS &lt;-&gt; hardwares<br>T<br>T<br>T</pre><p name="5505" id="5505" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 1-3</strong>. Fill in the blanks of with <strong class="markup--strong markup--p-strong">Monolithic</strong>, <strong class="markup--strong markup--p-strong">Modular</strong>, and <strong class="markup--strong markup--p-strong">Microkernel</strong>.</p><ul class="postList"><li name="555f" id="555f" class="graf graf--li graf-after--p">Size: ____________ &gt; _____________ &gt; _____________</li><li name="dbeb" id="dbeb" class="graf graf--li graf-after--li">Resource-intensive: ____________ &gt; _____________ &gt; _____________</li><li name="6aea" id="6aea" class="graf graf--li graf-after--li">Portablility: ____________ &gt; _____________ &gt; _____________</li></ul><p name="b80a" id="b80a" class="graf graf--p graf-after--li">Ans:</p><pre name="aa60" id="aa60" class="graf graf--pre graf-after--p">Size: Monolithic &gt; Modular &gt; Microkernel<br>Resource-intensive: Monolithic &gt; Modular &gt; Microkernel<br>Portablility: Modular &gt; Monolithic &gt; Microkernel</pre><p name="b8df" id="b8df" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 1-4</strong>. For the following options, indicate if they are examples of abstraction (B) or arbitration (R).</p><ul class="postList"><li name="9409" id="9409" class="graf graf--li graf-after--p">Allocate CPU time for different user-level threads</li><li name="ba43" id="ba43" class="graf graf--li graf-after--li">Distributing memory between multiple processes</li><li name="baef" id="baef" class="graf graf--li graf-after--li">Supporting different types of speakers</li><li name="cf3b" id="cf3b" class="graf graf--li graf-after--li">Interchangeable access of a hard disk or SSD</li><li name="ebac" id="ebac" class="graf graf--li graf-after--li">Arbitrate access to a shared device</li></ul><p name="518e" id="518e" class="graf graf--p graf-after--li">Ans:</p><pre name="1899" id="1899" class="graf graf--pre graf-after--p">R              // because OS can directly allocate CPU time<br>R              // because OS can directly allocate memory<br>B              // OS uses drivers for abstracting different speakers<br>B              // OS uses file abstraction for access a hard disk<br>R              // an arbitrate access means a direct access</pre><p name="08f2" id="08f2" class="graf graf--p graf-after--pre">The key for answer this type of question is that you need to determine whether the OS abstracts a hardware or it accesses the hardware directly or arbitrarily.</p><p name="27b1" id="27b1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 1-5</strong>. Which of the following are likely components of an OS? Check all that apply.</p><ul class="postList"><li name="2828" id="2828" class="graf graf--li graf-after--p">[ ] File editor</li><li name="7583" id="7583" class="graf graf--li graf-after--li">[ ] File system</li><li name="e6c5" id="e6c5" class="graf graf--li graf-after--li">[ ] Device driver</li><li name="5731" id="5731" class="graf graf--li graf-after--li">[ ] Cache memory</li><li name="22c8" id="22c8" class="graf graf--li graf-after--li">[ ] Web browser</li><li name="776d" id="776d" class="graf graf--li graf-after--li">[ ] Schedular</li></ul><p name="225a" id="225a" class="graf graf--p graf-after--li">Ans:</p><pre name="c91f" id="c91f" class="graf graf--pre graf-after--p">[ ] File editor<br>[✓] File system<br>[✓] Device driver<br>[ ] Cache memory<br>[ ] Web browser<br>[✓] Schedular</pre><p name="f9c9" id="f9c9" class="graf graf--p graf-after--pre graf--trailing">Note that OS can not directly manage cache and it is actually managed by the hardware.</p></div></div></section><section name="48ac" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="e151" id="e151" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">2. Threads and Processes Concepts</strong></p><p name="b269" id="b269" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Process Creation</strong></p><ul class="postList"><li name="1561" id="1561" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">fork</code> : creates a new process with the same content of the parent</li><li name="4e88" id="4e88" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">exec</code> : rewrite the content of a process with some other program</li></ul><p name="44e0" id="44e0" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Process and Thread Life Cycle</strong></p><ul class="postList"><li name="b133" id="b133" class="graf graf--li graf-after--p">PLC</li></ul><figure name="9d15" id="9d15" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*9o_B31CtjKb9ERWoCMoQ7w.png" data-width="1420" data-height="436" src="https://cdn-images-1.medium.com/max/800/1*9o_B31CtjKb9ERWoCMoQ7w.png"></figure><ul class="postList"><li name="17cb" id="17cb" class="graf graf--li graf-after--figure">TLC</li></ul><figure name="c346" id="c346" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*y8sCYenbeC8nqU4HBabp-g.png" data-width="1382" data-height="500" src="https://cdn-images-1.medium.com/max/800/1*y8sCYenbeC8nqU4HBabp-g.png"></figure><p name="0da8" id="0da8" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) Process and Thread Execution Context</strong></p><p name="c685" id="c685" class="graf graf--p graf-after--p">Process-wide Items:</p><ul class="postList"><li name="25b5" id="25b5" class="graf graf--li graf-after--p">Virtual to physical memory address mappings</li><li name="8157" id="8157" class="graf graf--li graf-after--li">Global variables</li><li name="add5" id="add5" class="graf graf--li graf-after--li">Open files</li><li name="b9b1" id="b9b1" class="graf graf--li graf-after--li">Child processes</li><li name="38b6" id="38b6" class="graf graf--li graf-after--li">Pending alarms</li><li name="a3f0" id="a3f0" class="graf graf--li graf-after--li">Signals</li><li name="6666" id="6666" class="graf graf--li graf-after--li">Signal handlers</li><li name="98b8" id="98b8" class="graf graf--li graf-after--li">Accounting information</li></ul><p name="acdc" id="acdc" class="graf graf--p graf-after--li">Thread-specific Items:</p><ul class="postList"><li name="9a6d" id="9a6d" class="graf graf--li graf-after--p">Program counter</li><li name="eb24" id="eb24" class="graf graf--li graf-after--li">Thread-specific register values</li><li name="aafb" id="aafb" class="graf graf--li graf-after--li">Signal mask</li><li name="e10f" id="e10f" class="graf graf--li graf-after--li">Stack pointer</li><li name="518d" id="518d" class="graf graf--li graf-after--li">Stack</li></ul><p name="2152" id="2152" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Process and Thread Context Switch</strong></p><ul class="postList"><li name="6fe9" id="6fe9" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Direct Cost</strong>: the number of cycles that have to be executed to load/store all the values from the process control blocks to/from memory</li><li name="98f0" id="98f0" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Indirect Cost</strong>: caused by cache missing problems like cold cache or cache pollution</li></ul><p name="1a0c" id="1a0c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) Intro to Inter Process Communication (IPC)</strong></p><p name="0e7f" id="0e7f" class="graf graf--p graf-after--p">There are two models of IPC:</p><ul class="postList"><li name="40c0" id="40c0" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Shared-memory Based Communication</strong>: need synchronisation (e.g. mutex, cv, …). Cost for synchronisation setups.</li><li name="73bc" id="73bc" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Message-passing Communication</strong>: asynchronously or synchronously send/recv message. Cost for the approach implementation.</li></ul><p name="18ef" id="18ef" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Example 2-1</strong>. How is a new process created? Select the <strong class="markup--strong markup--p-strong">best</strong> option.</p><ul class="postList"><li name="39d7" id="39d7" class="graf graf--li graf-after--p">only via fork</li><li name="12bb" id="12bb" class="graf graf--li graf-after--li">only via exec</li><li name="bd92" id="bd92" class="graf graf--li graf-after--li">only via fork followed by exec</li><li name="5e2c" id="5e2c" class="graf graf--li graf-after--li">only via exec followed by fork</li><li name="04ef" id="04ef" class="graf graf--li graf-after--li">via fork or exec followed by fork</li><li name="69b5" id="69b5" class="graf graf--li graf-after--li">via fork or fork followed by exec</li><li name="64f4" id="64f4" class="graf graf--li graf-after--li">via exec or exec followed by fork</li><li name="1bfd" id="1bfd" class="graf graf--li graf-after--li">via exec or fork followed by exec</li></ul><p name="77d6" id="77d6" class="graf graf--p graf-after--li">Ans:</p><pre name="4dbf" id="4dbf" class="graf graf--pre graf-after--p">via fork or fork followed by exec</pre><ul class="postList"><li name="51b3" id="51b3" class="graf graf--li graf-after--pre">The term <code class="markup--code markup--li-code">fork followed by exec</code> means that we first call <code class="markup--code markup--li-code">fork</code>, and then we call <code class="markup--code markup--li-code">exec</code>.</li><li name="78bb" id="78bb" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">exec followed by fork</code> will call <code class="markup--code markup--li-code">exec</code> first. Then the program content <code class="markup--code markup--li-code">exec</code> will be replaced by some other program and the <code class="markup--code markup--li-code">fork</code> is never called.</li></ul><p name="abba" id="abba" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Example 2-2</strong>. Specify the following statements refer to which process states they are <strong class="markup--strong markup--p-strong">entering</strong> at the moment. The states are New (N), Ready (R), Running (RUN), Terminated (T), and Waiting (W).</p><ul class="postList"><li name="716f" id="716f" class="graf graf--li graf-after--p">Once the process has been created</li><li name="604b" id="604b" class="graf graf--li graf-after--li">Once the process has been allocated and initialized</li><li name="22f8" id="22f8" class="graf graf--li graf-after--li">Once the OS performs admission control</li><li name="f6b1" id="f6b1" class="graf graf--li graf-after--li">Once the process has been dispatched to the CPU</li><li name="5005" id="5005" class="graf graf--li graf-after--li">Once the process gets scheduled to run on the CPU</li><li name="822f" id="822f" class="graf graf--li graf-after--li">Once the process is interrupted by some other process</li><li name="4d36" id="4d36" class="graf graf--li graf-after--li">Once the process is preempted and context switched to another process</li><li name="57aa" id="57aa" class="graf graf--li graf-after--li">Once the process starts waiting on a signal</li><li name="6c96" id="6c96" class="graf graf--li graf-after--li">Once the process issues an I/O operation</li><li name="57b5" id="57b5" class="graf graf--li graf-after--li">Once an I/O operation completes for the process</li><li name="cbbb" id="cbbb" class="graf graf--li graf-after--li">Once the process created via the <code class="markup--code markup--li-code">fork</code> call (means initialized)</li><li name="bc7d" id="bc7d" class="graf graf--li graf-after--li">Once the process has its time slice expired</li></ul><p name="d117" id="d117" class="graf graf--p graf-after--li">Ans:</p><pre name="0834" id="0834" class="graf graf--pre graf-after--p">N<br>R<br>R<br>RUN<br>RUN<br>R<br>R<br>W<br>W<br>R<br>R<br>R</pre><p name="f1af" id="f1af" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 2-3</strong>. DELETED</p><p name="03b2" id="03b2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 2-4</strong>. DELETED</p><p name="8e60" id="8e60" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 2-5</strong>. The CPU is able to execute a process when the process is in which state(s)?</p><ul class="postList"><li name="47d4" id="47d4" class="graf graf--li graf-after--p">Running</li><li name="d94a" id="d94a" class="graf graf--li graf-after--li">Waiting</li><li name="b335" id="b335" class="graf graf--li graf-after--li">Ready</li><li name="26d9" id="26d9" class="graf graf--li graf-after--li">New</li></ul><p name="bbab" id="bbab" class="graf graf--p graf-after--li">Ans:</p><pre name="84e0" id="84e0" class="graf graf--pre graf-after--p">Running<br>Ready</pre><p name="c003" id="c003" class="graf graf--p graf-after--pre">It is a little bit tricky for this problem because we the CPU is able to execute a process in the ready state. The reason why it is not being executed is that this process is waiting for the scheduler to allocate a CPU for this process. So it is basically the moment when process is <strong class="markup--strong markup--p-strong">scheduled to run</strong> after some execution.</p><p name="60a7" id="60a7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 2-6</strong>. Do the following statements apply to processes(P), threads(T) or both(B)?</p><ul class="postList"><li name="dc7e" id="dc7e" class="graf graf--li graf-after--p">Can share a virtual address space</li><li name="1079" id="1079" class="graf graf--li graf-after--li">Take longer to context switch</li><li name="07ec" id="07ec" class="graf graf--li graf-after--li">Have an execution context</li><li name="8359" id="8359" class="graf graf--li graf-after--li">Usually result in hotter caches when multiple exists</li><li name="2d3e" id="2d3e" class="graf graf--li graf-after--li">Make use of some communication mechanisms</li></ul><p name="0706" id="0706" class="graf graf--p graf-after--li">Ans:</p><pre name="d125" id="d125" class="graf graf--pre graf-after--p graf--trailing">T<br>P<br>B<br>T<br>B</pre></div></div></section><section name="6839" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="036a" id="036a" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">3. Mutex and Condition Variable</strong></p><p name="b063" id="b063" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 3-1</strong>. In the (pseudo) code segments for the <strong class="markup--strong markup--p-strong">producer code</strong> and <strong class="markup--strong markup--p-strong">consumer code</strong>, mark and explain all the lines where there are errors.</p><ul class="postList"><li name="de58" id="de58" class="graf graf--li graf-after--p">Global Section</li></ul><pre name="d2c7" id="d2c7" class="graf graf--pre graf-after--li"><code class="markup--code markup--pre-code">int in, out, buffer[BUFFERSIZE];<br>mutex_t m;<br>cond_var_t not_empty, not_full;</code></pre><ul class="postList"><li name="7dc2" id="7dc2" class="graf graf--li graf-after--pre">Producer Code</li></ul><pre name="438d" id="438d" class="graf graf--pre graf-after--li"><code class="markup--code markup--pre-code">1. while (more_to_produce) {<br>2.    mutex_lock(&amp;m);<br>3.    if (out == (in + 1) % BUFFERSIZE))      // buffer full <br>4.       condition_wait(&amp;not_full);<br>5.    add_item(buffer[in]);                   // add item<br>6.    in = (in + 1) % BUFFERSIZE <br>7.    cond_broadcast(&amp;not_empty);<br>8.             <br>9. }                                          // end producer code</code></pre><ul class="postList"><li name="337a" id="337a" class="graf graf--li graf-after--pre">Consumer Code</li></ul><pre name="d938" id="d938" class="graf graf--pre graf-after--li"><code class="markup--code markup--pre-code">1. while (more_to_consume) {<br>2.    mutex_lock(&amp;m);<br>3.    if (out == in)                      // buffer empty <br>4.       condition_wait(&amp;not_empty);<br>5.    remove_item(out);<br>6.    out = (out + 1) % BUFFERSIZE; <br>7.    condition_signal(&amp;not_empty);<br>8.          <br>9. }                                      // end consumer code</code></pre><p name="14b4" id="14b4" class="graf graf--p graf-after--pre">Ans:</p><ul class="postList"><li name="5bba" id="5bba" class="graf graf--li graf-after--p">Producer Code</li></ul><pre name="46aa" id="46aa" class="graf graf--pre graf-after--li">line 3: using if instead of while<br>line 4: condition_wait doesn’t specify a mutex<br>line 7: using signal instead of broadcast<br>line 8: missing the mutex_unlock</pre><ul class="postList"><li name="507a" id="507a" class="graf graf--li graf-after--pre">Consumer Code</li></ul><pre name="f215" id="f215" class="graf graf--pre graf-after--li">line 3: using if instead of while<br>line 4: condition_wait doesn’t specify a mutex<br>line 7: should signal not_full<br>line 8: missing the mutex_unlock</pre><p name="b746" id="b746" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 3-2</strong>. DELETED</p><p name="2f4b" id="2f4b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 3-3</strong>. Does the following code suffice to protect a critical section with two processes <em class="markup--em markup--p-em">p</em>0 and <em class="markup--em markup--p-em">p</em>1 running on separate processors on a two-processor shared-memory machine? That is, does it meet <em class="markup--em markup--p-em">all</em> of the requirements for protecting a critical section? Variable <code class="markup--code markup--p-code">turn</code> is a shared variable.</p><pre name="515b" id="515b" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">/* Code for p0 */</strong><br>// non-critical-section code<br>while(turn != 0) {}<br>   <em class="markup--em markup--pre-em">critical section</em><br>turn = 1;<br>// non-critical-section code</pre><pre name="1989" id="1989" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">/* Code for p1 */</strong><br>// non-critical-section code<br>while(turn != 1) {}<br>   <em class="markup--em markup--pre-em">critical section</em><br>turn = 0;<br>// non-critical-section code</pre><p name="f4f8" id="f4f8" class="graf graf--p graf-after--pre">Ans:</p><pre name="dcd9" id="dcd9" class="graf graf--pre graf-after--p">Yes</pre><p name="3960" id="3960" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 3-4</strong>. Suppose that two threads have several critical sections, protected by different mutexes. The following are two of those critical sections, with their protection code.</p><pre name="834f" id="834f" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">/* code segment 1 */</strong><br>lock(m1);<br>…  /* code protected by m1 */<br>lock(m2);<br>…  /* code protected by m2 */<br>unlock(m2);<br>unlock(m1)<br><br><strong class="markup--strong markup--pre-strong">/* code segment 2 */</strong><br>lock(m2);<br>…  /* code protected by m2 */<br>lock(m1);<br>…  /* code protected by m1 */<br>unlock(m1);<br>unlock(m2)</pre><p name="14f5" id="14f5" class="graf graf--p graf-after--pre">Is that a sensible way to protect this critical code? If not, how to protect this critical code?</p><p name="5bce" id="5bce" class="graf graf--p graf-after--p">Ans:</p><pre name="6534" id="6534" class="graf graf--pre graf-after--p">No, because there is a deadlock problem</pre><p name="45e2" id="45e2" class="graf graf--p graf-after--pre">We have two ways to protect this critical code,</p><ul class="postList"><li name="6366" id="6366" class="graf graf--li graf-after--p">Method 1</li></ul><pre name="28b4" id="28b4" class="graf graf--pre graf-after--li"><strong class="markup--strong markup--pre-strong">/* code segment 1 */</strong><br>lock(m1);<br>…  /* code protected by m1 */<br>lock(m2);<br>…  /* code protected by m2 */<br>unlock(m1);<br>unlock(m2)<br><br><strong class="markup--strong markup--pre-strong">/* code segment 2 */</strong><br>lock(m1);<br>…  /* code protected by m2 */<br>lock(m2);<br>…  /* code protected by m1 */<br>unlock(m1);<br>unlock(m2)</pre><ul class="postList"><li name="fefa" id="fefa" class="graf graf--li graf-after--pre">Method 2</li></ul><pre name="0843" id="0843" class="graf graf--pre graf-after--li"><strong class="markup--strong markup--pre-strong">/* code segment 1 */</strong><br>lock(m1);<br>…  /* code protected by m1 */<br>unlock(m1);<br>lock(m2);<br>…  /* code protected by m2 */<br>unlock(m2)<br><br><strong class="markup--strong markup--pre-strong">/* code segment 2 */</strong><br>lock(m1);<br>…  /* code protected by m1 */<br>unlock(m1);<br>lock(m2);<br>…  /* code protected by m2 */<br>unlock(m2)</pre><p name="4c8e" id="4c8e" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 3-5</strong>. A shared calendar supports three types of operations for reservations:</p><ol class="postList"><li name="51c5" id="51c5" class="graf graf--li graf-after--p">read</li><li name="0f2d" id="0f2d" class="graf graf--li graf-after--li">cancel</li><li name="a3b8" id="a3b8" class="graf graf--li graf-after--li">update</li></ol><p name="aab9" id="aab9" class="graf graf--p graf-after--li">Requests for cancellations should have priority above reads, who in turn have priority over new updates. In pseudocode, write the critical section enter/exit code for the <strong class="markup--strong markup--p-strong">read</strong> operation.</p><p name="ed50" id="ed50" class="graf graf--p graf-after--p">Ans:</p><pre name="ed36" id="ed36" class="graf graf--pre graf-after--p graf--trailing">cs_enter_read {<br>    mutex_lock(m);<br>    read_waiting++;<br>    while (read&gt;0 || cancel&gt;0 || update&gt;0 || cancel_waiting&gt;0)<br>        wait(read_cv, m);<br>    read++;<br>    read_waiting--;<br>    mutex_unlock(m);<br>}<br>cs_exit_read {<br>    mutex_lock(m);<br>    read--;<br>    if (cancel_waiting&gt;0) signal(cancle_cv);<br>    else if (read_waiting&gt;0) signal(read_cv);<br>    else if (update_waiting&gt;0) signal(update_cv);<br>    mutex_unlock(m);<br>}</pre></div></div></section><section name="6546" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="723a" id="723a" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">4. Boss-worker Model and Pipeline Model</strong></p><p name="9686" id="9686" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 4-1</strong>. An image web server has three stages with average execution times as follows:</p><ul class="postList"><li name="9f09" id="9f09" class="graf graf--li graf-after--p">Stage 1: read and parse request (10ms)</li><li name="e3f5" id="e3f5" class="graf graf--li graf-after--li">Stage 2: read and process image (30ms)</li><li name="4a35" id="4a35" class="graf graf--li graf-after--li">Stage 3: send the image (20ms)</li></ul><p name="62b1" id="62b1" class="graf graf--p graf-after--li">Suppose we can create a maximum of 6 threads. You have been asked to build a multi-threaded implementation of this server using the<strong class="markup--strong markup--p-strong"> pipeline model</strong>. Using a <strong class="markup--strong markup--p-strong">pipeline model</strong>, answer the following questions:</p><p name="d3a9" id="d3a9" class="graf graf--p graf-after--p">a. How many threads will you allocate to each pipeline stage to create a balanced pipeline?</p><p name="5acf" id="5acf" class="graf graf--p graf-after--p">b. What is the expected execution time for 100 requests (in sec)?</p><p name="1dee" id="1dee" class="graf graf--p graf-after--p">c. What is the average throughput of the system in Question 2 (in req/sec)? Assume there are infinite processing resources (CPU’s, memory, etc.).</p><p name="8a87" id="8a87" class="graf graf--p graf-after--p">d. Suppose we have a non-balanced pipeline model with 2 threads assigned to all three stages. What is the expected execution time for 100 requests (in sec)?</p><p name="d9f3" id="d9f3" class="graf graf--p graf-after--p">e. Which performs better, a balanced pipeline or a non-balanced pipeline?</p><p name="19b7" id="19b7" class="graf graf--p graf-after--p">Ans:</p><pre name="48ab" id="48ab" class="graf graf--pre graf-after--p">// a. <br>stage 1 (10ms) = 1 thread<br>stage 2 (30ms) = 3 threads<br>stage 3 (20ms) = 2 threads</pre><pre name="196e" id="196e" class="graf graf--pre graf-after--pre">// b.<br>exe_time_1 = (10+30+20) + (100-1)*10 = 1050 ms = 1.05 s</pre><pre name="d280" id="d280" class="graf graf--pre graf-after--pre">// c. <br>throughput = # of reqs/exe_time = 100/1.05 = 95.24 req/s</pre><pre name="2467" id="2467" class="graf graf--pre graf-after--pre">// d. <br>It is eqvilent to the situation that we have 2 same pipelines, and each of them has a longest stage time of 30ms.<br>exe_time_2 = (10+30+20) + (100/2-1)*30 = 1530 ms = 1.53 s</pre><pre name="0b5c" id="0b5c" class="graf graf--pre graf-after--pre">// e.<br>It depends on our metrics. With the execution time, we can conclude that the balanced pipeline has a better performance.</pre><p name="0b5a" id="0b5a" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 4-2</strong>. Suppose we have a boss-worker model and a pipeline model, and we assign 11 tasks and 6 working threads for each model. A worker in the boss-worker model takes 120ms to complete a task, while each stage in the pipeline mode takes 20ms.</p><p name="3014" id="3014" class="graf graf--p graf-after--p">Answer the following questions.</p><p name="0d8d" id="0d8d" class="graf graf--p graf-after--p">For the <strong class="markup--strong markup--p-strong">boss-worker model</strong>,</p><p name="e489" id="e489" class="graf graf--p graf-after--p">a1. The execution time is __________ ms.</p><p name="7067" id="7067" class="graf graf--p graf-after--p">b1. The throughput is __________ req/sec.</p><p name="1fe2" id="1fe2" class="graf graf--p graf-after--p">c1. The average execution time is ____________ ms.</p><p name="4cf3" id="4cf3" class="graf graf--p graf-after--p">d1. The average completion time is __________ ms.</p><p name="48ec" id="48ec" class="graf graf--p graf-after--p">For the <strong class="markup--strong markup--p-strong">pipeline model</strong>,</p><p name="7803" id="7803" class="graf graf--p graf-after--p">a2. The execution time is __________ ms.</p><p name="f731" id="f731" class="graf graf--p graf-after--p">b2. The throughput is __________ req/sec.</p><p name="90c3" id="90c3" class="graf graf--p graf-after--p">c2. The average execution time is ____________ ms.</p><p name="bec7" id="bec7" class="graf graf--p graf-after--p">d2. The average completion time is __________ ms.</p><p name="b6f3" id="b6f3" class="graf graf--p graf-after--p">Ans:</p><pre name="a140" id="a140" class="graf graf--pre graf-after--p">a1. 3*120 = 360 ms <br>b1. 11/0.36 = 30.56 req/sec<br>c1. 360/11 = 32.73 ms<br>d1. (120*5 + 240*5 + 360)/11 = 196.36 ms<br>a2. 20*6 + 10*20 = 320 ms<br>b2. 11/0.32 = 34.38 req/sec<br>c2. 320/11 = 20.09 ms<br>d2. (120 + 140 + 160 + ... + 320)/11 = 220 ms</pre><p name="9bb5" id="9bb5" class="graf graf--p graf-after--pre graf--trailing"><strong class="markup--strong markup--p-strong">Example 4-3</strong>. DELETED</p></div></div></section><section name="76e0" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="a5b9" id="a5b9" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">5. Solaris Papers</strong></p><p name="1350" id="1350" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 5-1</strong>. For each of these data structures, list at least two elements they must contain:</p><ul class="postList"><li name="b987" id="b987" class="graf graf--li graf-after--p">a. Process</li><li name="cfe3" id="cfe3" class="graf graf--li graf-after--li">b. LWP</li><li name="206f" id="206f" class="graf graf--li graf-after--li">c. Kernel-threads</li><li name="da8f" id="da8f" class="graf graf--li graf-after--li">d. CPU</li></ul><p name="94c9" id="94c9" class="graf graf--p graf-after--li">Ans:</p><p name="72ee" id="72ee" class="graf graf--p graf-after--p">All the possible solutions are,</p><p name="9ff0" id="9ff0" class="graf graf--p graf-after--p">a. Process:</p><pre name="296c" id="296c" class="graf graf--pre graf-after--p">pointer to <strong class="markup--strong markup--pre-strong">List of KLTs</strong><br>pointer to <strong class="markup--strong markup--pre-strong">address space</strong><br><strong class="markup--strong markup--pre-strong">user credentials</strong><br>list of <strong class="markup--strong markup--pre-strong">signal handlers</strong><br><strong class="markup--strong markup--pre-strong">user structure</strong></pre><p name="9ac0" id="9ac0" class="graf graf--p graf-after--pre">b. LWP</p><pre name="8403" id="8403" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">UL register values</strong><br><strong class="markup--strong markup--pre-strong">system call arguments<br>signal masks</strong><br>resource usage information<br>profiling pointers</pre><p name="21ea" id="21ea" class="graf graf--p graf-after--pre">c. Kernel-threads</p><pre name="9ca5" id="9ca5" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">kernel registers</strong><br><strong class="markup--strong markup--pre-strong">dispatch queue</strong> links<br><strong class="markup--strong markup--pre-strong">stack pointers<br>scheduling class<br></strong>pointer to the next KLT</pre><p name="43b5" id="43b5" class="graf graf--p graf-after--pre">d. CPU</p><pre name="2e8d" id="2e8d" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">pointer to currently executing KLT</strong><br><strong class="markup--strong markup--pre-strong">pointer to idle KLTs</strong> for the CPU<br><strong class="markup--strong markup--pre-strong">dispatch handling information<br>interrupt handling information</strong></pre><p name="4d16" id="4d16" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 5-2</strong>. DELETED</p><p name="5419" id="5419" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 5-3</strong>. Specify whether the following data structures in the Solaris papers are <strong class="markup--strong markup--p-strong">SWAPPABLE (S)</strong> or <strong class="markup--strong markup--p-strong">NON-SWAPPABLE (N)</strong>.</p><ul class="postList"><li name="3c22" id="3c22" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">proc</code> structure</li><li name="f256" id="f256" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">user</code> structure</li><li name="5dfa" id="5dfa" class="graf graf--li graf-after--li">kernel thread structure</li><li name="0c9d" id="0c9d" class="graf graf--li graf-after--li">LWP structure</li><li name="a1df" id="a1df" class="graf graf--li graf-after--li">Stack</li><li name="6d16" id="6d16" class="graf graf--li graf-after--li">CPU structure</li></ul><p name="d6e7" id="d6e7" class="graf graf--p graf-after--li">Ans:</p><pre name="8890" id="8890" class="graf graf--pre graf-after--p">N<br>S<br>N<br>S<br>S<br>S</pre><p name="bdb3" id="bdb3" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 5-4</strong>. Based on the mechanisms described in the Solaris papers,</p><p name="674c" id="674c" class="graf graf--p graf-after--p">a. Answer the following questions with one-to-one(<strong class="markup--strong markup--p-strong">1:1</strong>), many-to-one(<strong class="markup--strong markup--p-strong">M:1</strong>), or many-to-many(<strong class="markup--strong markup--p-strong">M:N</strong>)</p><ul class="postList"><li name="2a12" id="2a12" class="graf graf--li graf-after--p">a1. Linux uses a __________ threading model.</li><li name="2160" id="2160" class="graf graf--li graf-after--li">a2. Solaris uses a __________ threading model.</li><li name="6264" id="6264" class="graf graf--li graf-after--li">a3. LWPs have a __________ mapping pattern to the kernel-level threads.</li><li name="b268" id="b268" class="graf graf--li graf-after--li">a4. LWPs have a __________ mapping pattern to the user-level threads.</li></ul><p name="5653" id="5653" class="graf graf--p graf-after--li">b. Answer the following questions with <strong class="markup--strong markup--p-strong">Multiprocessing</strong>, <strong class="markup--strong markup--p-strong">Multithreading</strong>, <strong class="markup--strong markup--p-strong">Synchronization</strong>, and <strong class="markup--strong markup--p-strong">Visibility</strong></p><ul class="postList"><li name="96e3" id="96e3" class="graf graf--li graf-after--p">b1. Solaris provides configurations for concurrency because of ____________.</li><li name="1cb0" id="1cb0" class="graf graf--li graf-after--li">b2. Solaris designs LWPs because of ____________.</li><li name="1aad" id="1aad" class="graf graf--li graf-after--li">b3. Solaris implements full-fledged threads for interrupts because of ___________.</li></ul><p name="5d70" id="5d70" class="graf graf--p graf-after--li">c. Answer the following questions with <strong class="markup--strong markup--p-strong">DISPATCH</strong> and <strong class="markup--strong markup--p-strong">SLEEP</strong>.</p><ul class="postList"><li name="221e" id="221e" class="graf graf--li graf-after--p">c1. When a thread is runnable, it will be put on the _________ queue.</li><li name="6110" id="6110" class="graf graf--li graf-after--li">c2. When a thread blocks on a local synchronization object, it will be put on the ___________ queue.</li><li name="3342" id="3342" class="graf graf--li graf-after--li">c3. When the ____________ queue is empty, the LWP goes back to idling.</li></ul><p name="d562" id="d562" class="graf graf--p graf-after--li">d. Answer the following questions with <strong class="markup--strong markup--p-strong">PARK</strong> and <strong class="markup--strong markup--p-strong">IDLE</strong>.</p><p name="4162" id="4162" class="graf graf--p graf-after--p">d1. When an unbound thread exits and there are no more RUNNABLE threads, the LWP becomes __________.</p><p name="6ea1" id="6ea1" class="graf graf--p graf-after--p">d2. When an unbound thread becomes blocked and there are no more RUNNABLE threads, the LWP becomes __________.</p><p name="b1c2" id="b1c2" class="graf graf--p graf-after--p">d3. When an bound thread blocks on a process-local synchronization variable, the LWP must __________.</p><p name="e9b5" id="e9b5" class="graf graf--p graf-after--p">Ans:</p><pre name="b98e" id="b98e" class="graf graf--pre graf-after--p">a1. 1:1<br>a2. M:N<br>a3. 1:1<br>a4. M:N</pre><pre name="08a9" id="08a9" class="graf graf--pre graf-after--pre">b1. Multithreading<br>b2. Visibility<br>b3. Synchronization</pre><pre name="f6a0" id="f6a0" class="graf graf--pre graf-after--pre">c1. DISPATCH<br>c2. SLEEP<br>c3. DISPATCH</pre><pre name="2e88" id="2e88" class="graf graf--pre graf-after--pre graf--trailing">d1. IDLE<br>d2. PARK         // note that PARK is faster than IDLE<br>d3. PARK</pre></div></div></section><section name="5f60" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="d3a0" id="d3a0" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">6. The Flash Paper </strong>/* a bug in this line, if you can see this, just ignore*/</p><p name="adad" id="adad" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">6. The Flash Paper</strong></p><p name="ba78" id="ba78" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Summary of Different Servers</strong></p><p name="1da2" id="1da2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">a. SPED</strong></p><ul class="postList"><li name="3081" id="3081" class="graf graf--li graf-after--p">Perfect for the situation when cache/memory resource is large</li><li name="112e" id="112e" class="graf graf--li graf-after--li">Perfect for requesting a single small file many times (Cache hit, best case numbers)</li><li name="c8e4" id="c8e4" class="graf graf--li graf-after--li">Good for requesting different small files (Owlnet trace, some I/O blockings)</li><li name="4dc7" id="4dc7" class="graf graf--li graf-after--li">Bad for requesting different large files (CS trace, many I/O lockings)</li><li name="5594" id="5594" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">I/O operation blocking</strong> issues add overheads (only for cache miss)</li><li name="16df" id="16df" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Can’t make full use of multicores</strong> (only one event dispatcher process)</li></ul><p name="5da8" id="5da8" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">b. Flash (AMPED)</strong></p><ul class="postList"><li name="a44c" id="a44c" class="graf graf--li graf-after--p">Perfect for requesting different small/large files</li><li name="c189" id="c189" class="graf graf--li graf-after--li">Not good for requesting a single small file many times (<strong class="markup--strong markup--li-strong">add cache checking overheads for helpers</strong>)</li><li name="753e" id="753e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Can’t make full use of multicores</strong> (only one event dispatcher process)</li></ul><p name="cc10" id="cc10" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">c. MP</strong></p><ul class="postList"><li name="567f" id="567f" class="graf graf--li graf-after--p">Good for multicore architectures (e.g. a quad-core platform, not perfect because the <strong class="markup--strong markup--li-strong">memory cost for MP is higher than MT</strong>)</li><li name="0037" id="0037" class="graf graf--li graf-after--li">Cost for <strong class="markup--strong markup--li-strong">context switching</strong></li><li name="3d4c" id="3d4c" class="graf graf--li graf-after--li">Cost for <strong class="markup--strong markup--li-strong">synchronization </strong>tools (e.g. mutex, condition variable)</li><li name="b93a" id="b93a" class="graf graf--li graf-after--li">Cost for process execution contexts in <strong class="markup--strong markup--li-strong">memory</strong> (more cache for process execution contexts, less cache for the file data)</li></ul><p name="8419" id="8419" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">d. MT</strong></p><ul class="postList"><li name="d5e0" id="d5e0" class="graf graf--li graf-after--p">Perfect for multicore architectures (e.g. a quad-core platform)</li><li name="1745" id="1745" class="graf graf--li graf-after--li">Cost for<strong class="markup--strong markup--li-strong"> context switching</strong></li><li name="b5ad" id="b5ad" class="graf graf--li graf-after--li">Cost for <strong class="markup--strong markup--li-strong">synchronization</strong> tools (e.g. mutex, condition variable)</li><li name="3ab4" id="3ab4" class="graf graf--li graf-after--li">Cost for process execution contexts in <strong class="markup--strong markup--li-strong">memory</strong> (more cache for process execution contexts, less cache for the file data)</li></ul><p name="81f8" id="81f8" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">e. Zeus</strong> (SPED model with 2 processes)</p><ul class="postList"><li name="7b1d" id="7b1d" class="graf graf--li graf-after--p">Cost for some misalignment for some of the DMA operations</li></ul><p name="82b3" id="82b3" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">f. Apache </strong>(an unoptimized MP configuration)</p><ul class="postList"><li name="ef21" id="ef21" class="graf graf--li graf-after--p">Worst because it doesn’t have any optimizations that the others implement</li></ul><p name="a79d" id="a79d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Advanced Implementation AMTED</strong></p><p name="e701" id="e701" class="graf graf--p graf-after--p">If we convert the AMPED model to the AMTED (async multi-threaded event-driven) model, we can expect that the performance will be improved because the cost for thread memory and the cost for thread context switch is much lower. This is actually a follow on work that actually does to the Flash.</p><p name="8a14" id="8a14" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 6-1</strong>. Here is a graph from the paper <a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-pai-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-pai-paper.pdf" class="markup--anchor markup--p-anchor" rel="noreferrer noopener noopener" target="_blank"><em class="markup--em markup--p-em">Flash: An Efficient and Portable Web Server</em></a>, that compares the performance of Flash with other web servers.</p><figure name="e8ad" id="e8ad" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1WYEOc82oyBowtTVLZn2bA.png" data-width="1182" data-height="442" src="https://cdn-images-1.medium.com/max/800/1*1WYEOc82oyBowtTVLZn2bA.png"></figure><p name="ed2a" id="ed2a" class="graf graf--p graf-after--figure">For data sets <strong class="markup--strong markup--p-strong">where the data set size is less than 100 MB</strong> why does,</p><p name="b260" id="b260" class="graf graf--p graf-after--p">a. Flash perform worse than SPED?</p><p name="a2d3" id="a2d3" class="graf graf--p graf-after--p">b. Flash perform better than MP?</p><p name="7d22" id="7d22" class="graf graf--p graf-after--p">For data sets <strong class="markup--strong markup--p-strong">where the data set size is greater than 100 MB</strong> why does,</p><p name="5863" id="5863" class="graf graf--p graf-after--p">c. Flash perform better than SPED?</p><p name="38a3" id="38a3" class="graf graf--p graf-after--p">d. Flash perform better than MP?</p><p name="3052" id="3052" class="graf graf--p graf-after--p">Ans:</p><pre name="d2dd" id="d2dd" class="graf graf--pre graf-after--p">// a. <br>In both cases the dataset will likely fit in cache, but Flash incurs an overhead on each request because Flash must first <strong class="markup--strong markup--pre-strong">check for cache residency</strong>. In the SPED model, this check is not performed.</pre><pre name="655d" id="655d" class="graf graf--pre graf-after--pre">// b. <br>When data is present in the cache, there is no need for slow disk I/O operations. Adding threads or processes just <strong class="markup--strong markup--pre-strong">adds context switching and extra synchronization</strong> <strong class="markup--strong markup--pre-strong">overheads</strong>, but there is no benefit of “hiding I/O latency”.</pre><pre name="4fbd" id="4fbd" class="graf graf--pre graf-after--pre">// c. <br>Because the dataset is large, it is not likely to fit in cache, and thus, the <strong class="markup--strong markup--pre-strong">blocking I/O</strong> is required. Given the blocking I/O possibility SPED will occasionally block since the SPED does not support asynchronous I/O operations, whereas in Flash the helper processes will resolve the problem, we will therefore achieve a better result for the Flash.</pre><pre name="11dc" id="11dc" class="graf graf--pre graf-after--pre">// d.<br>When we should read from the memory, there is some needs for context switching to hide the I/O latency. However, the MP has a <strong class="markup--strong markup--pre-strong">larger  memory footprint</strong>, which leads to less memories for caching files. So Flash performs better than MP.</pre><p name="86ec" id="86ec" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 6-2</strong>. DELETED</p><p name="6db9" id="6db9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 6-3</strong>. If we have the MT GETFILE server for the project 1 and it is used for two differences,</p><ul class="postList"><li name="0179" id="0179" class="graf graf--li graf-after--p">(i) many requests for a single file</li><li name="3997" id="3997" class="graf graf--li graf-after--li">(ii) many random requests across a very large pool of very large files</li></ul><p name="7377" id="7377" class="graf graf--p graf-after--li">Sketch 2 hypothetical graphs for each of these two situations. One graph is used to show the average execution time for a request against the number of threads, the other is to show the average respond time for a request against the number of threads.</p><p name="96ac" id="96ac" class="graf graf--p graf-after--p">Ans:</p><p name="fcf6" id="fcf6" class="graf graf--p graf-after--p">For situation (i),</p><p name="3e90" id="3e90" class="graf graf--p graf-after--p">The file will be out of the cache and we have to do I/O operations if we keep increasing the number of the threads. This is because the execution contexts of threads take up the memory for the file. Thus, the average execution time will be higher when we need to conduct I/O operations.</p><figure name="65f6" id="65f6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qcDSKIM_9aCRO49LKavOGg.png" data-width="1840" data-height="392" src="https://cdn-images-1.medium.com/max/800/1*qcDSKIM_9aCRO49LKavOGg.png"></figure><p name="5606" id="5606" class="graf graf--p graf-after--figure">For situation (ii),</p><p name="2b6f" id="2b6f" class="graf graf--p graf-after--p">Because all the files are not fitted in cache initially and we have to operate I/O for each of them. So the average execution time and the average respond time will be higher at the beginning. But thanks to the help of increasing number of threads, we can finally have a relatively low average responding time because of concurrency.</p><figure name="3b61" id="3b61" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*UwLD-pEk-iQZD1_eUINC_w.png" data-width="1840" data-height="392" src="https://cdn-images-1.medium.com/max/800/1*UwLD-pEk-iQZD1_eUINC_w.png"></figure></div></div></section><section name="dd29" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="89c6" id="89c6" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">7. Interrupts and Signals</strong></p><p name="dd7b" id="dd7b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 7-1</strong>. Operating systems’ (e.g. in Linux or UNIX in general) signals are: (select all that apply)</p><ul class="postList"><li name="74f5" id="74f5" class="graf graf--li graf-after--p">an interface from the kernel to the user-level process</li><li name="6143" id="6143" class="graf graf--li graf-after--li">a synchronous notification mechanism from the kernel to a process or a thread within the process</li><li name="e076" id="e076" class="graf graf--li graf-after--li">an asynchronous notification mechanism from the kernel to a process or a thread within the process</li><li name="a96b" id="a96b" class="graf graf--li graf-after--li">a way to notify a user-level thread waiting on a condition variable</li><li name="4457" id="4457" class="graf graf--li graf-after--li">a way to notify many user-level threads waiting on a condition variable (e.g. via broadcast)</li><li name="cab7" id="cab7" class="graf graf--li graf-after--li">invented so that the kernel can engage the user-level threading library scheduler</li></ul><p name="451a" id="451a" class="graf graf--p graf-after--li">Ans:</p><pre name="1d24" id="1d24" class="graf graf--pre graf-after--p">- a synchronous notification mechanism from the kernel to a process or a thread within the process<br>- an asynchronous notification mechanism from the kernel to a process or a thread within the process<br>- invented so that the kernel can engage the user-level threading library scheduler     // no sure, needs clarify</pre><p name="8181" id="8181" class="graf graf--p graf-after--pre">Note the other definitions are for,</p><pre name="c40f" id="c40f" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">OS</strong> provides an interface from the kernel to the user-level process<br><strong class="markup--strong markup--pre-strong">PThread signal function</strong> provides a way to notify a user-level thread waiting on a condition variable<br><strong class="markup--strong markup--pre-strong">PThread broadcast function</strong> provides a way to notify many user-level threads waiting on a condition variable</pre><p name="7347" id="7347" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 7-2</strong>. Which of the following statements are TRUE. Select all that apply.</p><ul class="postList"><li name="60df" id="60df" class="graf graf--li graf-after--p">Each instruction trap triggers an interrupt</li><li name="95eb" id="95eb" class="graf graf--li graf-after--li">Peripherals may send interrupts to the processor</li><li name="cf3f" id="cf3f" class="graf graf--li graf-after--li">A timer interrupt is a trap</li><li name="43ee" id="43ee" class="graf graf--li graf-after--li">An external interrupt from a peripheral is called a trap</li><li name="c060" id="c060" class="graf graf--li graf-after--li">Software interrupts are interrupts sent to the processor by the software</li><li name="a202" id="a202" class="graf graf--li graf-after--li">Traps are being used for software interrupts</li><li name="3633" id="3633" class="graf graf--li graf-after--li">Interrupts can be used for transition from user mode to kernel mode</li><li name="8460" id="8460" class="graf graf--li graf-after--li">Interrupts can cause context switching</li></ul><pre name="7263" id="7263" class="graf graf--pre graf-after--li">T             // all traps are interrupts<br>T<br>F             // timer interrupts are not traps<br>F             // peripheral interrupts are not traps<br>F             // by hardware, caused by software<br>T<br>T<br>T</pre><p name="8d06" id="8d06" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 7-3</strong>. Which of the following statements are TRUE. Select all that apply.</p><ul class="postList"><li name="0cd5" id="0cd5" class="graf graf--li graf-after--p">Processes may send each other signals by IPC</li><li name="7598" id="7598" class="graf graf--li graf-after--li">Kernel may send signals internally</li><li name="e52b" id="e52b" class="graf graf--li graf-after--li">Each signal is maintained by a single bit</li><li name="4124" id="4124" class="graf graf--li graf-after--li">Linux syscall <code class="markup--code markup--li-code">kill</code> sends a signal</li><li name="7984" id="7984" class="graf graf--li graf-after--li">It is possible for an interrupt to result in a signal</li><li name="aadd" id="aadd" class="graf graf--li graf-after--li">Both of the signals and interrupts can be masked</li></ul><pre name="60b1" id="60b1" class="graf graf--pre graf-after--li">T<br>T<br>T<br>T<br>T        // e.g. divide by zero<br>T</pre><p name="adc3" id="adc3" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 7-4</strong>. Check all the components used for dealing with the signal mask visibility problem in each of the following situations. Note that <code class="markup--code markup--p-code">1 ULT (0)</code> means that we have 1 ULT with a signal mask of 0, and <code class="markup--code markup--p-code">2ULT (0,1)</code> means that we have 2 ULTs with signal masks of bit 0 and bit 1.</p><p name="2635" id="2635" class="graf graf--p graf-after--p">a. 1 ULT (0), 1 KLT (1)</p><ul class="postList"><li name="f0c8" id="f0c8" class="graf graf--li graf-after--p">a1. lightweight user-level threading library</li><li name="89dd" id="89dd" class="graf graf--li graf-after--li">a2. signal handler table</li><li name="1d29" id="1d29" class="graf graf--li graf-after--li">a3. signal handling routine</li><li name="70e8" id="70e8" class="graf graf--li graf-after--li">a4. system calls for changing signal masks</li><li name="6bda" id="6bda" class="graf graf--li graf-after--li">a5. schedular</li></ul><p name="c839" id="c839" class="graf graf--p graf-after--li">b. 2ULT (0, 1), 1KLT (1)</p><ul class="postList"><li name="af08" id="af08" class="graf graf--li graf-after--p">b1. lightweight user-level threading library</li><li name="cd85" id="cd85" class="graf graf--li graf-after--li">b2. signal handler table</li><li name="0b79" id="0b79" class="graf graf--li graf-after--li">b3. signal handling routine</li><li name="394e" id="394e" class="graf graf--li graf-after--li">b4. system calls for changing signal masks</li><li name="1e89" id="1e89" class="graf graf--li graf-after--li">b5. schedular</li></ul><p name="b149" id="b149" class="graf graf--p graf-after--li">c. 2ULT (0, 0), 2KLT (1, 1)</p><ul class="postList"><li name="7d3c" id="7d3c" class="graf graf--li graf-after--p">c1. lightweight user-level threading library</li><li name="fb3d" id="fb3d" class="graf graf--li graf-after--li">c2. signal handler table</li><li name="8de0" id="8de0" class="graf graf--li graf-after--li">c3. signal handling routine</li><li name="0af0" id="0af0" class="graf graf--li graf-after--li">c4. system calls for changing signal masks</li><li name="d5b0" id="d5b0" class="graf graf--li graf-after--li">c5. schedular</li></ul><p name="be30" id="be30" class="graf graf--p graf-after--li">d. 2ULT (0, 1), 2KLT (0, 0)</p><ul class="postList"><li name="9a9a" id="9a9a" class="graf graf--li graf-after--p">d1. lightweight user-level threading library</li><li name="fb76" id="fb76" class="graf graf--li graf-after--li">d2. signal handler table</li><li name="13f0" id="13f0" class="graf graf--li graf-after--li">d3. signal handling routine</li><li name="9465" id="9465" class="graf graf--li graf-after--li">d4. system calls for changing signal masks</li><li name="dd1c" id="dd1c" class="graf graf--li graf-after--li">d5. schedular</li></ul><p name="50de" id="50de" class="graf graf--p graf-after--li">Ans:</p><pre name="b619" id="b619" class="graf graf--pre graf-after--p">// a.<br>a1, a2, a3, a4</pre><pre name="0ca4" id="0ca4" class="graf graf--pre graf-after--pre">// b. <br>b1, b2, b3, b5</pre><pre name="207a" id="207a" class="graf graf--pre graf-after--pre">// c.<br>c1, c2, c3, c4</pre><pre name="6288" id="6288" class="graf graf--pre graf-after--pre graf--trailing">// d.<br>d1, d4</pre></div></div></section><section name="eda2" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="ba86" id="ba86" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">7. Linux and MacOS</strong></p><p name="b529" id="b529" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example 7-1</strong>. Specify TRUE (T) or FALSE (F) for the following statements.</p><ul class="postList"><li name="fe95" id="fe95" class="graf graf--li graf-after--p">The OS X has a hybrid kernel.</li><li name="2238" id="2238" class="graf graf--li graf-after--li">The PThread library of Linux follows the 1x1 mapping model.</li><li name="6d3f" id="6d3f" class="graf graf--li graf-after--li">Linux supports both one-shot signals and real-time signals.</li><li name="33c5" id="33c5" class="graf graf--li graf-after--li">Linux uses the <code class="markup--code markup--li-code">clone</code> call to create a thread</li><li name="99c3" id="99c3" class="graf graf--li graf-after--li">Linux uses the <code class="markup--code markup--li-code">fork</code> call to create a thread</li><li name="77b3" id="77b3" class="graf graf--li graf-after--li">Linux is a monolithic kernel</li><li name="48ad" id="48ad" class="graf graf--li graf-after--li">Linux can be modular</li><li name="f346" id="f346" class="graf graf--li graf-after--li">Linux forking in a thread will create a process with its address space same to the parent</li></ul><p name="7953" id="7953" class="graf graf--p graf-after--li">Ans:</p><pre name="48c4" id="48c4" class="graf graf--pre graf-after--p">T                // Mach and BSD<br>T<br>F                // only supports real-time signals<br>T<br>F                // fork is used to create new process<br>T<br>T                // Linux can be monolithic and modular<br>F                // Only a portion is copied</pre><p name="b7c5" id="b7c5" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Example 7-2</strong>. On a 64-bit Linux-based OS, which system call is used to,</p><ul class="postList"><li name="b30a" id="b30a" class="graf graf--li graf-after--p">Create a process ____________</li><li name="a17c" id="a17c" class="graf graf--li graf-after--li">Replace the execution context of the current process ____________</li><li name="b578" id="b578" class="graf graf--li graf-after--li">Send a signal to terminate a process ____________</li><li name="4859" id="4859" class="graf graf--li graf-after--li">Determine the termination of child process ___________</li></ul><p name="1462" id="1462" class="graf graf--p graf-after--li">Ans:</p><pre name="1bc3" id="1bc3" class="graf graf--pre graf-after--p graf--trailing">fork<br>exec<br>kill<br>wait</pre></div></div></section><section name="82dc" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="1fe8" id="1fe8" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">8. More Details</strong></p><p name="eaf6" id="eaf6" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) User-Kernel Mode Crossing</strong></p><ul class="postList"><li name="d6b6" id="d6b6" class="graf graf--li graf-after--p">Step 1-1. Start with the user mode (code = 1)</li><li name="3598" id="3598" class="graf graf--li graf-after--li">Step 1-2. UL process needs a hardware access, raise a system call</li><li name="54fa" id="54fa" class="graf graf--li graf-after--li">Step 1-3. UL process passes arguments and data to that system call</li><li name="15a0" id="15a0" class="graf graf--li graf-after--li">Step 2-1. Change the code to kernel/privileged mode (code = 0)</li><li name="a08d" id="a08d" class="graf graf--li graf-after--li">Step 2-2. Kernel sees the system call and get its arguments and data</li><li name="f4d0" id="f4d0" class="graf graf--li graf-after--li">Step 2-3. Kernel context switch to the location of the system call and execute it</li><li name="5e98" id="5e98" class="graf graf--li graf-after--li">Step 2-4. Kernel returns the result to the UL process and context switch to its original content</li><li name="c5d8" id="c5d8" class="graf graf--li graf-after--li">Step 1-4. Change the code to user mode (code = 1)</li></ul><figure name="187a" id="187a" class="graf graf--figure graf-after--li graf--trailing"><img class="graf-image" data-image-id="1*VXmwTViqeC6LvQCBBvOTrQ.png" data-width="2144" data-height="532" src="https://cdn-images-1.medium.com/max/800/1*VXmwTViqeC6LvQCBBvOTrQ.png"></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/a18d77561476"><time class="dt-published" datetime="2021-03-05T18:56:07.850Z">March 5, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/operating-system-15-midterm-review-a18d77561476" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>