<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Intro to Machine Learning 10 | Lab Review</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Intro to Machine Learning 10 | Lab Review</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Intro to Machine Learning
</section>
<section data-field="body" class="e-content">
<section name="1e8a" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="5956" id="5956" class="graf graf--h3 graf--leading graf--title">Intro to Machine Learning 10 | Lab Review</h3><figure name="568d" id="568d" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*TvFAe8LcyOO7QT_a.png" data-width="1250" data-height="700" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*TvFAe8LcyOO7QT_a.png"></figure><ol class="postList"><li name="06db" id="06db" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Machine Learning Settings</strong></li></ol><p name="5f25" id="5f25" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) What are two supervised learning settings?</strong></p><p name="494d" id="494d" class="graf graf--p graf-after--p">Ans: Classification and regression</p><p name="fb3b" id="fb3b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Briefly explain the train set, validation set, and test set.</strong></p><p name="700f" id="700f" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="7336" id="7336" class="graf graf--li graf-after--p">train set: part of the dataset for training data</li><li name="043b" id="043b" class="graf graf--li graf-after--li">validation set: part of the dataset for selecting models</li><li name="912d" id="912d" class="graf graf--li graf-after--li">test set: part of the dataset for estimating error</li></ul><p name="3e1e" id="3e1e" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) How to get a generalization error for a selected model?</strong></p><p name="1aea" id="1aea" class="graf graf--p graf-after--p">Ans: By computing error on a large independent test set.</p><p name="886d" id="886d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Give three examples of hyperparameters.</strong></p><p name="253c" id="253c" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="877e" id="877e" class="graf graf--li graf-after--p">Learning rate</li><li name="2d8b" id="2d8b" class="graf graf--li graf-after--li">Depth of tree</li><li name="cd2c" id="cd2c" class="graf graf--li graf-after--li">Number of clusters <em class="markup--em markup--li-em">k</em></li><li name="0507" id="0507" class="graf graf--li graf-after--li">etc.</li></ul><p name="7ff6" id="7ff6" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) What are the two transforms of a standard scaler?</strong></p><p name="fc0b" id="fc0b" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="b92d" id="b92d" class="graf graf--li graf-after--p">Zero out mean</li><li name="3101" id="3101" class="graf graf--li graf-after--li">Scale to unit variance</li></ul><p name="566c" id="566c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(6) Suppose we have the following data after standard scaling, then what is the problem and what should be the solution?</strong></p><figure name="16d5" id="16d5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*nIRFXbosJCt2W5Q8Fh0eTg.png" data-width="860" data-height="237" src="https://cdn-images-1.medium.com/max/800/1*nIRFXbosJCt2W5Q8Fh0eTg.png"></figure><p name="0c9a" id="0c9a" class="graf graf--p graf-after--figure">Ans:</p><ul class="postList"><li name="99ae" id="99ae" class="graf graf--li graf-after--p">Problem: The feature x1 is heavy-tailed</li><li name="5dd6" id="5dd6" class="graf graf--li graf-after--li">Solution: Log transformation before scaling</li></ul><p name="3c03" id="3c03" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(7) Suppose we are given the train set X1, the validation set X2, and the test set X3. Then which dataset we should use for scaling each of these sets?</strong></p><p name="de1b" id="de1b" class="graf graf--p graf-after--p">Ans: X1</p><p name="837b" id="837b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(8) Give three types of models that we must scale data before modeling.</strong></p><p name="6363" id="6363" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="013a" id="013a" class="graf graf--li graf-after--p">Linear models</li><li name="0881" id="0881" class="graf graf--li graf-after--li">Neural networks</li><li name="4c01" id="4c01" class="graf graf--li graf-after--li">Clustering (e.g. nearest neighbor type)</li></ul><p name="f694" id="f694" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(9) When is scaling not necessary?</strong></p><p name="f0db" id="f0db" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="c2e0" id="c2e0" class="graf graf--li graf-after--p">The data is initially scaled</li><li name="3b6b" id="3b6b" class="graf graf--li graf-after--li">The model is tree-based</li></ul><p name="5686" id="5686" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(10) What does it mean to fit a model?</strong></p><p name="bf76" id="bf76" class="graf graf--p graf-after--p">Ans: Finding the model parameters that will minimize the loss function</p><p name="85ee" id="85ee" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Model Assessment and Selection</strong></p><p name="58f0" id="58f0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) What should we do for the train-test split instead of the train-validation-test split on model selection?</strong></p><p name="0812" id="0812" class="graf graf--p graf-after--p">Ans: We should perform cross validation for the training set.</p><p name="876b" id="876b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) When do we use cross-validation instead of train-validation split?</strong></p><p name="a524" id="a524" class="graf graf--p graf-after--p">Ans: When the dataset is small.</p><p name="2f2a" id="2f2a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) When do we use the time-based split?</strong></p><p name="b035" id="b035" class="graf graf--p graf-after--p">Ans: When we have time-series data.</p><p name="6e0b" id="6e0b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) What is the purpose of regularization?</strong></p><p name="e859" id="e859" class="graf graf--p graf-after--p">Ans: Reduce overfitting.</p><p name="74c0" id="74c0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) How many times of train-validation split should we perform in a LOOCV?</strong></p><p name="8981" id="8981" class="graf graf--p graf-after--p">Ans: the number of observations.</p><p name="ab57" id="ab57" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Suppose we have a 3-fold cross validation of 600 observations. Then what is the size of training data in each iteration?</strong></p><p name="b119" id="b119" class="graf graf--p graf-after--p">Ans: 400</p><p name="7a49" id="7a49" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) When shall we use LOOCV or k-fold cross validation?</strong></p><p name="b5bf" id="b5bf" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="5157" id="5157" class="graf graf--li graf-after--p">Estimating test error</li><li name="8855" id="8855" class="graf graf--li graf-after--li">Model selection</li></ul><p name="b008" id="b008" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(8) What happens if we used the same data for both model selection and assessment?</strong></p><p name="3763" id="3763" class="graf graf--p graf-after--p">Ans: It will result in an optimistic estimate of the model’s error</p><p name="1dba" id="1dba" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(9) How can we select a model if we have an extremely small dataset?</strong></p><p name="a933" id="a933" class="graf graf--p graf-after--p">Ans: Consider nested cross-validation.</p><p name="8521" id="8521" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(10) What is the difference between grid search and random search?</strong></p><p name="25ce" id="25ce" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="98ab" id="98ab" class="graf graf--li graf-after--p">Random search is a subset of grid search used for a speed purpose</li><li name="6106" id="6106" class="graf graf--li graf-after--li">They are commonly as accurate</li></ul><p name="9fb3" id="9fb3" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(11) How to get a confidence interval for model error if we have a small dataset?</strong></p><p name="be97" id="be97" class="graf graf--p graf-after--p">Ans: Bootstrapping M times for error estimates</p><p name="5c32" id="5c32" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(12) Why do we have to scale inside the cross-validation loop?</strong></p><p name="ddd4" id="ddd4" class="graf graf--p graf-after--p">Ans: Because we have to use the real training data to find the scaling parameters</p><p name="3850" id="3850" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(13) Why we must scale the data for regularization?</strong></p><p name="e8eb" id="e8eb" class="graf graf--p graf-after--p">Ans: Because otherwise, the regularization will be unfair</p><p name="fb89" id="fb89" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Encoding and Feature Engineering</strong></p><p name="ff04" id="ff04" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Why dropping columns is not a recommended solution for missing values?</strong></p><p name="a06c" id="a06c" class="graf graf--p graf-after--p">Ans: Because it loses information.</p><p name="5d4a" id="5d4a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Why do imputation and adding a column for missing values work?</strong></p><p name="1c66" id="1c66" class="graf graf--p graf-after--p">Ans: Because these values may not miss at random.</p><p name="3d48" id="3d48" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Given three imputation techniques.</strong></p><p name="503f" id="503f" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="6e2d" id="6e2d" class="graf graf--li graf-after--p">Use mean or median for numerical data</li><li name="43d8" id="43d8" class="graf graf--li graf-after--li">Use the most common value for categorical data</li><li name="2f99" id="2f99" class="graf graf--li graf-after--li">Use prediction by fitting the model with the imputed variable as the target</li><li name="1d96" id="1d96" class="graf graf--li graf-after--li">etc.</li></ul><p name="a575" id="a575" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) What is the definition of normal outliers?</strong></p><p name="ca9f" id="ca9f" class="graf graf--p graf-after--p">Ans: They are data points</p><pre name="f25d" id="f25d" class="graf graf--pre graf-after--p">&gt; 1.5 * IQR + Q3 or &lt; Q1 - 1.5 * IQR</pre><p name="9a46" id="9a46" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(5) Why outliers can be a problem?</strong></p><p name="f472" id="f472" class="graf graf--p graf-after--p">Ans: They can have an effect on models</p><p name="57a1" id="57a1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) What are the solutions for outliers?</strong></p><p name="aa3f" id="aa3f" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="304d" id="304d" class="graf graf--li graf-after--p">Dropping</li><li name="5ada" id="5ada" class="graf graf--li graf-after--li">Imputing</li><li name="5ff5" id="5ff5" class="graf graf--li graf-after--li">Capping</li></ul><p name="8b6c" id="8b6c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(7) Let’s say we have a feature with a variance of 0.003. When should we exclude it in the model?</strong></p><p name="f88e" id="f88e" class="graf graf--p graf-after--p">Ans: When we have linear models or neural networks. (Or when we have non-tree-based models.)</p><p name="b4e4" id="b4e4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(8) What are the different ways in which we can encode categorical variables? When do you use them?</strong></p><p name="7a2f" id="7a2f" class="graf graf--p graf-after--p">Ans: One hot encoding and the hashing trick are used for logistic regression, regression, and neural networks while label encoding can be used for any tree-based algorithm like random forest or gradient boosting.</p><p name="5ed8" id="5ed8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(9) Why the SGDClassifier function is faster than LogisticRegression?</strong></p><p name="d287" id="d287" class="graf graf--p graf-after--p">Ans: Because LogisticRegression uses all the data to compute one step of gradient descent while SGDClassifier uses just one observation.</p><p name="00a4" id="00a4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">4. Losses and Metrics</strong></p><p name="e854" id="e854" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) When do we use MAE instead of MSE?</strong></p><p name="6c29" id="6c29" class="graf graf--p graf-after--p">Ans: when we have outliers</p><p name="e58d" id="e58d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) When do we use RMSE instead of MAE?</strong></p><p name="430c" id="430c" class="graf graf--p graf-after--p">Ans: When we want a higher weight/punishment for large errors.</p><p name="9064" id="9064" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Define the cross-entropy loss that is often used with neural networks based classifiers.</strong></p><p name="7be1" id="7be1" class="graf graf--p graf-after--p">a) Write the expression for binary classification problems.</p><p name="afc4" id="afc4" class="graf graf--p graf-after--p">b) Write the expression for multi-class classification problems</p><p name="2c32" id="2c32" class="graf graf--p graf-after--p">Ans:</p><p name="ad0f" id="ad0f" class="graf graf--p graf-after--p">a)</p><figure name="b2fb" id="b2fb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wdfyRMuoVfBC-3svo_0NXQ.png" data-width="1342" data-height="122" src="https://cdn-images-1.medium.com/max/800/1*wdfyRMuoVfBC-3svo_0NXQ.png"></figure><p name="cc22" id="cc22" class="graf graf--p graf-after--figure">b)</p><figure name="0ca4" id="0ca4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jADb_SOa7kuoL17DnmA29Q.png" data-width="1342" data-height="122" src="https://cdn-images-1.medium.com/max/800/1*jADb_SOa7kuoL17DnmA29Q.png"></figure><p name="5d67" id="5d67" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Suppose we have an email with the true label Ham. </strong>However, the soft prediction of this email is (Ham, Spam) = (0.3, 0.7). Then what is the log loss in this prediction?</p><p name="b397" id="b397" class="graf graf--p graf-after--p">Ans:</p><pre name="341a" id="341a" class="graf graf--pre graf-after--p"># Suppose Ham = 1 and Spam = 0<br>logloss = -(log0.3) = log3.33</pre><pre name="ae12" id="ae12" class="graf graf--pre graf-after--pre"># Suppose Ham = 0 and Spam = 1<br>logloss = -(log0.7) = log(10/7)</pre><p name="5072" id="5072" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(8) Suppose we classify pictures in classes Piazza, Cake, and Cookie and we have the following three soft predictions,</strong></p><ul class="postList"><li name="4222" id="4222" class="graf graf--li graf-after--p">Pred = (0.2, 0.1, 0.7), True = (0, 0, 1)</li><li name="2ffd" id="2ffd" class="graf graf--li graf-after--li">Pred = (0.1, 0.5, 0.4), True = (0, 0, 1)</li><li name="a74c" id="a74c" class="graf graf--li graf-after--li">Pred = (0.6, 0.2, 0.2), True = (1, 0, 0)</li></ul><p name="1a64" id="1a64" class="graf graf--p graf-after--li">Compute the entire logloss for these predictions.</p><p name="ccc5" id="ccc5" class="graf graf--p graf-after--p">Ans: We only need to care about the prediction with true value 1</p><pre name="788d" id="788d" class="graf graf--pre graf-after--p">logloss = (-log0.7 - log0.4 - log0.6) / 3</pre><p name="d501" id="d501" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(9)</strong> <strong class="markup--strong markup--p-strong">Suppose we classify pictures in labels Mountain, Lake, and Forest and we have the following three soft predictions,</strong></p><ul class="postList"><li name="4c56" id="4c56" class="graf graf--li graf-after--p">Pred = (0.9, 0.7, 0.7), True = (1, 0, 1)</li><li name="9e64" id="9e64" class="graf graf--li graf-after--li">Pred = (0.1, 0.6, 0.7), True = (0, 1, 1)</li><li name="2d13" id="2d13" class="graf graf--li graf-after--li">Pred = (0.7, 0.9, 0.5), True = (1, 1, 1)</li></ul><p name="0171" id="0171" class="graf graf--p graf-after--li">Compute the entire logloss for these predictions.</p><p name="4eda" id="4eda" class="graf graf--p graf-after--p">Ans: We have to flip the label to all ones,</p><ul class="postList"><li name="0634" id="0634" class="graf graf--li graf-after--p">Pred = (0.9, 0.3, 0.7), True = (1, 1, 1)</li><li name="7d5d" id="7d5d" class="graf graf--li graf-after--li">Pred = (0.9, 0.6, 0.7), True = (1, 1, 1)</li><li name="4f82" id="4f82" class="graf graf--li graf-after--li">Pred = (0.7, 0.9, 0.5), True = (1, 1, 1)</li></ul><p name="be81" id="be81" class="graf graf--p graf-after--li">Then we can calculate the log-loss by,</p><pre name="222d" id="222d" class="graf graf--pre graf-after--p">logloss = (-log0.9 - log0.3 - log0.7<br>           -log0.9 - log0.6 - log0.7<br>           -log0.7 - log0.9 - log0.5) / 3</pre><p name="e9ce" id="e9ce" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(10) Suppose we have the following soft predictions,</strong></p><pre name="6b6d" id="6b6d" class="graf graf--pre graf-after--p">pred   0.0    0.7    0.4     0.3     0.1     0.6     0.8     0.2<br>y       0      1      0       1       1       1       0       0</pre><p name="f350" id="f350" class="graf graf--p graf-after--pre">a) What is the confusion matrix if the threshold is 0.3?</p><p name="ed41" id="ed41" class="graf graf--p graf-after--p">b) What should be the sensitivity, precision, accuracy, false-positive rate when the threshold is 0.3?</p><p name="5f7c" id="5f7c" class="graf graf--p graf-after--p">c) What should be the F1 score and Fβ score when the threshold is 0.3 and β is 2?</p><p name="4bb2" id="4bb2" class="graf graf--p graf-after--p">d) Compute the AUC score.</p><p name="c2ad" id="c2ad" class="graf graf--p graf-after--p">e) With the threshold from 0.1, 0.3, 0.5, 0.9, draw a ROC curve, calculate AUROC.</p><p name="a865" id="a865" class="graf graf--p graf-after--p">f) With the threshold from 0.1, 0.3, 0.5, 0.9, draw a PR curve, calculate AUPRC.</p><p name="b265" id="b265" class="graf graf--p graf-after--p">Ans: The hard prediction is,</p><pre name="beaf" id="beaf" class="graf graf--pre graf-after--p">hard    0      1      1       1       0      1       1       0</pre><p name="0cdf" id="0cdf" class="graf graf--p graf-after--pre">Then,</p><pre name="1180" id="1180" class="graf graf--pre graf-after--p">TP = 3<br>TN = 2<br>FP = 2<br>FN = 1</pre><p name="450d" id="450d" class="graf graf--p graf-after--pre">Then the confusion matrix should be,</p><pre name="6c01" id="6c01" class="graf graf--pre graf-after--p">+------------------+------------------+<br>|                  |                  |<br>|                  |                  |<br>|        2         |         2        |   0<br>|                  |                  |<br>|                  |                  |<br>+------------------+------------------+       True<br>|                  |                  |<br>|                  |                  |<br>|        1         |         3        |   1<br>|                  |                  |<br>|                  |                  |<br>+------------------+------------------+<br>         0                   1<br>                Predict</pre><p name="726b" id="726b" class="graf graf--p graf-after--pre">b) We have,</p><pre name="f4b9" id="f4b9" class="graf graf--pre graf-after--p">sensitivity = 3/4 = 0.75<br>precision = 3/5 = 0.6<br>accuracy = 5/8 = 0.625<br>false-positive rate = 2/4 = 0.5</pre><p name="08a7" id="08a7" class="graf graf--p graf-after--pre">c) We have,</p><pre name="858c" id="858c" class="graf graf--pre graf-after--p">F1 = 2 * 1 / (1/0.6 + 1/0.75) = 2/3<br>Fβ = (1+4) * 0.6 * 0.75 / (4 * 0.6 + 0.75) <br>   = 2.25 / 3.15 = 0.71</pre><p name="165d" id="165d" class="graf graf--p graf-after--pre">d) Sort it then,</p><pre name="ee5f" id="ee5f" class="graf graf--pre graf-after--p">pred   0.0    0.1    0.2     0.3     0.4     0.6     0.7     0.8<br>y       0      1      0       1       0       1       1       0</pre><p name="870f" id="870f" class="graf graf--p graf-after--pre">In total, we have the number of pairs as,</p><pre name="6efb" id="6efb" class="graf graf--pre graf-after--p"># of pairs = 4 * 4 = 16</pre><p name="4b35" id="4b35" class="graf graf--p graf-after--pre">Misordered pairs should be,</p><pre name="80f8" id="80f8" class="graf graf--pre graf-after--p"># of misordered pairs = 7</pre><p name="cf18" id="cf18" class="graf graf--p graf-after--pre">So the AUC should be,</p><pre name="6842" id="6842" class="graf graf--pre graf-after--p">AUC = # of ordered pairs / # of pairs = 9/16</pre><p name="8559" id="8559" class="graf graf--p graf-after--pre">e) The FPRs and TPRs for each threshold are</p><pre name="d14c" id="d14c" class="graf graf--pre graf-after--p">threshold                 FPR                    TPR                     <br>0.9                       0.00                   0.00<br>0.5                       0.25                   0.50<br>0.3                       0.50                   0.75<br>0.1                       0.75                   1.00</pre><p name="f55f" id="f55f" class="graf graf--p graf-after--pre">Then the ROC curve is,</p><figure name="c39e" id="c39e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Fks4lTeaL7KkIJi0CHpW6w.png" data-width="1126" data-height="336" src="https://cdn-images-1.medium.com/max/800/1*Fks4lTeaL7KkIJi0CHpW6w.png"></figure><p name="2e0d" id="2e0d" class="graf graf--p graf-after--figure">The AUROC score is 0.6875.</p><p name="dc93" id="dc93" class="graf graf--p graf-after--p">f) The recalls and precisions for each threshold are</p><pre name="15a3" id="15a3" class="graf graf--pre graf-after--p">threshold               recall                 precision                     <br>0.9                     0.00                   1.00<br>0.5                     0.50                   0.67<br>0.3                     0.75                   0.60<br>0.1                     1.00                   0.57</pre><figure name="96e2" id="96e2" class="graf graf--figure graf-after--pre"><img class="graf-image" data-image-id="1*Rn3rwREsls-sRyEFHqVL2A.png" data-width="1080" data-height="306" src="https://cdn-images-1.medium.com/max/800/1*Rn3rwREsls-sRyEFHqVL2A.png"><figcaption class="imageCaption">Note: edge case precision 0/0 should be taken as 1</figcaption></figure><p name="cd19" id="cd19" class="graf graf--p graf-after--figure">The AUPRC score is 0.7217.</p><p name="891e" id="891e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">5. Bias and Variance</strong></p><p name="21c3" id="21c3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Explain underfitting and overfitting.</strong></p><p name="2d58" id="2d58" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="1b34" id="1b34" class="graf graf--li graf-after--p">Underfitting: model is not able to capture the relationship between the input and the target</li><li name="2dec" id="2dec" class="graf graf--li graf-after--li">Overfitting: model learns details and noise of the training data to the extent that negatively impacts the performance of new data</li></ul><p name="9e80" id="9e80" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) What’s the meaning of model complexity?</strong></p><p name="dbec" id="dbec" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="cadc" id="cadc" class="graf graf--li graf-after--p">Number of features and parameters</li><li name="6e74" id="6e74" class="graf graf--li graf-after--li">Linear or non-linear model</li><li name="9d49" id="9d49" class="graf graf--li graf-after--li">Amount of regularization</li></ul><p name="a255" id="a255" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) How to decrease bias?</strong></p><p name="7161" id="7161" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="b34a" id="b34a" class="graf graf--li graf-after--p">Increase parameters</li><li name="bd7d" id="bd7d" class="graf graf--li graf-after--li">Increase complexity</li><li name="7a2b" id="7a2b" class="graf graf--li graf-after--li">Decrease regularization</li></ul><p name="ab6d" id="ab6d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) How to decrease variance?</strong></p><p name="806e" id="806e" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="c460" id="c460" class="graf graf--li graf-after--p">Decrease parameters</li><li name="6b27" id="6b27" class="graf graf--li graf-after--li">Decrease model complexity</li><li name="5b2a" id="5b2a" class="graf graf--li graf-after--li">Increase regularization</li></ul><p name="e894" id="e894" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) Consider the following <em class="markup--em markup--p-em">k</em>NN model. What’s wrong and how we can modify this model?</strong></p><figure name="d25a" id="d25a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*79VaJuFmdOlARtNhAk6EhQ.png" data-width="1100" data-height="374" src="https://cdn-images-1.medium.com/max/800/1*79VaJuFmdOlARtNhAk6EhQ.png"></figure><p name="eba5" id="eba5" class="graf graf--p graf-after--figure">Ans:</p><ul class="postList"><li name="61cd" id="61cd" class="graf graf--li graf-after--p">This model is overfitting with high variance and low bias</li><li name="4591" id="4591" class="graf graf--li graf-after--li">We can improve this model by increasing k</li></ul><p name="dace" id="dace" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(6) What is the effect of increasing the regularization parameter?</strong></p><p name="3a1b" id="3a1b" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="ec0c" id="ec0c" class="graf graf--li graf-after--p">Increase the bias</li><li name="7a25" id="7a25" class="graf graf--li graf-after--li">Decrease the variance</li></ul><p name="261d" id="261d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(7) Which one has a higher bias, a shallow decision tree or a fully grown decision tree?</strong></p><p name="b3fe" id="b3fe" class="graf graf--p graf-after--p">Ans: a shallow decision tree</p><p name="cf15" id="cf15" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(8) How does bagging work for the random forest model?</strong></p><p name="ddb4" id="ddb4" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="21e4" id="21e4" class="graf graf--li graf-after--p">RF uses fully grown decision trees which is low bias, high variance</li><li name="8086" id="8086" class="graf graf--li graf-after--li">Bagging reduces variance by averaging the bootstrap samples</li></ul><p name="34f8" id="34f8" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(9) Which one is more likely to overfit, a high variance model or a high bias model?</strong></p><p name="cb18" id="cb18" class="graf graf--p graf-after--p">Ans: The high variance model</p><p name="1134" id="1134" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(10) Which one is more likely to underfit, a high variance model or a high bias model?</strong></p><p name="263a" id="263a" class="graf graf--p graf-after--p">Ans: The high bias model</p><p name="630e" id="630e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">6. Imbalanced Data</strong></p><p name="29f1" id="29f1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) What is the definition of an imbalanced dataset?</strong></p><p name="8c26" id="8c26" class="graf graf--p graf-after--p">Ans: Datasets where the positive class has far fewer observations than the negative class.</p><p name="f136" id="f136" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) What are the downsides of random undersampling?</strong></p><p name="ac87" id="ac87" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="41e6" id="41e6" class="graf graf--li graf-after--p">examples are removed independently on how useful they can be</li><li name="d53d" id="d53d" class="graf graf--li graf-after--li">useful information may be deleted</li></ul><p name="9c17" id="9c17" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Give three techniques of undersampling.</strong></p><p name="f045" id="f045" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="5881" id="5881" class="graf graf--li graf-after--p">Condensed Nearest Neighbor (CNN)</li><li name="7b6d" id="7b6d" class="graf graf--li graf-after--li">One-Side Selection</li><li name="ddfb" id="ddfb" class="graf graf--li graf-after--li">Edited Nearest Neighbor (ENN)</li><li name="4311" id="4311" class="graf graf--li graf-after--li">etc.</li></ul><p name="be3f" id="be3f" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Name two techniques of oversampling.</strong></p><p name="5c81" id="5c81" class="graf graf--p graf-after--p">Ans:</p><ul class="postList"><li name="0c65" id="0c65" class="graf graf--li graf-after--p">Random sampling</li><li name="5307" id="5307" class="graf graf--li graf-after--li">SMOTE</li></ul><p name="8928" id="8928" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) Why we should not use accuracy for measuring imbalanced data?</strong></p><p name="717c" id="717c" class="graf graf--p graf-after--p">Ans: Since it does not distinguish between the numbers of correctly classified examples of different classes, it may lead to erroneous conclusions.</p><p name="bcf0" id="bcf0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Why we should not use ROC-AUC for measuring imbalanced data?</strong></p><p name="702c" id="702c" class="graf graf--p graf-after--p graf--trailing">Ans: ROC-AUC can present an overly optimistic view of an algorithm’s performance if there is class imbalance.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/8e960f22d77f"><time class="dt-published" datetime="2021-12-15T18:09:56.969Z">December 15, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/intro-to-machine-learning-10-lab-review-8e960f22d77f" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>