<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Intro to Machine Learning 6 | Unsupervised Learning and Clustering</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Intro to Machine Learning 6 | Unsupervised Learning and Clustering</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Intro to Machine Learning
</section>
<section data-field="body" class="e-content">
<section name="27a4" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="a7c0" id="a7c0" class="graf graf--h3 graf--leading graf--title">Intro to Machine Learning 6 | Unsupervised Learning and Clustering</h3><figure name="2489" id="2489" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*MbuS_ssCeg-u9ZIG.png" data-width="1250" data-height="700" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*MbuS_ssCeg-u9ZIG.png"></figure><ol class="postList"><li name="8d09" id="8d09" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Unsupervised Learning Techniques</strong></li></ol><ul class="postList"><li name="3e28" id="3e28" class="graf graf--li graf-after--li">Principle Components Analysis</li><li name="2dce" id="2dce" class="graf graf--li graf-after--li">Page Rank</li><li name="a6d3" id="a6d3" class="graf graf--li graf-after--li">Word Embedding like glove</li><li name="879d" id="879d" class="graf graf--li graf-after--li">Anomaly detection</li></ul><p name="d93e" id="d93e" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">2. Common Unsupervised Learning Models</strong></p><ul class="postList"><li name="5044" id="5044" class="graf graf--li graf-after--p">Clustering: ùëò-means / ùëò-medians / ùëò-medoid / mean-shift</li><li name="2543" id="2543" class="graf graf--li graf-after--li">Hierarchical Clustering</li><li name="e594" id="e594" class="graf graf--li graf-after--li">Spectral Clustering</li><li name="088c" id="088c" class="graf graf--li graf-after--li">Collaborative Filtering</li></ul><p name="9a76" id="9a76" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">3. Clustering Problems</strong></p><ul class="postList"><li name="2973" id="2973" class="graf graf--li graf-after--p">Useful in specific circumstances like compression</li><li name="e89d" id="e89d" class="graf graf--li graf-after--li">Generally doesn‚Äôt work well with imbalanced data</li><li name="6937" id="6937" class="graf graf--li graf-after--li">No clear measure of success</li></ul><p name="3ff0" id="3ff0" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">4. Common Distances for Clustering</strong></p><ul class="postList"><li name="d0bd" id="d0bd" class="graf graf--li graf-after--p">We need to <strong class="markup--strong markup--li-strong">normalize <em class="markup--em markup--li-em">x</em></strong> values so distance means the same thing in all directions</li><li name="77a7" id="77a7" class="graf graf--li graf-after--li">Taxicab Distance: L1 distance for Euclidean space</li><li name="4a3e" id="4a3e" class="graf graf--li graf-after--li">Euclidean Distance: L2 distance for Euclidean space</li><li name="7add" id="7add" class="graf graf--li graf-after--li">Chebyshev Distance: L‚àû distance can also be useful</li><li name="df19" id="df19" class="graf graf--li graf-after--li">Cosine Similarity: angle Œ∏ between 2 vectors by cosine theorem, and the similarity should be 1-cos(Œ∏)</li></ul><p name="8222" id="8222" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">5. <em class="markup--em markup--p-em">k</em>-Means, <em class="markup--em markup--p-em">k</em>-Medians, and <em class="markup--em markup--p-em">k</em>-Medoids</strong></p><ul class="postList"><li name="e8bb" id="e8bb" class="graf graf--li graf-after--p">ùëò-means uses mean for centroids and centroids don‚Äôt have to be points in X</li><li name="61c5" id="61c5" class="graf graf--li graf-after--li"><em class="markup--em markup--li-em">k</em>-medians uses median not mean for centroids and it minimizes with respect to L1, not L2 distance</li><li name="5aff" id="5aff" class="graf graf--li graf-after--li"><em class="markup--em markup--li-em">k</em>-medoids requires medoids to be points in X and it will pick the centrally located point for each cluster</li></ul><p name="cf72" id="cf72" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">6. Troubles with ùëò-means</strong></p><ul class="postList"><li name="75f3" id="75f3" class="graf graf--li graf-after--p">Requires to specify <em class="markup--em markup--li-em">k</em>, which is usually difficult</li><li name="64dc" id="64dc" class="graf graf--li graf-after--li">Not stable: starting centroids can lead to different results</li><li name="e337" id="e337" class="graf graf--li graf-after--li graf--trailing">Hard predictions: would prefer to have soft predictions like probabilities</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/c67ca068a64"><time class="dt-published" datetime="2021-12-15T17:58:36.554Z">December 15, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/intro-to-machine-learning-6-unsupervised-learning-and-clustering-c67ca068a64" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>