<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>High-Performance Computer Architecture 4 | Metrics and Evaluation of Performance, Iron Law…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">High-Performance Computer Architecture 4 | Metrics and Evaluation of Performance, Iron Law…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: High-Performance Computer Architecture
</section>
<section data-field="body" class="e-content">
<section name="15ab" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="5315" id="5315" class="graf graf--h3 graf--leading graf--title">High-Performance Computer Architecture 4 | Metrics and Evaluation of Performance, <strong class="markup--strong markup--h3-strong">Iron Law, Amdahl’s Law, and Lhadma’s Law</strong></h3><figure name="9abb" id="9abb" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*aNb7yWK5UP6_5jRA.png" data-width="1446" data-height="864" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*aNb7yWK5UP6_5jRA.png"></figure><ol class="postList"><li name="ef4d" id="ef4d" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Performance Measurements</strong></li></ol><p name="41cc" id="41cc" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) The Definition of Latency and Throughput</strong></p><p name="527d" id="527d" class="graf graf--p graf-after--p">Usually, we say performance, we mean the “processor speed”. But even then, there are really two aspects of performance that are not necessarily identical. One is called <strong class="markup--strong markup--p-strong">latency</strong>, the other is called <strong class="markup--strong markup--p-strong">throughput</strong>.</p><ul class="postList"><li name="1bd1" id="1bd1" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Latency</strong>: How long does a thing take from when we start something until it’s done.</li><li name="aecf" id="aecf" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Throughput</strong>: How many things can we do per second.</li></ul><p name="82f3" id="82f3" class="graf graf--p graf-after--li">We will see why they are <strong class="markup--strong markup--p-strong">not identical</strong>.</p><p name="5ea5" id="5ea5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) The Relationship Between Latency and Throughput</strong></p><p name="572d" id="572d" class="graf graf--p graf-after--p">Some may think that the value of the throughput is actually 1 over latency, which is,</p><figure name="8d8f" id="8d8f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*3wr_lcDTMpl15TDl_RblLA.png" data-width="1070" data-height="122" src="https://cdn-images-1.medium.com/max/800/1*3wr_lcDTMpl15TDl_RblLA.png"></figure><p name="2f62" id="2f62" class="graf graf--p graf-after--figure">However, this is <strong class="markup--strong markup--p-strong">NOT right</strong>. Let’s think about an example. Suppose we have a task that has a latency of 4 seconds. Then by the expression above, we may calculate that,</p><pre name="2851" id="2851" class="graf graf--pre graf-after--p">throughput = 1/4 = 0.25</pre><p name="ea59" id="ea59" class="graf graf--p graf-after--pre">This is not right because, in reality, the tasks are always divided into many steps and we don’t have to wait for the last task if we want to start a new task. This means that the real throughput can be much<strong class="markup--strong markup--p-strong"> higher</strong> than <code class="markup--code markup--p-code">0.25</code> and <code class="markup--code markup--p-code">0.25</code> is a just extreme case of the throughput.</p><p name="5bcf" id="5bcf" class="graf graf--p graf-after--p">Let’s see now see another example. Suppose we have 2 servers and for processing online orders and each order request is assigned to one of the two servers. Each server takes 1 ms to process the order and it can not do anything else while processing an order. In this case, because each task needs 1ms to be processed, so by definition, the latency should be <code class="markup--code markup--p-code">1 ms</code> . However, the throughput is not <code class="markup--code markup--p-code">1,000</code> orders per second because we have two servers working at the same time. Thus, the throughput should be <code class="markup--code markup--p-code">2,000</code> orders per second.</p><p name="420f" id="420f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Comparing Performance By Speedup</strong></p><p name="05fc" id="05fc" class="graf graf--p graf-after--p">Let’s now see how do we compare the performance through the latency and throughput. If we say “Computer X is N times faster than Y” or the <strong class="markup--strong markup--p-strong">speedup</strong> of X and Y is N, then the speedup N can be computed by,</p><figure name="3d7b" id="3d7b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*hZ-Q0JMhGWMqNXOeCGTUBA.png" data-width="1070" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*hZ-Q0JMhGWMqNXOeCGTUBA.png"></figure><p name="f141" id="f141" class="graf graf--p graf-after--figure">If we use <strong class="markup--strong markup--p-strong">throughput</strong> as the measure of the speed, then,</p><figure name="b318" id="b318" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*eJQq_7h2P3RpTtIGrpmdTA.png" data-width="1070" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*eJQq_7h2P3RpTtIGrpmdTA.png"></figure><p name="4155" id="4155" class="graf graf--p graf-after--figure">However, if we use <strong class="markup--strong markup--p-strong">latency</strong> as the measure of the speed, because latency is negatively related to each other, then,</p><figure name="8ceb" id="8ceb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*S-FeIDJHKY9pYuDo6OXXZg.png" data-width="1070" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*S-FeIDJHKY9pYuDo6OXXZg.png"></figure><p name="24b3" id="24b3" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Speedup Interpretation</strong></p><p name="4ee1" id="4ee1" class="graf graf--p graf-after--p">When the value of speedup is larger than 1, then,</p><ul class="postList"><li name="d7c4" id="d7c4" class="graf graf--li graf-after--p">Improved performance</li><li name="bfdd" id="bfdd" class="graf graf--li graf-after--li">Shorter execution time</li><li name="d87d" id="d87d" class="graf graf--li graf-after--li">Higher throughput</li></ul><p name="a84a" id="a84a" class="graf graf--p graf-after--li">When the value of speedup is smaller than 1, then,</p><ul class="postList"><li name="513a" id="513a" class="graf graf--li graf-after--p">Worse performance</li><li name="9887" id="9887" class="graf graf--li graf-after--li">Longer execution time</li><li name="d5ef" id="d5ef" class="graf graf--li graf-after--li">Lower throughput</li></ul><p name="32b9" id="32b9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) The Definition of Benchmark Workloads</strong></p><p name="374e" id="374e" class="graf graf--p graf-after--p">Now, let’s think about how to measure performance. We have seen that we can express performance by 1 over execution time. But there’s a question remaining that what is the workload for this execution time? A simple idea is to use the <strong class="markup--strong markup--p-strong">actual user workload</strong>. However, this idea is useless in practice for three main reasons,</p><ul class="postList"><li name="9502" id="9502" class="graf graf--li graf-after--p">too many programs</li><li name="53c6" id="53c6" class="graf graf--li graf-after--li">not representative of other users</li><li name="8871" id="8871" class="graf graf--li graf-after--li">privacy concerns</li></ul><p name="dc2d" id="dc2d" class="graf graf--p graf-after--li">Instead, we use the benchmark workloads for measuring the performance. The <strong class="markup--strong markup--p-strong">benchmark workload</strong> is a series of programs and input data that users and companies have agreed upon will be used for performance measures.</p><p name="7991" id="7991" class="graf graf--p graf-after--p">Usually, we don’t have only one benchmark program. A <strong class="markup--strong markup--p-strong">benchmark suite </strong>contains multiple programs along with the input data and each of these programs is usually chosen to be representative of some type of applications.</p><p name="4b51" id="4b51" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Types of Benchmarks</strong></p><ul class="postList"><li name="8fda" id="8fda" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Real applications benchmarks</strong>: are the most representative benchmark. But they are also the most difficult ones to set up on a new machine (for example, we may need to configure the environment, install the drives and apps, etc.).</li><li name="c416" id="c416" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Kernel benchmarks</strong>: We can find the most time-consuming part of an application (usually a loop). Thus, we don’t have to install all the drives or relative stuff for the real application. But a reasonably sized kernel is still too difficult for a prototyped machine or an early staged computer (sometimes we even don’t have a compiler). When we actually build a machine for the first time as a <strong class="markup--strong markup--li-strong">prototype</strong>, we can use this kind of benchmark.</li><li name="929e" id="929e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Synthetic benchmarks</strong>: These benchmarks are usually designed to behave similarly to some type of kernel but they are much simpler to compile. These benchmarks are usually good for <strong class="markup--strong markup--li-strong">design studies</strong>, but they are not a good idea to report to others, especially our customers.</li><li name="72e2" id="72e2" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Peak performance benchmarks</strong>: The above methods are to compare machines based on some actual codes but there’s also a measure of the peak performance that tells us the performance. In theory, peak performance tells us how many instructions per second should this machine be able to execute. However, this measurement is only used for <strong class="markup--strong markup--li-strong">marketing</strong> because it can deviate from the actual performance of a machine. peak performance</li></ul><p name="7993" id="7993" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(7) Benchmark Standards</strong></p><p name="1250" id="1250" class="graf graf--p graf-after--p">Usually, there are <strong class="markup--strong markup--p-strong">standard organizations</strong> that put together benchmark suites for comparing machines. A standard organization takes inputs from manufacturers, user groups, and experts in academia to produce a standard <strong class="markup--strong markup--p-strong">benchmark suite</strong> along with instructions on how to produce representative measurements.</p><ul class="postList"><li name="b001" id="b001" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">TPC benchmark</strong>: standard benchmark used for database, web servers, data mining, and other <strong class="markup--strong markup--li-strong">transaction</strong> processing</li><li name="3580" id="3580" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">EEMBC benchmark</strong>: standard benchmark used for <strong class="markup--strong markup--li-strong">embedded processing</strong> such as cars, video players, printers, mobile phones, etc.</li><li name="05c6" id="05c6" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">SPEC benchmark</strong>: standard benchmark typically used to evaluate <strong class="markup--strong markup--li-strong">engineering workstations</strong> and also our <strong class="markup--strong markup--li-strong">processors</strong> because these benchmarks are not very I/O intensive. This kind of benchmark includes several applications (i.e. GCC — software development workloads like compiler, BEWAVES &amp; LBM — Floyd dynamic workloads, PERL — string processing applications, CACTUS ADM — physics simulation, XALANC BMK — for XML, CALCULIX &amp; DEALL—for differential equations, BZIP — for compression application, GO &amp; SJENG — for game AI applications).</li></ul><p name="72da" id="72da" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(8) Performance Summarizing Methods</strong></p><ul class="postList"><li name="f266" id="f266" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Average execution time</strong>: calculate the average time for each execution and then calculate the speedup. We can not simply average the values of the speedups. This is the commonest method we normally use for summarizing performance</li><li name="a99f" id="a99f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Geometric mean</strong>: if we want to calculate the mean value by the speedups, we have to use the geometric mean. We are going to use the geometric mean only if we don’t know the actual time for each application. The geometric mean is defined by,</li></ul><figure name="3a7b" id="3a7b" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*2JfZYZA50rXqiEC5YOqZ1Q.png" data-width="1492" data-height="176" src="https://cdn-images-1.medium.com/max/800/1*2JfZYZA50rXqiEC5YOqZ1Q.png"></figure><p name="7be7" id="7be7" class="graf graf--p graf-after--figure">Let’s see an example. Where <code class="markup--code markup--p-code">AVG</code> represents average execution time and <code class="markup--code markup--p-code">GEO</code> means for geometric mean,</p><pre name="ddfe" id="ddfe" class="graf graf--pre graf-after--p">           COMP_X    COMP_Y     SPEEDUP<br>APP A        9        18          2<br>APP B       10         7          0.7   <br>APP C        5        11          2.2<br>AVG          8        12          1.5<br>GEO          7.66     11.15       1.46</pre><p name="c566" id="c566" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">2. Iron Law of Performance</strong></p><p name="1df4" id="1df4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) CPU Time</strong></p><p name="67aa" id="67aa" class="graf graf--p graf-after--p">In this series, we are going to focus mainly on the processor. When we say processor, we are always meaning the CPU (central processing unit). The CPU time or the processor time is defined as the time for a processor to run a program.</p><p name="9a8c" id="9a8c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Iron Law of Performance</strong></p><p name="1d8c" id="1d8c" class="graf graf--p graf-after--p">Actually, the CPU time can be calculated by,</p><figure name="fa20" id="fa20" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*2HFxvNzQ77i4xCwYvupFYw.png" data-width="1492" data-height="78" src="https://cdn-images-1.medium.com/max/800/1*2HFxvNzQ77i4xCwYvupFYw.png"></figure><p name="3cda" id="3cda" class="graf graf--p graf-after--figure">This can be proved by the following expression,</p><figure name="dde2" id="dde2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*v7x7Z3w82t0d3wK6LF7WNw.png" data-width="1492" data-height="134" src="https://cdn-images-1.medium.com/max/800/1*v7x7Z3w82t0d3wK6LF7WNw.png"></figure><p name="4175" id="4175" class="graf graf--p graf-after--figure">The three components of the CPU time allow us to think about different aspects of computer architecture. This is called the Iron Law of performance. We can also write this expression to,</p><figure name="a5b8" id="a5b8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*kSbGR6hOQ2ihKj2mHCtIjQ.png" data-width="1178" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*kSbGR6hOQ2ihKj2mHCtIjQ.png"></figure><p name="4c1f" id="4c1f" class="graf graf--p graf-after--figure">where,</p><ul class="postList"><li name="fe9f" id="fe9f" class="graf graf--li graf-after--p">IC means instructions count</li><li name="ad60" id="ad60" class="graf graf--li graf-after--li">CPI means cycles per instruction</li><li name="28a8" id="28a8" class="graf graf--li graf-after--li">CCT means clock cycle time (which is also the reciprocal of the cycle clock)</li></ul><p name="fd2c" id="fd2c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Components of the CPU Time And Computer Architecture</strong></p><ul class="postList"><li name="aa55" id="aa55" class="graf graf--li graf-after--p"># of instructions per program: generally affected by the <strong class="markup--strong markup--li-strong">algorithm </strong>we use and the <strong class="markup--strong markup--li-strong">compiler</strong> we use. Also, the <strong class="markup--strong markup--li-strong">instruction set</strong> can impact how many instructions we need for a program</li><li name="4848" id="4848" class="graf graf--li graf-after--li"># of cycles per instruction: affected by the <strong class="markup--strong markup--li-strong">instruction set</strong> (a simple set will reduce the cycles to do) and the<strong class="markup--strong markup--li-strong"> processor design</strong></li><li name="4379" id="4379" class="graf graf--li graf-after--li">clock cycle time: affected by the <strong class="markup--strong markup--li-strong">processor design</strong>, the <strong class="markup--strong markup--li-strong">circuit design,</strong> and the <strong class="markup--strong markup--li-strong">transistor physics</strong></li></ul><p name="6283" id="6283" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Iron Law for Unequal Instruction Times</strong></p><p name="85e7" id="85e7" class="graf graf--p graf-after--p">The iron law of performance can be easily applied to the instructions that have constant cycles, but how can we apply this law to the unequal instruction times. This is a simple mathematic problem and the final processor time can be calculated by,</p><figure name="3dd9" id="3dd9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*oQ62xybIEp4gJzgnCTc1fw.png" data-width="1178" data-height="124" src="https://cdn-images-1.medium.com/max/800/1*oQ62xybIEp4gJzgnCTc1fw.png"></figure><p name="bf99" id="bf99" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">3. Amdahl’s Law</strong></p><p name="2423" id="2423" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Definition of the Amdahl’s Law</strong></p><p name="2aed" id="2aed" class="graf graf--p graf-after--p">Another law we may use a lot is called the Amdahl’s Law, especially when we are about to speed up only <strong class="markup--strong markup--p-strong">part of the program</strong> or only some instructions. Basically, when are have a speed-up task but it doesn’t apply to the entire program and we want to know what is the overall speed up on the entire program.</p><p name="aad8" id="aad8" class="graf graf--p graf-after--p">The fraction enhanced is defined as the percentage of the original execution <strong class="markup--strong markup--p-strong">TIME</strong> (not instructions count or something else) that is affected by our enhancement and this value is denoted as <code class="markup--code markup--p-code">FRAC_enh</code>.</p><p name="6770" id="6770" class="graf graf--p graf-after--p">By Amdahl’s Law, the overall speedup can be calculated by,</p><figure name="6e1e" id="6e1e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*aawfCEZHyL6iknZ7m2wiQg.png" data-width="1178" data-height="156" src="https://cdn-images-1.medium.com/max/800/1*aawfCEZHyL6iknZ7m2wiQg.png"></figure><p name="a042" id="a042" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Amdahl’s Law Implications</strong></p><p name="bbcc" id="bbcc" class="graf graf--p graf-after--p">So what does Amdahl’s law implies? Let’s think about two different enhancements. For enhancement #1, we enhance a speedup of 20 on 10% of the time. For enhancement #2, we enhance a speedup of 1.6 on 80% of the time. By Amdahl’s law, the overall speedup for enhancement #1 is <code class="markup--code markup--p-code">1.105</code> and the overall speedup for enhancement #2 is <code class="markup--code markup--p-code">1.43</code> .</p><p name="51cf" id="51cf" class="graf graf--p graf-after--p">This implies that if we put significant effort to speed up something that is a small part of the execution time, you will still not get a very large improvement. In contrast, if you are impacting a large part of the execution time and even if there’s only a small reasonably small speedup, you will still result in a large overall speedup.</p><p name="c9cb" id="c9cb" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">4. Lhadma’s Law</strong></p><p name="5310" id="5310" class="graf graf--p graf-after--p">This is jokingly called Lhadma’s law because of Amdahl’s law. We have known that Amdahl’s law implies that we have to speed up the most common cases in order to have a significant impact on the overall speedup, while Lhadma’s law tells us that we don’t want to mess up with the uncommon cases too badly.</p><p name="e77e" id="e77e" class="graf graf--p graf-after--p">Let’s see an example. Suppose we would like to have a speedup of 2 on 90% of the execution time and another speedup of 0.1 on the rest of the execution time. The overall speedup can be calculated by,</p><figure name="b09b" id="b09b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*b9aaIaOZvihHu4T_LxFnEw.png" data-width="1178" data-height="156" src="https://cdn-images-1.medium.com/max/800/1*b9aaIaOZvihHu4T_LxFnEw.png"></figure><p name="5d2c" id="5d2c" class="graf graf--p graf-after--figure">And this result proves Lhadma’s law.</p><p name="6817" id="6817" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">5. Diminishing Returns</strong></p><p name="7187" id="7187" class="graf graf--p graf-after--p graf--trailing">The diminishing returns is another rule that tells us not to go overboard improving the same thing because the thing that has been already improved are now a smaller percentage of the new execution time and we need to reassess what is now the dominate part. In other words, this also mentions that we have to reconsider what is now the enhancement percentage after each speeding up.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/1812e901dc63"><time class="dt-published" datetime="2021-01-15T14:40:44.542Z">January 15, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/high-performance-computer-architecture-4-metrics-and-evaluation-of-performance-iron-law-1812e901dc63" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>