<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>High-Performance Computer Architecture 25 | Cache Experiment</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">High-Performance Computer Architecture 25 | Cache Experiment</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: High-Performance Computer Architecture
</section>
<section data-field="body" class="e-content">
<section name="aa35" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="1486" id="1486" class="graf graf--h3 graf--leading graf--title">High-Performance Computer Architecture 25 | Cache Experiment</h3><figure name="709d" id="709d" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*NGQHk0-oyGav9lx8.png" data-width="1446" data-height="864" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*NGQHk0-oyGav9lx8.png"></figure><blockquote name="07b1" id="07b1" class="graf graf--blockquote graf-after--figure"><strong class="markup--strong markup--blockquote-strong">NOTE:</strong> The present article does <strong class="markup--strong markup--blockquote-strong">NOT</strong> include anything related to the final submission (<strong class="markup--strong markup--blockquote-strong">no answers, no specific values, no results</strong>) for the course <a href="https://omscs.gatech.edu/cs-6290-high-performance-computer-architecture" data-href="https://omscs.gatech.edu/cs-6290-high-performance-computer-architecture" class="markup--anchor markup--blockquote-anchor" rel="noopener nofollow noopener" target="_blank">CS6290 HPCA</a> because of the honor code. Most of the contents in this article is repeating the basic instructions and the directions of the Project 2. More Linux commands are provided as complements to the project’s guidelines.</blockquote><blockquote name="a5bc" id="a5bc" class="graf graf--blockquote graf-after--blockquote"><strong class="markup--strong markup--blockquote-strong">Please feel free to contact me if this article violates the rules of Georgia Tech and I will immediately delete this article with no doubt.</strong></blockquote><p name="8c2a" id="8c2a" class="graf graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">0. Basic Setup</strong></p><p name="bd40" id="bd40" class="graf graf--p graf-after--p">In this experiment, we are going to focus on the cache. We will use the original <code class="markup--code markup--p-code">cmp4-noc.conf</code> file and you can view the file by,</p><pre name="6e7a" id="6e7a" class="graf graf--pre graf-after--p">$ cd sesc/confs<br>$ cat cmp4-noc.conf | more</pre><p name="8519" id="8519" class="graf graf--p graf-after--pre">Also, we will be using the FMM benchmark with 256 particles and single-core execution, and you can find this simulation from,</p><pre name="6b53" id="6b53" class="graf graf--pre graf-after--p">$ cd ~/sesc/apps/Splash2/fmm</pre><p name="db52" id="db52" class="graf graf--p graf-after--pre">Then we can view the content of this directory by,</p><pre name="6509" id="6509" class="graf graf--pre graf-after--p">$ ls</pre><p name="2652" id="2652" class="graf graf--p graf-after--pre">If you access this directory for the first time, you may probably get the following output,</p><pre name="abf3" id="abf3" class="graf graf--pre graf-after--p">Changed  Changed1  Changed.new  Changed.NOLOCK  Input  Makefile  Source</pre><p name="a142" id="a142" class="graf graf--p graf-after--pre">From this output, we can find out that the file <code class="markup--code markup--p-code">fmm.mipseb</code> doesn’t exist. We can use the <code class="markup--code markup--p-code">Makefile</code> to compile this file,</p><pre name="46a2" id="46a2" class="graf graf--pre graf-after--p">$ make<br>$ ls</pre><p name="9707" id="9707" class="graf graf--p graf-after--pre">Then the output should be,</p><pre name="1ae9" id="1ae9" class="graf graf--pre graf-after--p">Changed   Changed.new     fmm.mipseb  Makefile<br>Changed1  Changed.NOLOCK  Input       Source</pre><p name="0094" id="0094" class="graf graf--p graf-after--pre">Then we can run the simulation as we have done in the previous experiments and by the following command,</p><pre name="19a1" id="19a1" class="graf graf--pre graf-after--p">$ ~/sesc/sesc.opt -f Default -c ~/sesc/confs/cmp4-noc.conf -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1</pre><p name="e23d" id="e23d" class="graf graf--p graf-after--pre">The output report will be named as <code class="markup--code markup--p-code">sesc_fmm.mipseb.Default</code> and we have to make sure that the <code class="markup--code markup--p-code">fmm.err</code> file should be empty,</p><pre name="c02c" id="c02c" class="graf graf--pre graf-after--p">$ cat fmm.err</pre><p name="ae0d" id="ae0d" class="graf graf--p graf-after--pre">and for <code class="markup--code markup--p-code">fmm.out</code>,</p><pre name="7197" id="7197" class="graf graf--pre graf-after--p">$ cat fmm.out</pre><p name="a458" id="a458" class="graf graf--p graf-after--pre">the output should begin with,</p><pre name="3548" id="3548" class="graf graf--pre graf-after--p">Creating a two cluster, non uniform distribution for 256 particles</pre><p name="f8c5" id="f8c5" class="graf graf--p graf-after--pre">and have a,</p><pre name="7fdb" id="7fdb" class="graf graf--pre graf-after--p">Total time for steps 3 to 5 : 0</pre><p name="e18d" id="e18d" class="graf graf--p graf-after--pre">at the end.</p><ol class="postList"><li name="7ccb" id="7ccb" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Experiment 1: Cache Performance</strong></li></ol><p name="ed02" id="ed02" class="graf graf--p graf-after--li">In this experiment, we will be modifying the data caches of the simulated processor. So let’s take a closer look at the configuration file <code class="markup--code markup--p-code">~/sesc/confs/cmp4-noc.conf</code> by,</p><pre name="7111" id="7111" class="graf graf--pre graf-after--p">$ cat ~/sesc/confs/cmp4-noc.conf | more</pre><p name="832e" id="832e" class="graf graf--p graf-after--pre">Let’s then have a look at the <code class="markup--code markup--p-code">DMemory</code> section,</p><pre name="f1a1" id="f1a1" class="graf graf--pre graf-after--p"># data source<br>[DMemory]<br>deviceType    = &#39;smpcache&#39;<br>size          = 32*1024  <br>assoc         = 4 <br>bsize         = $(cacheLineSize)<br>writePolicy   = &#39;WB&#39;<br>replPolicy = &#39;LRU&#39;<br>protocol      = &#39;DMESI&#39;<br>numPorts      = 2 <br>portOccp      = 1 # Number of occupancy per port. 0: UnlimitedPort, 1:FullyPipelinedPort, other value: PortPipe<br>hitDelay      = 1<br>missDelay     = 1               <br>#displNotify   = false<br>MSHR          = &quot;DMSHR&quot;<br>lowerLevel   = &quot;Router RTR sharedBy 1&quot;</pre><p name="8664" id="8664" class="graf graf--p graf-after--pre">It says that the structure the processor gets data from is of type <code class="markup--code markup--p-code">smpcache</code> which,</p><ul class="postList"><li name="2219" id="2219" class="graf graf--li graf-after--p">can store 32KB of data: by <code class="markup--code markup--li-code">size</code></li><li name="dd58" id="dd58" class="graf graf--li graf-after--li">4-way set associative: by <code class="markup--code markup--li-code">assoc</code></li><li name="6ab4" id="6ab4" class="graf graf--li graf-after--li">has a 64B block/line size: by <code class="markup--code markup--li-code">bsize</code> which uses the <code class="markup--code markup--li-code">cacheLineSize</code> (64)</li><li name="64e9" id="64e9" class="graf graf--li graf-after--li">write-back cache: by <code class="markup--code markup--li-code">writePolicy</code></li><li name="f37c" id="f37c" class="graf graf--li graf-after--li">LRU replacement policy: by <code class="markup--code markup--li-code">replPolicy</code></li><li name="87f5" id="87f5" class="graf graf--li graf-after--li">handle 2 cache accesses every cycle: by <code class="markup--code markup--li-code">numPorts</code> and <code class="markup--code markup--li-code">portOccp</code></li><li name="5f8e" id="5f8e" class="graf graf--li graf-after--li">has a 1-cycle hit time: by <code class="markup--code markup--li-code">hitDelay</code></li><li name="4411" id="4411" class="graf graf--li graf-after--li">takes 1 cycles to detect a miss: by <code class="markup--code markup--li-code">missDelay</code></li><li name="ffb6" id="ffb6" class="graf graf--li graf-after--li">keeps track of the misses with (data miss handling registers) DMSHR: by <code class="markup--code markup--li-code">MSHR</code></li></ul><p name="d3ab" id="d3ab" class="graf graf--p graf-after--li">In the <code class="markup--code markup--p-code">DMSHR</code> section of the configuration file, we can find out that it is a 64-entry structure where each entry can keep track of a miss to an entire 64-byte block. On a miss, the L1 cache requests data from the core’s local slice of the L2 cache, or from the on-chip router that connects it to the L2 slices of other cores.</p><pre name="07fd" id="07fd" class="graf graf--pre graf-after--p">[DMSHR]<br>type = &#39;single&#39; # Options: none, nodeps, full, single, banked Check libsuc/MSHR<br>size = 64<br>bsize = $(cacheLineSize)</pre><p name="dc41" id="dc41" class="graf graf--p graf-after--pre">Note that in this project we will still be using only one core (Core 0) so it gets to use the entire L2 cache (<strong class="markup--strong markup--p-strong">all four slices</strong>). Looking at the <code class="markup--code markup--p-code">L2Slice</code> section,</p><pre name="cb2b" id="cb2b" class="graf graf--pre graf-after--p">[L2Slice]<br>deviceType    = &#39;slicecache&#39;<br>inclusive     = false<br>size          = 1*1024*1024<br>assoc         = 16<br>bsize         = $(cacheLineSize)<br>writePolicy   = &#39;WB&#39;<br>replPolicy = &#39;LRU&#39;<br>numPorts      = 2                # one for L1, one for snooping<br>portOccp      = 1  # throughput of a cache<br>hitDelay      = 12<br>missDelay     = 12               # exclusive, i.e., not added to hitDelay<br>numPortsDir      = 1                # one for L1, one for snooping<br>portOccpDir      = 1  # throughput of a cache<br>hitDelayDir      = 1<br>MSHR          = &#39;L2MSHR&#39;<br>lowerLevel    = &quot;Router RTR sharedBy 1&quot;</pre><p name="3f22" id="3f22" class="graf graf--p graf-after--pre">We see that,</p><ul class="postList"><li name="592a" id="592a" class="graf graf--li graf-after--p">each slice can store 1 MB of data (so the total L2 cache size is 4MB): by <code class="markup--code markup--li-code">size</code></li><li name="f561" id="f561" class="graf graf--li graf-after--li">it is a 16-way set-associative cache: by <code class="markup--code markup--li-code">assoc</code></li><li name="bddd" id="bddd" class="graf graf--li graf-after--li">with 64B block size: by <code class="markup--code markup--li-code">bsize</code></li><li name="18a9" id="18a9" class="graf graf--li graf-after--li">with write-back cache: by <code class="markup--code markup--li-code">writePolicy</code></li><li name="870a" id="870a" class="graf graf--li graf-after--li">with LRU replacement policy: by <code class="markup--code markup--li-code">replPolicy</code></li><li name="ad25" id="ad25" class="graf graf--li graf-after--li">handle 2 cache accesses every cycle: by <code class="markup--code markup--li-code">numPorts</code> and <code class="markup--code markup--li-code">portOccp</code></li><li name="00a7" id="00a7" class="graf graf--li graf-after--li">has a 12-cycle hit time: by <code class="markup--code markup--li-code">hitDelay</code></li><li name="de77" id="de77" class="graf graf--li graf-after--li">takes 12 cycles to detect a miss: by <code class="markup--code markup--li-code">missDelay</code></li><li name="45a7" id="45a7" class="graf graf--li graf-after--li">keeps track of the misses with (data miss handling registers) DMSHR: by <code class="markup--code markup--li-code">MSHR</code></li><li name="2209" id="2209" class="graf graf--li graf-after--li">it uses a 64-entry MSHR to keep track of misses: by <code class="markup--code markup--li-code">MSHR</code></li></ul><p name="2083" id="2083" class="graf graf--p graf-after--li">When there is a miss, it is handed off to a local on-chip router (see the <code class="markup--code markup--p-code">router</code> section), which uses the on-chip network (NOC) to deliver the message to a memory controller (see the <code class="markup--code markup--p-code">NOC</code> section).</p><p name="6df8" id="6df8" class="graf graf--p graf-after--p">It, in turn, uses the off-chip processor-memory bus to access the main memory, and this can be found from the <code class="markup--code markup--p-code">memory</code> section,</p><pre name="c8a2" id="c8a2" class="graf graf--pre graf-after--p">[Memory]<br>deviceType    = &#39;niceCache&#39;<br>size          = 64<br>assoc         = 1<br>bsize         = 64<br>writePolicy   = &#39;WB&#39;<br>replPolicy = &#39;LRU&#39;<br>numPorts      = 1<br>portOccp      = 1<br>hitDelay      = 200 <br>missDelay     = 10000<br>MSHR          = NoMSHR<br>lowerLevel    = &#39;voidDevice&#39;</pre><p name="2f44" id="2f44" class="graf graf--p graf-after--pre">which is modeled in this configuration as an infinite cache with,</p><ul class="postList"><li name="5b33" id="5b33" class="graf graf--li graf-after--p">a 200-cycle hit delay: by <code class="markup--code markup--li-code">hitDelay</code></li></ul><p name="fea0" id="fea0" class="graf graf--p graf-after--li">Now, let’s read the default report <code class="markup--code markup--p-code">sesc_fmm.mipseb.Default</code> by,</p><pre name="0412" id="0412" class="graf graf--pre graf-after--p">$ ~/sesc/scripts/report.pl <code class="markup--code markup--pre-code">sesc_fmm.mipseb.Default</code></pre><p name="7dfc" id="7dfc" class="graf graf--p graf-after--pre">Then we should change the L1 cache size to 2kB, leave all other conf parameters unchanged and get a new configuration file named <code class="markup--code markup--p-code">cmp4-noc-SmallL1.conf</code> . Then we can redo the simulation by,</p><pre name="351e" id="351e" class="graf graf--pre graf-after--p">$ ~/sesc/sesc.opt -f SmallL1 -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-SmallL1.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1</pre><p name="5d11" id="5d11" class="graf graf--p graf-after--pre">We can then read this report by,</p><pre name="e6ba" id="e6ba" class="graf graf--pre graf-after--p">$ ~/sesc/scripts/report.pl <code class="markup--code markup--pre-code">sesc_fmm.mipseb.SmallL1</code></pre><p name="622e" id="622e" class="graf graf--p graf-after--pre">Compare the miss rate of these two caches, we are expected to see that the larger cache (32KB) will have a lower miss rate and thus, it has a better performance.</p><p name="1f3e" id="1f3e" class="graf graf--p graf-after--p">Now, let’s modify the original configuration file <code class="markup--code markup--p-code">cmp4-noc.conf</code> to make a directed-mapped cache. The new configuration file named <code class="markup--code markup--p-code">cmp4-noc-DMapL1.conf</code> . Then we can redo the simulation by,</p><pre name="9311" id="9311" class="graf graf--pre graf-after--p">$ ~/sesc/sesc.opt -f <code class="markup--code markup--pre-code">DMapL1</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-DMapL1.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1</pre><p name="c284" id="c284" class="graf graf--p graf-after--pre">We can then read this report by,</p><pre name="3105" id="3105" class="graf graf--pre graf-after--p">$ ~/sesc/scripts/report.pl <code class="markup--code markup--pre-code">sesc_fmm.mipseb.DMapL1</code></pre><p name="6989" id="6989" class="graf graf--p graf-after--pre">We can find out the set-associative cache has a better performance than the direct-mapped cache.</p><p name="6fba" id="6fba" class="graf graf--p graf-after--p">Now let’s restore the default configuration (32kB, 4-way set associative L1 cache) and change the L1 cache latency to<strong class="markup--strong markup--p-strong"> 4 cycles</strong> (change both hitDelay and missDelay to 3) and then to 7<strong class="markup--strong markup--p-strong"> cycles</strong>. The two configuration files should be named as <code class="markup--code markup--p-code">cmp4-noc-4CycL1.conf</code> and <code class="markup--code markup--p-code">cmp4-noc-7CycL1.conf</code>, respectively. Then we can run the simulations by,</p><pre name="e1c1" id="e1c1" class="graf graf--pre graf-after--p">$ ~/sesc/sesc.opt -f 4<code class="markup--code markup--pre-code">CycL1</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-4CycL1.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1<br>$ ~/sesc/sesc.opt -f 7<code class="markup--code markup--pre-code">CycL1</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-7CycL1.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1</pre><p name="fb6d" id="fb6d" class="graf graf--p graf-after--pre">We can then read these reports by,</p><pre name="1c4c" id="1c4c" class="graf graf--pre graf-after--p">$ ~/sesc/scripts/report.pl <code class="markup--code markup--pre-code">sesc_fmm.mipseb.</code>4<code class="markup--code markup--pre-code">CycL1<br></code>$ ~/sesc/scripts/report.pl <code class="markup--code markup--pre-code">sesc_fmm.mipseb.7CycL1</code></pre><p name="3446" id="3446" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">2. Experiment 2: NXLRU Policy Implementation</strong></p><p name="b229" id="b229" class="graf graf--p graf-after--p">The cache implementation in the simulator can <strong class="markup--strong markup--p-strong">only</strong> model the LRU replacement policy. Even though a RANDOM policy can be specified in the configuration file, the code that models the replacement policy will still implement LRU.</p><p name="6e89" id="6e89" class="graf graf--p graf-after--p">Now we will explore what happens when we actually change the cache’s replacement policy. We will <strong class="markup--strong markup--p-strong">implement the NXLRU</strong> (Next to Least Recently Used). While LRU replaces the block that is the first in LRU order (i.e. the least recently used block) in the cache set, NXLRU should replace the block that is the second in LRU order in the set.</p><p name="ec2b" id="ec2b" class="graf graf--p graf-after--p">To implement NXLRU, we need to modify the code of the simulator. The source file which implements the <code class="markup--code markup--p-code">smpcache</code> (used for our L1 cache) is in the <code class="markup--code markup--p-code">~/sesc/src/libcmp/</code> directory named,</p><ul class="postList"><li name="224f" id="224f" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">SMPCache.h</code></li><li name="8857" id="8857" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">SMCache.cpp</code></li></ul><p name="d223" id="d223" class="graf graf--p graf-after--li">For much of the basic cache behavior, the SMPCache also uses code in <code class="markup--code markup--p-code">~/sesc/src/libsuc/</code> named,</p><ul class="postList"><li name="e1cf" id="e1cf" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">CacheCore.h</code></li><li name="497e" id="497e" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">CacheCore.cpp</code></li></ul><p name="1768" id="1768" class="graf graf--p graf-after--li">In these files, there are separate classes for,</p><ul class="postList"><li name="6170" id="6170" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">CacheDM</code> (for direct-mapped caches)</li><li name="dccb" id="dccb" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">CacheAssoc</code> (for set-associative caches).</li></ul><p name="3153" id="3153" class="graf graf--p graf-after--li">Since direct-mapped caches do not have a replacement policy (they must replace the one line where the new block must go), we will be looking at the <code class="markup--code markup--p-code">CacheAssoc</code> class.</p><p name="de93" id="de93" class="graf graf--p graf-after--p">First, we must add <code class="markup--code markup--p-code">NXLRU</code> as an option that can be specified in the conf file and it can be selected when a <code class="markup--code markup--p-code">CacheAssoc</code> object is constructed. Probably a good approach is to look for <code class="markup--code markup--p-code">LRU</code> in the code to see how this is done for <code class="markup--code markup--p-code">LRU</code> (and <code class="markup--code markup--p-code">RANDOM</code>), and then add <code class="markup--code markup--p-code">NXLRU</code>. And remember to check the following parts,</p><ul class="postList"><li name="7182" id="7182" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">macros</code></li><li name="b602" id="b602" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">CacheGeneric</code></li><li name="bcb4" id="bcb4" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">CacheAssoc</code></li></ul><p name="5b57" id="5b57" class="graf graf--p graf-after--li">Then we must actually implement this policy. The function that actually implements the cache’s replacement policy is the <code class="markup--code markup--p-code">findLine2Replace</code> method of the <code class="markup--code markup--p-code">CacheAssoc</code> class in <code class="markup--code markup--p-code">CacheCore.cpp</code>.</p><figure name="048c" id="048c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/3699c6308eb11a6d2fb9e6c9aec96288.js"></script></figure><p name="4bc6" id="4bc6" class="graf graf--p graf-after--figure">The parameter <code class="markup--code markup--p-code">addr</code> supplied to this method is the new address that needs a line in the cache. Note that this method does not only implement the replacement policy because an actual replacement (replace one valid line with another) may not be needed. For example, when addr is already in the cache (a <strong class="markup--strong markup--p-strong">cache hit</strong>), this method returns the line that contains <code class="markup--code markup--p-code">addr</code>. In the most typical case, the cache will be treated as a DMC (direct-mapped cache) which will only check the most typical case instead of all the cases in the cache. If we have a cache miss, then it will then be treated as a set-associative cache. This is an implementation of the <strong class="markup--strong markup--p-strong">Way Prediction</strong>.</p><pre name="da07" id="da07" class="graf graf--pre graf-after--p">// extract tag from the address<br>Addr_t tag    = calcTag(addr);</pre><pre name="5a50" id="5a50" class="graf graf--pre graf-after--pre">// extract index and get the corresponding set<br>Line **theSet = &amp;content[calcIndex4Tag(tag)];</pre><pre name="e2b4" id="e2b4" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">/* Check most typical case */</strong><br>// if the tag in the set equals the tag we extracted<br>// means a cache hit<br>if ((*theSet)-&gt;getTag() == tag) {<br>    GI(tag,(*theSet)-&gt;isValid());        // set the valid bit to 1<br>    return *theSet;               // return the line contains addr<br>}</pre><p name="2216" id="2216" class="graf graf--p graf-after--pre">However, when we have a cache miss with the way prediction, we need to have a search in the set and treat this cache as a normal <strong class="markup--strong markup--p-strong">set-associative cache</strong>. When we have a cache hit, we will store the <strong class="markup--strong markup--p-strong">hit line</strong> in the parameter <code class="markup--code markup--p-code">lineHit</code>. While if we have a cache miss, we will need to check whether we have a <strong class="markup--strong markup--p-strong">non-valid line</strong>. When the set where the <code class="markup--code markup--p-code">addr</code> belongs to contains non-valid lines, one of those non-valid lines <code class="markup--code markup--p-code">lineFree</code> is stored and will be used — a valid block may have a cache hit in the future, while a non-valid line cannot, so we should only replace a valid line if the set has no non-valid lines. Finally, when the set contains <code class="markup--code markup--p-code">locked</code> lines, they are skipped.</p><pre name="9d29" id="9d29" class="graf graf--pre graf-after--p">// get the set ending line based on associativity<br>Line **setEnd = theSet + assoc;</pre><pre name="4ef8" id="4ef8" class="graf graf--pre graf-after--pre">// assume we have a cache <strong class="markup--strong markup--pre-strong">hit line</strong> and initialize it with NULL<br>Line **lineHit=0;</pre><pre name="02f8" id="02f8" class="graf graf--pre graf-after--pre">// assume we have a <strong class="markup--strong markup--pre-strong">non-valid line</strong> and initialize it with NULL<br>Line **lineFree=0;</pre><pre name="aa96" id="aa96" class="graf graf--pre graf-after--pre">/* search the cache hit in the set */<br>// let&#39;s start looping from the LRU to the MRU line in the set<br>Line **l = setEnd -1;</pre><pre name="21a6" id="21a6" class="graf graf--pre graf-after--pre">// when the address of line l is smaller than the <br>// set beginning address, we have to break the loop<br>// because we have checked the whole set<br>while(l &gt;= theSet) {<br>    // let&#39;s check if the current line has a cache hit<br>    if ((*l)-&gt;getTag() == tag) {<br>        lineHit = l;         // set to lineHit if we have a hit<br>        break;               // then break the loop<br>    }<br>    // if the current line is non-valid, it can be useful<br>    if (!(*l)-&gt;isValid())<br>        lineFree = l;        // set the free line<br>    // if we haven&#39;t got a free line, we set the free line to <br>    // the LRU line without lock<br>    else if (lineFree == 0 &amp;&amp; !(*l)-&gt;isLocked())<br>        lineFree = l;</pre><pre name="1321" id="1321" class="graf graf--pre graf-after--pre">    // If line is invalid, isLocked must be false<br>    GI(!(*l)-&gt;isValid(), !(*l)-&gt;isLocked());<br>    l--;                     // loop the next line<br>}</pre><pre name="4427" id="4427" class="graf graf--pre graf-after--pre">// if we have a cache hit, we can directly return the line hit<br>if (lineHit)<br>    return *lineHit;</pre><p name="6e21" id="6e21" class="graf graf--p graf-after--pre">So the actual <code class="markup--code markup--p-code">LRU</code> policy implemented by <code class="markup--code markup--p-code">findLine2Replace</code> is that,</p><p name="892f" id="892f" class="graf graf--p graf-after--p">from the set where <code class="markup--code markup--p-code">addr</code> belongs,</p><ul class="postList"><li name="f6c2" id="f6c2" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">return the line</strong> that contains <code class="markup--code markup--li-code">addr</code> if there is such a line</li><li name="177f" id="177f" class="graf graf--li graf-after--li">otherwise <strong class="markup--strong markup--li-strong">return the invalid line</strong> that was accessed most recently if there are any invalid lines</li><li name="eef3" id="eef3" class="graf graf--li graf-after--li">otherwise <strong class="markup--strong markup--li-strong">return the LRU line</strong> among the lines that are not locked</li></ul><p name="8813" id="8813" class="graf graf--p graf-after--li">Even that is not the complete specification because <code class="markup--code markup--p-code">findLine2Replace</code> must consider what should happen when <strong class="markup--strong markup--p-strong">all lines are valid and locked</strong>. In that case, it returns 0 unless <code class="markup--code markup--p-code">ignoreLocked</code> is true, in which case it returns the least recently used line chosen among all the (valid and locked) lines in the set.</p><p name="7b81" id="7b81" class="graf graf--p graf-after--p">Our NXLRU policy should treat hits and invalid lines just like the existing LRU and RANDOM policy, but when there is no hit and no invalid lines to return, the NXLRU policy should find the <strong class="markup--strong markup--p-strong">second-least-recently-used line</strong> among the non-locked lines.</p><p name="ab5b" id="ab5b" class="graf graf--p graf-after--p">However, if only <strong class="markup--strong markup--p-strong">one</strong> non-locked line exists in the set, that line must be returned. And if all lines are valid and locked, <strong class="markup--strong markup--p-strong">the second-least-recently-used</strong> one in the set should be returned.</p><p name="2777" id="2777" class="graf graf--p graf-after--p">Because hanging the behavior of existing policies will change the behavior of all cache-like structures in the processor, including TLBs. We will want to change the replacement policy only in L1 caches and leave the behavior of TLBs, L2 caches, etc. unchanged! So we must add a new NXLRU policy instead of modifying the existing LRU (or RANDOM) code.</p><p name="0c8f" id="0c8f" class="graf graf--p graf-after--p">After modification, we have to copy the files in the shared folder to the sesc library by,</p><pre name="af5a" id="af5a" class="graf graf--pre graf-after--p">$ cp /media/sf_CS6290/sesc/src/libsuc/<code class="markup--code markup--pre-code">CacheCore.h ~/</code>sesc/src/libsuc/<code class="markup--code markup--pre-code">CacheCore.h<br>$ </code>cp /media/sf_CS6290/sesc/src/libsuc/<code class="markup--code markup--pre-code">CacheCore.cpp ~/</code>sesc/src/libsuc/<code class="markup--code markup--pre-code">CacheCore.cpp</code></pre><p name="a818" id="a818" class="graf graf--p graf-after--pre">Then we have to rebuild the <code class="markup--code markup--p-code">sesc</code> simulator by,</p><pre name="d07b" id="d07b" class="graf graf--pre graf-after--p">$ cd ~/sesc<br>$ make</pre><p name="9668" id="9668" class="graf graf--p graf-after--pre">Now, let’s run a simulation with a 2kB L1 cache, using NXLRU policy, and with all other settings at their default values. The configuration file should be named as <code class="markup--code markup--p-code">cmp4-noc-L1NXLRU.conf</code>.The simulation report for this should be named as <code class="markup--code markup--p-code">sesc_fmm.mipseb.L1NXLRU</code>.</p><pre name="0e65" id="0e65" class="graf graf--pre graf-after--p">$ ~/sesc/sesc.opt -f <code class="markup--code markup--pre-code">L1NXLRU</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-L1NXLRU.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1</pre><p name="a4d0" id="a4d0" class="graf graf--p graf-after--pre">We can then read these reports by,</p><pre name="e62e" id="e62e" class="graf graf--pre graf-after--p">$ ~/sesc/scripts/report.pl <code class="markup--code markup--pre-code">sesc_fmm.mipseb.L1NXLRU</code></pre><p name="ebd3" id="ebd3" class="graf graf--p graf-after--pre">Because <code class="markup--code markup--p-code">report.pl</code> does not provide summary statistics on the L2 cache, you will have to directly examine the report file generated by SESC for knowing the number of blocks that are fetched for L1 and L2.</p><pre name="ad0a" id="ad0a" class="graf graf--pre graf-after--p">$ cat sesc_fmm.mipseb.L1NXLRU | more</pre><p name="5d58" id="5d58" class="graf graf--p graf-after--pre">This file begins with a copy of the configuration that was used, then reports how many events of each kind were observed in each part of the processor. Events in the DL1 cache of processor zero (the one running the application) are reported in lines that start with <code class="markup--code markup--p-code">P(0)_DL1:</code>.</p><p name="9bc9" id="9bc9" class="graf graf--p graf-after--p">In the report file, the number of blocks requested by the L1 cache from the L2 cache is reported as <code class="markup--code markup--p-code">lineFill</code> (these become entire-block reads from the L2 cache), and the number of write-backs the L1 wants to do to the L2 is reported as <code class="markup--code markup--p-code">writeBack</code> (these become entire-block writes to the L2 cache). Then if we want to get the block reads from L2, we can use,</p><pre name="41be" id="41be" class="graf graf--pre graf-after--p">$ cat sesc_fmm.mipseb.L1NXLRU | grep &quot;P(0)_DL1:lineFill&quot;</pre><p name="b75c" id="b75c" class="graf graf--p graf-after--pre">Compare this result with the <code class="markup--code markup--p-code">sesc_fmm.mipseb.SmallL1</code> report that we have generated in experiment 1, you are expected to find that the NXLRU will have more cache reads to L2 because this policy is worse than LRU.</p><p name="e1e8" id="e1e8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Experiment 3: Misses Classification</strong></p><p name="2763" id="2763" class="graf graf--p graf-after--p">Now we will change the simulator to identify what kind of L1 cache miss we are having each time. Recall that the misses can be,</p><ul class="postList"><li name="fa5a" id="fa5a" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">compulsory</strong>: a miss is a compulsory miss if it would occur in an infinite-sized cache, i.e. if the block has never been in the cache before</li><li name="3c0a" id="3c0a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">capacity</strong>: a non-compulsory miss that would occur even in a fully associative LRU cache that has the same block size and overall capacity</li><li name="a5a7" id="a5a7" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">conflict</strong>: a miss that is neither a compulsory nor a capacity miss</li></ul><p name="ce99" id="ce99" class="graf graf--p graf-after--li">The L1 cache in the simulator counts read and write misses in separate counters, which appear in the simulation report as <code class="markup--code markup--p-code">readMiss</code> and <code class="markup--code markup--p-code">writeMiss</code> number for each cache. For example, there is line in the report for <code class="markup--code markup--p-code">P(0)_DL1:readMiss=something</code> in the report file. This is implement in the file <code class="markup--code markup--p-code">SMPCache.h</code> and <code class="markup--code markup--p-code">SMPCache.cpp</code> by the following variables,</p><pre name="6cb4" id="6cb4" class="graf graf--pre graf-after--p">GStatsCntr readMiss;<br>GStatsCntr writeMiss;</pre><p name="8edc" id="8edc" class="graf graf--p graf-after--pre">Now we need to have additional counters, which should appear in the simulation report file as <code class="markup--code markup--p-code">compMiss</code>, <code class="markup--code markup--p-code">capMiss</code>, and <code class="markup--code markup--p-code">confMiss</code> counters (these three values should add up to the readMiss+writeMiss value). Each of the new counters should count both read and write misses of that kind.</p><p name="a42c" id="a42c" class="graf graf--p graf-after--p">Note that we can also have counters that count compulsory, capacity, and conflict misses <strong class="markup--strong markup--p-strong">separately for reads and writes</strong>, or to do this classification of misses for other caches. But we must should the overall result in the report.</p><p name="f4ef" id="f4ef" class="graf graf--p graf-after--p">From the <code class="markup--code markup--p-code">SMPCache.cpp</code> file, we can find out that the <code class="markup--code markup--p-code">readMiss</code> and <code class="markup--code markup--p-code">writeMiss</code> increases in the <code class="markup--code markup--p-code">doRead</code> and <code class="markup--code markup--p-code">dowrite</code>. So we may consider modifying something in these methods.</p><p name="54ff" id="54ff" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Another potentially confusing</strong> <strong class="markup--strong markup--p-strong">consideration</strong> is that it is possible to have an access that is a hit in a set-associative cache but it a miss in the fully associative cache that we are modeling to determine if a cache miss is a conflict miss.</p><p name="93f2" id="93f2" class="graf graf--p graf-after--p">After modification, we have to copy the files in the shared folder to the sesc library by,</p><pre name="d71c" id="d71c" class="graf graf--pre graf-after--p">$ cp /media/sf_CS6290/sesc/src/libcmp/SMPCache.h<code class="markup--code markup--pre-code"> ~/</code>sesc/src/libcmp/SMPCache.h<code class="markup--code markup--pre-code"><br>$ </code>cp /media/sf_CS6290/sesc/src/libcmp/SMPCache.cpp <code class="markup--code markup--pre-code">~/</code>sesc/src/libcmp/SMPCache.cpp</pre><p name="7676" id="7676" class="graf graf--p graf-after--pre">Then we have to rebuild the <code class="markup--code markup--p-code">sesc</code> simulator by,</p><pre name="39e1" id="39e1" class="graf graf--pre graf-after--p">$ cd ~/sesc<br>$ make</pre><p name="125d" id="125d" class="graf graf--p graf-after--pre">With your new miss-classification code in the simulator, you should run a simulation with,</p><ul class="postList"><li name="95fa" id="95fa" class="graf graf--li graf-after--p">the default configuration (32kB 4-way set-associative LRU L1, cache)</li><li name="8c29" id="8c29" class="graf graf--li graf-after--li">the 2kB 4-way set-associative LRU L1 cache</li><li name="b9a1" id="b9a1" class="graf graf--li graf-after--li">the direct-mapped 32kB L1 cache</li><li name="8767" id="8767" class="graf graf--li graf-after--li">the 32kB 4-way set-associative NXLRU L1 cache</li></ul><p name="32b7" id="32b7" class="graf graf--p graf-after--li">We have implemented some of the configuration files above. And the configuration files should be,</p><ul class="postList"><li name="622f" id="622f" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">cmp4-noc.conf</code></li><li name="efce" id="efce" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">cmp4-noc-SmallL1.conf</code></li><li name="08ce" id="08ce" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">cmp4-noc-DMapL1.conf</code></li></ul><p name="4ce5" id="4ce5" class="graf graf--p graf-after--li">We haven’t got the last configuration file and we have to make a new one named <code class="markup--code markup--p-code">cmp4-noc-DefNXLRU.conf</code>.</p><p name="2bde" id="2bde" class="graf graf--p graf-after--p">Then we can generate the new reports by,</p><pre name="0b3f" id="0b3f" class="graf graf--pre graf-after--p">$ ~/sesc/sesc.opt -f <code class="markup--code markup--pre-code">DefLRU</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1<br>$ ~/sesc/sesc.opt -f <code class="markup--code markup--pre-code">SmallLRU</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-SmallL1.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1<br>$ ~/sesc/sesc.opt -f <code class="markup--code markup--pre-code">DefDM</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-DMapL1.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1<br>$ ~/sesc/sesc.opt -f <code class="markup--code markup--pre-code">DefNXLRU</code> -c ~/sesc/confs/<code class="markup--code markup--pre-code">cmp4-noc-DefNXLRU.conf</code> -iInput/input.256 -ofmm.out -efmm.err fmm.mipseb -p 1</pre><p name="6480" id="6480" class="graf graf--p graf-after--pre">And the newly generated reports are,</p><ul class="postList"><li name="d326" id="d326" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">sesc_fmm.mipseb.DefLRU</code></li><li name="6d49" id="6d49" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">sesc_fmm.mipseb.SmallLRU</code></li><li name="a2d9" id="a2d9" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">sesc_fmm.mispeb.DefDM</code></li><li name="f31f" id="f31f" class="graf graf--li graf-after--li graf--trailing"><code class="markup--code markup--li-code">sesc_fmm.mispeb.DefNXLRU</code></li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/e4d50f24d217"><time class="dt-published" datetime="2021-03-15T08:58:19.005Z">March 15, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/high-performance-computer-architecture-25-cache-experiment-e4d50f24d217" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>