<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>High-Performance Computer Architecture 7 | Branch Prediction Part 1</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">High-Performance Computer Architecture 7 | Branch Prediction Part 1</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: High-Performance Computer Architecture
</section>
<section data-field="body" class="e-content">
<section name="0219" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="412f" id="412f" class="graf graf--h3 graf--leading graf--title">High-Performance Computer Architecture 7 | <strong class="markup--strong markup--h3-strong">Branch Prediction Part 1</strong></h3><figure name="554b" id="554b" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*juKVnGhup43FctyG.png" data-width="1446" data-height="864" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*juKVnGhup43FctyG.png"></figure><p name="7a3e" id="7a3e" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">1. Branch Penalty in a Pipeline</strong></p><p name="a36c" id="a36c" class="graf graf--p graf-after--p">Let’s see the following code,</p><pre name="698f" id="698f" class="graf graf--pre graf-after--p">BEQ R1, R2, Label</pre><p name="ab05" id="ab05" class="graf graf--p graf-after--pre">A branch instruction like <code class="markup--code markup--p-code">BEQ</code> in the code above compares registers R1 and R2. And if they are equal, then we jump to the <code class="markup--code markup--p-code">Label</code>. This is usually implemented by having the <strong class="markup--strong markup--p-strong">difference</strong> between the next instruction’s PC and the PC that should be at the label in the immediate part of the instruction field. So effectively, if R1 and R2 are equal, the branch would just add the immediate operand to its current PC that is computed for the next instruction.</p><p name="5d1e" id="5d1e" class="graf graf--p graf-after--p">Thus, if <code class="markup--code markup--p-code">R1 != R2</code> , then <code class="markup--code markup--p-code">PC++</code> (only increment the PC, move 4 bytes). Else if <code class="markup--code markup--p-code">R1 == R2</code> , then <code class="markup--code markup--p-code">PC = PC + 4 + Imm</code> (increment the PC and also add the immediate, move to the <code class="markup--code markup--p-code">Label</code>).</p><p name="0973" id="0973" class="graf graf--p graf-after--p">In the pipeline, we always assume (or predict) that the branch will not be working because we fetch the new instructions before we know the instruction is a branch (at the <code class="markup--code markup--p-code">DECODE</code> phase) and before we know whether or not it will branch (at the <code class="markup--code markup--p-code">ALU</code> phase).</p><p name="b9e9" id="b9e9" class="graf graf--p graf-after--p">Now there are two possibilities. If our prediction is right and the branch is not effective, then there will be no penalty. However, if we mispredict the result, the branch instruction (in our case, the <code class="markup--code markup--p-code">BEQ</code> instruction) will take 3 cycles because of the pipeline flushes (1 cycle for BEQ, 2 idle cycles for the penalty).</p><p name="012c" id="012c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Disadvantage of Stalls after Branch Instead of Flushes</strong></p><p name="1530" id="1530" class="graf graf--p graf-after--p">You can also see why it never pays to not fetch anything after the branch. If we don’t fetch anything after the branch until we are sure about what to fetch, then we are guaranteed to have two empty slots after the branch. So somehow in that case, regardless of whether we would have guessed correctly or not, we have a two-cycle penalty. Because we would rather have the 2-cycle penalty some of the time than all of the time, we would like to predict instead of stalling after all the branches.</p><p name="9674" id="9674" class="graf graf--p graf-after--p">Another thing that is important is that right after the FETCH stage, we don’t know the instruction is a branch instruction (we have just obtained the instruction word, which is a 4-byte value). So the instruction after the branch instruction must be fetched because we don’t even know whether it is a branch or not before the instruction is decoded.</p><p name="2ca1" id="2ca1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Branch Prediction Requirements</strong></p><p name="5b2c" id="5b2c" class="graf graf--p graf-after--p">Thus, if we want to improve the performance of our computer, we have to successfully predict whether our branches are taken or not and where they are going if the branches are taken.</p><p name="8c81" id="8c81" class="graf graf--p graf-after--p">What we have if we want to predict a branch instruction? At the FETCH stage where a prediction is needed, we only know the PC of the current instruction and what we want to predict is the PC of the next instruction to fetch. So our prediction must answer the following questions,</p><ul class="postList"><li name="0062" id="0062" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Is this a taken branch?</strong> : If this is not a branch, then certainly it is not taken. If it is a branch, is it taken?</li><li name="0851" id="0851" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">What is the target PC?</strong> : If it is a taken branch, what is the target PC and where is this branch going?</li></ul><p name="61dc" id="61dc" class="graf graf--p graf-after--li">We have to answer these two questions through our prediction.</p><p name="5dea" id="5dea" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">4. Branch Prediction Accuracy</strong></p><p name="8efe" id="8efe" class="graf graf--p graf-after--p">Our CPI can be written as <code class="markup--code markup--p-code">1 + penalty</code>, which is the CPI we get with the ideal pipelining plus the overall penalty we pay because of the misprediction. The overall penalty can be calculated by the production of <strong class="markup--strong markup--p-strong">how often</strong> we have the mispredictions (this is determined by the <strong class="markup--strong markup--p-strong">predictor accuracy</strong>) and the penalty in terms of cycles we pay for each of these mispredictions (this is determined by the <strong class="markup--strong markup--p-strong">pipeline</strong>). Thus, the overall CPI can be written as,</p><figure name="85ef" id="85ef" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*p8ji8TNMI9cs5RXrDT5bKw.png" data-width="1306" data-height="126" src="https://cdn-images-1.medium.com/max/800/1*p8ji8TNMI9cs5RXrDT5bKw.png"></figure><p name="edfa" id="edfa" class="graf graf--p graf-after--figure">Let’s see an example. Suppose 20% of all instructions are branches. For the first processor, the branch instructions are resolved in the 3rd stage, while for the second one, the branch instructions are resolved in the 10th stage. If we know the predictor accuracy for the branches is 50% and the accuracy for the other instructions is 100%. Then,</p><pre name="9387" id="9387" class="graf graf--pre graf-after--p">CPI for Processor #1: 1 + 20% * 50% * 2 = 1.2<br>CPI for Processor #2: 1 + 20% * 50% * 9 = 1.9</pre><p name="ef86" id="ef86" class="graf graf--p graf-after--pre">Similarly, if we change the predictor accuracy for the branches is 90% and the accuracy for the other instructions is 100%. Then,</p><pre name="d940" id="d940" class="graf graf--pre graf-after--p">CPI for Processor #1: 1 + 20% * 10% * 2 = 1.04<br>CPI for Processor #2: 1 + 20% * 10% * 9 = 1.18</pre><p name="c8d8" id="c8d8" class="graf graf--p graf-after--pre">Therefore, we can conclude that a better branch predictor will help us regardless of whether we have a shallow (or deep) pipeline. When we change the predictor from 50% to 90% branch accuracy, the speedup for the first processor is <code class="markup--code markup--p-code">1.2/1.04 = 1.15</code>, while the speedup for the first processor is <code class="markup--code markup--p-code">1.9/1.18 = 1.61</code>. As you can see, the deeper the pipeline, the more dependent it is on having a good predictor for good performance. In reality, we can actually have predictors significantly better than 90%, so we are still benefiting from this improvement.</p><p name="985e" id="985e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">5. Branch Prediction Benefit Example</strong></p><p name="fc4a" id="fc4a" class="graf graf--p graf-after--p">Suppose we have a standard 5-stage pipeline with branches resolved in the 3rd stage. Let’s assume that this processor is a <strong class="markup--strong markup--p-strong">SAFE</strong> processor, which means that the processor fetches nothing until it is sure about what to fetch. If the processor now execute many iterations of the following program,</p><pre name="75a4" id="75a4" class="graf graf--pre graf-after--p">Loop:<br>    ADDI R1, R1, -1<br>    ADD  R2, R2, R2<br>    BNEZ R1, Loop</pre><p name="f451" id="f451" class="graf graf--p graf-after--pre">Suppose we have an <strong class="markup--strong markup--p-strong">IDEAL</strong> processor, which means that the predictor accuracy for the branch instruction is 100%, then what is the speedup between the ideal processor and the safe processor?</p><p name="b4c3" id="b4c3" class="graf graf--p graf-after--p">It is obvious that for the ideal processor, because all the branches are predicted successfully, then we actually pay no penalty for branches and the overall CPI for this processor is <code class="markup--code markup--p-code">1</code>. To solve this problem, we also have to calculate the overall CPI for the safe processor, and this can be a little bit tricky.</p><p name="2ad0" id="2ad0" class="graf graf--p graf-after--p">Actually, for this safe processor, when in the fetch phase, we don’t know whether it is a branch instruction or not, so we will not fetch the next instruction until the end of the decode phase. Thus, the <code class="markup--code markup--p-code">ADDI</code> instruction and the <code class="markup--code markup--p-code">ADD</code> instruction will take 2 cycles (including 1 idle cycle to wait for the result of decoding). For the branch instruction <code class="markup--code markup--p-code">BNEZ</code>, it will take 3 cycles (including 2 idle cycles to wait for the result of decoding and to wait for the result of where to branch). So the overall CPI for this safe processor should be <code class="markup--code markup--p-code">(2 + 2 + 3) / 3 = 2.33</code> and the speedup should be <code class="markup--code markup--p-code">2.33/1 = 2.33</code>. We will discuss more of this in the next segment.</p><p name="a4e0" id="a4e0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">6. Refuse to Predict VS. Not-Taken Predictor</strong></p><p name="dea8" id="dea8" class="graf graf--p graf-after--p">According to what we have seen in the example above, if we refuse to predict the branch instructions, a branch instruction will take <code class="markup--code markup--p-code">3</code> cycles and the other instructions will also take <code class="markup--code markup--p-code">2</code> cycles instead of only one cycle.</p><p name="fe84" id="fe84" class="graf graf--p graf-after--p">Let’s see a comparison, suppose we predict the branches with a <strong class="markup--strong markup--p-strong">not-taken</strong> <strong class="markup--strong markup--p-strong">predictor</strong> (means that by default, we assume that all the branches are not taken). Then a branch instruction will take <code class="markup--code markup--p-code">3</code> cycles (when the branch is actually taken) or <code class="markup--code markup--p-code">1</code> cycle (when the branch is finally not taken) and the other instructions will also take only <code class="markup--code markup--p-code">1</code> cycle.</p><figure name="b49f" id="b49f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*opSFrX7wTckTuhCHBQrEYA.png" data-width="1666" data-height="304" src="https://cdn-images-1.medium.com/max/800/1*opSFrX7wTckTuhCHBQrEYA.png"></figure><p name="39ac" id="39ac" class="graf graf--p graf-after--figure">By this relationship, we can draw the conclusion that the <code class="markup--code markup--p-code">predict not taken</code> can always win over the <code class="markup--code markup--p-code">refuse to predict</code>. This is why every processor is going to do some sort of prediction even the prediction is simply to assume that the instructions are not taken by default.</p><p name="b036" id="b036" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">7. The Simplest Predictor: Not-Taken Predictor</strong></p><p name="8c79" id="8c79" class="graf graf--p graf-after--p">The not-taken predictor is actually the simplest predictor and now we would like to talk more about it. The predictor is the simplest because all it requires to do is to increase the PC. We know the PC from the instruction we fetch and we also know how big the instruction is (4 bytes), so we can simply increase the PC for this predictor.</p><p name="cd09" id="cd09" class="graf graf--p graf-after--p">The advantage of this predictor is that,</p><ul class="postList"><li name="65e0" id="65e0" class="graf graf--li graf-after--p">It requires no memories</li><li name="528f" id="528f" class="graf graf--li graf-after--li">It requires no other operations</li></ul><p name="cb09" id="cb09" class="graf graf--p graf-after--li">Based on the rule of thumb, 20% of all the instructions are branches, so 80% of the time, this predictor must be correct because the instructions are simply not branches. For branches, a little more than 50% (we will use 60% as its value in this explanation) of branches are actually taken. Therefore, the proportion when this predictor is correct is <code class="markup--code markup--p-code">80% + 20% * (1 — 60%) = 88%</code> and the incorrect proportion is <code class="markup--code markup--p-code">100% — 88% = 12%</code> (or this can be calculated by <code class="markup--code markup--p-code">60% * 20% = 12%</code>).</p><p name="6bc2" id="6bc2" class="graf graf--p graf-after--p">If we know the <code class="markup--code markup--p-code">penalty</code> of this pipeline, we can also calculate the impact on the overall CPI. The CPI will be <code class="markup--code markup--p-code">1 + 12% * penalty</code>. Specifically, in a standard 5-stage pipeline, the <code class="markup--code markup--p-code">penalty</code> will be <code class="markup--code markup--p-code">2</code> and then the overall CPI should be <code class="markup--code markup--p-code">1.24</code>.</p><p name="7a07" id="7a07" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">8. Why we need other predictors?</strong></p><p name="291a" id="291a" class="graf graf--p graf-after--p">We have seen that the not-taken predictor is simple and it predicts correctly with a prediction accuracy of 88%. So why do we need any better predictors? Let’s see the following table. Say we have two predictors, one is a standard not-taken predictor with an accuracy of 88%, and the other is an improved predictor with an accuracy of 99%,</p><figure name="4c30" id="4c30" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*JneVVetahDJf5TZzPnnVZQ.png" data-width="1536" data-height="306" src="https://cdn-images-1.medium.com/max/800/1*JneVVetahDJf5TZzPnnVZQ.png"></figure><p name="4999" id="4999" class="graf graf--p graf-after--figure">The larger the pipeline, the greater the penalty, especially when the branches are detected later in the pipeline and there are multiple instructions per cycle. This also means that there is a lot of waste from a misprediction, especially if it is a deep (more stages) and/or wide (more instructions per cycle) pipeline.</p><p name="5633" id="5633" class="graf graf--p graf-after--p graf--trailing">In the next section, we are going to talk about the predictors with better accuracy.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/943d454cecb9"><time class="dt-published" datetime="2021-01-20T15:42:37.069Z">January 20, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/high-performance-computer-architecture-7-branch-prediction-part-1-943d454cecb9" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>