<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Probability and Statistics 3 | Random Experiment, Probability Mass Function, Probability Density…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Probability and Statistics 3 | Random Experiment, Probability Mass Function, Probability Density…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Probability and Statistics
</section>
<section data-field="body" class="e-content">
<section name="134c" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6051" id="6051" class="graf graf--h3 graf--leading graf--title">Probability and Statistics 3 | <strong class="markup--strong markup--h3-strong">Random Experiment, Probability Mass Function, Probability Density Function, and Cumulative Density Function</strong></h3><figure name="6bd8" id="6bd8" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*YTeSIjiYirbk4CZavQXCqg.jpeg" data-width="1602" data-height="1141" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*YTeSIjiYirbk4CZavQXCqg.jpeg"></figure><ol class="postList"><li name="f27a" id="f27a" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Random Experiment</strong></li></ol><p name="11f4" id="11f4" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) The Definition of Random Experiment and Outcome</strong></p><p name="e890" id="e890" class="graf graf--p graf-after--p">A <strong class="markup--strong markup--p-strong">random experiment </strong>is any activity, process, or action that produces a non-deterministic (i.e. Stochastic) outcome. An <strong class="markup--strong markup--p-strong">outcome</strong> is a result of a random experiment. The set of all possible outcomes is called the <strong class="markup--strong markup--p-strong">sample space</strong>.</p><p name="0f3b" id="0f3b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) The Definition of Random Variable (aka. r.m.)</strong></p><p name="9558" id="9558" class="graf graf--p graf-after--p">A <strong class="markup--strong markup--p-strong">random variable</strong> is a <em class="markup--em markup--p-em">function from</em> {the set of all possible outcomes from some random experiment} to the <em class="markup--em markup--p-em">real number line</em>. The notations of the random variable are capitalized letters, for example, X, Y.</p><p name="766d" id="766d" class="graf graf--p graf-after--p">For example, choose 25 folks inside the United States at random (and without replacement). Call a particular outcome <em class="markup--em markup--p-em">w</em>1.</p><ul class="postList"><li name="e694" id="e694" class="graf graf--li graf-after--p">X(<em class="markup--em markup--li-em">w</em>1) = averages the heights (in centimeters) of the folks associated with <em class="markup--em markup--li-em">w</em>1.</li><li name="789a" id="789a" class="graf graf--li graf-after--li">Y(<em class="markup--em markup--li-em">w</em>1) = max weight (in kilograms) of the folks associated with <em class="markup--em markup--li-em">w</em>1.</li></ul><p name="7737" id="7737" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) The Definition of Random Vector</strong></p><p name="e4e0" id="e4e0" class="graf graf--p graf-after--p">A <strong class="markup--strong markup--p-strong">random vector</strong> is a<em class="markup--em markup--p-em"> function from</em> {the set of all possible outcomes from some random experiment} to <em class="markup--em markup--p-em">real space</em>, or ℝⁿ, or n-dimensional real space. The notations of the random variable are capitalized bold letters, for example, <strong class="markup--strong markup--p-strong">X<em class="markup--em markup--p-em"> </em></strong>and<strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em"> </em>Y</strong>. For example,</p><ul class="postList"><li name="7881" id="7881" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">X</strong>(<em class="markup--em markup--li-em">w</em>1) = &lt;X(<em class="markup--em markup--li-em">w</em>1), Y(<em class="markup--em markup--li-em">w</em>1)&gt;</li><li name="85f1" id="85f1" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">X</strong>(<em class="markup--em markup--li-em">w</em>1) = &lt;160, 67&gt;</li><li name="57b4" id="57b4" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">X</strong>(<em class="markup--em markup--li-em">w2</em>) = &lt;145, 72&gt;</li><li name="ce3a" id="ce3a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">X</strong>(<em class="markup--em markup--li-em">w3</em>) = &lt;164, 80&gt;</li></ul><figure name="b30b" id="b30b" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*adWZUVGOFaxKaYGeEzmWoQ.png" data-width="1632" data-height="860" src="https://cdn-images-1.medium.com/max/800/1*adWZUVGOFaxKaYGeEzmWoQ.png"></figure><p name="a445" id="a445" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">2. Types of Data or Random Variables</strong></p><p name="3820" id="3820" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Binary (aka. Bernoulli)</strong>: the data are either <strong class="markup--strong markup--p-strong">zeros or ones</strong> or can be mapped to such. For example:</p><ul class="postList"><li name="5396" id="5396" class="graf graf--li graf-after--p">bio gender</li><li name="9e5c" id="9e5c" class="graf graf--li graf-after--li">{switch is off, switch is on} ← mutually exclusive</li></ul><p name="bfab" id="bfab" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Categorical: </strong>the data that maps into<strong class="markup--strong markup--p-strong"> mutually exclusive categories</strong>. For example,</p><ul class="postList"><li name="fed6" id="fed6" class="graf graf--li graf-after--p">Integrated Postsecondary Education Data System</li><li name="b2ba" id="b2ba" class="graf graf--li graf-after--li">Race / Ethnicity</li><li name="daff" id="daff" class="graf graf--li graf-after--li">{A+, A, A-, B+, B, B-, C+, C, C-, F}</li></ul><p name="8a99" id="8a99" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Ordinal: </strong>This is categorical data that admits a <strong class="markup--strong markup--p-strong">natural ordering</strong>. For example,</p><ul class="postList"><li name="7350" id="7350" class="graf graf--li graf-after--p">grades</li><li name="8ea7" id="8ea7" class="graf graf--li graf-after--li">quartiles</li><li name="4db0" id="4db0" class="graf graf--li graf-after--li">{1st place, 2nd place, 3rd place}</li></ul><p name="be54" id="be54" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Continuous (aka. Quantitative or Numerical):</strong> The data that maps naturally onto the real number line. For example,</p><ul class="postList"><li name="b60f" id="b60f" class="graf graf--li graf-after--p">the stock price</li><li name="fe3b" id="fe3b" class="graf graf--li graf-after--li">temperatures</li><li name="95dd" id="95dd" class="graf graf--li graf-after--li">heights</li></ul><p name="4b86" id="4b86" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">3. Probability Mass Function (PMF)</strong></p><p name="743c" id="743c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Support Set</strong></p><p name="5be3" id="5be3" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">support set</strong> A of some random variable X is all those real values that can be or might be, naturally obtained by X. While <em class="markup--em markup--p-em">x</em> is an element (one of the real value of the random variable X) of the support set A. For example,</p><ul class="postList"><li name="b54f" id="b54f" class="graf graf--li graf-after--p">ℝ* is the support set for a random variable that measures the height.</li><li name="faa9" id="faa9" class="graf graf--li graf-after--li">Roll a die and look at the top face. The support set A = {1, 2, 3, 4, 5, 6}, and <em class="markup--em markup--li-em">x</em> could be 1 or 2 or 3 or 4 or 5 or 6.</li></ul><p name="197d" id="197d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) The Definition of the Probability Mass Function</strong></p><p name="204d" id="204d" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">probability mass function</strong> is a function <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) → ℝ, where A is the <strong class="markup--strong markup--p-strong">support set</strong> of an associated random variable X and <em class="markup--em markup--p-em">p</em> is called the<strong class="markup--strong markup--p-strong"> probability mass</strong>, satisfies the following two properties,</p><ul class="postList"><li name="74ad" id="74ad" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Axiom #1(Non-negativity)</strong>: If x ∈ A, <em class="markup--em markup--li-em">p</em>(<em class="markup--em markup--li-em">x</em>) = ℙ(X = <em class="markup--em markup--li-em">x</em>) = ℙ({ <em class="markup--em markup--li-em">w</em>∈Ω | X(<em class="markup--em markup--li-em">w</em>) = <em class="markup--em markup--li-em">x </em>}) ≥ 0</li><li name="179b" id="179b" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Axiom #2 (Unity)</strong>: for <em class="markup--em markup--li-em">x</em>∈A,</li></ul><figure name="d8e3" id="d8e3" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*LfUb_IBMSagBr7Kfh9qEaw.png" data-width="1632" data-height="112" src="https://cdn-images-1.medium.com/max/800/1*LfUb_IBMSagBr7Kfh9qEaw.png"></figure><p name="1b9f" id="1b9f" class="graf graf--p graf-after--figure">Note that we haven’t got an axiom #3 here. This is partly because the form of the countable additivity (or Axiom #3) is quite simple and obvious to <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) and we can directly compute that from Axiom #1. The proof is,</p><p name="e276" id="e276" class="graf graf--p graf-after--p">Proof:</p><p name="d49f" id="d49f" class="graf graf--p graf-after--p">Suppose that we have infinite random variables X1, X2, X3, … which are mutually exclusive. Given Xi, ∀ real values <em class="markup--em markup--p-em">x</em>i of the support set Ai would satisfy,</p><figure name="7f96" id="7f96" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jvSpiind07Rg9dMpsOHqKw.png" data-width="1632" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*jvSpiind07Rg9dMpsOHqKw.png"></figure><p name="4bae" id="4bae" class="graf graf--p graf-after--figure">So, we can then have,</p><figure name="051f" id="051f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*gUnTfj5SLbbqYv5YQ9Zk-Q.png" data-width="1632" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*gUnTfj5SLbbqYv5YQ9Zk-Q.png"></figure><p name="ed0a" id="ed0a" class="graf graf--p graf-after--figure">So it would be possible if we write,</p><figure name="4be0" id="4be0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*V6f7iN21epRgJaLtW2ZZaA.png" data-width="1632" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*V6f7iN21epRgJaLtW2ZZaA.png"></figure><p name="22d6" id="22d6" class="graf graf--p graf-after--figure">Well, this notation is not commonly used and just a simplified version of proving Axiom #3. It may have some contradiction in the notation because when we talk about <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>), we usually talk about one <strong class="markup--strong markup--p-strong">SINGLE</strong> random variable X. But in the proof before, we obtained these “<em class="markup--em markup--p-em">x</em>i”s from different random variable Xi. So that may be confused, and I want to clarify that this is not a rigorous proof.</p><p name="a17f" id="a17f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) The Notation of Probability Mass Function</strong></p><p name="7e5a" id="7e5a" class="graf graf--p graf-after--p">In the previous proof, we can find out that the PMF <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) is highly related to the random variable X. So in order to stress the dependence of probability mass <em class="markup--em markup--p-em">p</em> on X, we often write notations like,</p><figure name="0b9c" id="0b9c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LOlSqGyS20ucH1c56d3QSQ.png" data-width="1632" data-height="74" src="https://cdn-images-1.medium.com/max/800/1*LOlSqGyS20ucH1c56d3QSQ.png"></figure><p name="8648" id="8648" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Probability Mass Function: Die Rolling Example</strong></p><p name="8b2a" id="8b2a" class="graf graf--p graf-after--p">In this case, we have six discrete outcomes as Ω = {“top face = 1”, “top face = 2”, “top face = 3”, “top face = 4”, “top face = 5”, “top face = 6”}. For each of the outcome <em class="markup--em markup--p-em">w</em>i ∈Ω, the random variable function X(<em class="markup--em markup--p-em">w</em>i) changes different outcomes into discrete numbers. For example, X(“top face = 5”) = 5.</p><p name="4f88" id="4f88" class="graf graf--p graf-after--p">Therefore, as we have told that the support set A of X equals {1, 2, 3, 4, 5, 6}, and each of the elements in this set is reckoned to be the real value <em class="markup--em markup--p-em">x</em>. So because all the real values, in this case, are equally likely, then we can have the probability mass <em class="markup--em markup--p-em">p</em> as,</p><figure name="af5d" id="af5d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*2ROxjsiqtOYn2P0fHd55Tw.png" data-width="1656" data-height="148" src="https://cdn-images-1.medium.com/max/800/1*2ROxjsiqtOYn2P0fHd55Tw.png"></figure><figure name="cb40" id="cb40" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*ezSdi3ij1rR-R9CY5pWlew.png" data-width="1656" data-height="342" src="https://cdn-images-1.medium.com/max/800/1*ezSdi3ij1rR-R9CY5pWlew.png"></figure><p name="7aa5" id="7aa5" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">4. Probability Density Function (PDF)</strong></p><p name="e23d" id="e23d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of Probability Density Function</strong></p><p name="1457" id="1457" class="graf graf--p graf-after--p">A probability density function (PDF) is a function <em class="markup--em markup--p-em">f</em> from the real number to the real number line. For example, <em class="markup--em markup--p-em">f</em>: ℝ (or we could say the support set) → ℝ. It has two properties:</p><ul class="postList"><li name="8082" id="8082" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Non-negative</strong>: ∀ <em class="markup--em markup--li-em">x</em> ∈ℝ, <em class="markup--em markup--li-em">f</em>(<em class="markup--em markup--li-em">x</em>) ≥ 0, because a negative one will violate Axiom #1</li><li name="9195" id="9195" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Unity:</strong></li></ul><figure name="cace" id="cace" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*ed3-obLh_MXwLt8CrKP5iw.png" data-width="1656" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*ed3-obLh_MXwLt8CrKP5iw.png"></figure><p name="18b1" id="18b1" class="graf graf--p graf-after--figure">Note that it is not a requirement on <em class="markup--em markup--p-em">f </em>that 0 ≤ <em class="markup--em markup--p-em">f</em>(<em class="markup--em markup--p-em">x</em>) ≤ 1, ∀ <em class="markup--em markup--p-em">x</em> ∈ℝ. However, it is a requirement for <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) that 0 ≤ <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) ≤ 1. And also, because we want to stress the dependence of probability mass <em class="markup--em markup--p-em">f</em> on X, we write notations as,</p><figure name="a046" id="a046" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*xVz8XWWbsl40ihUDpB_2qw.png" data-width="1656" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*xVz8XWWbsl40ihUDpB_2qw.png"></figure><p name="0c9f" id="0c9f" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Probability Density Function: An Example</strong></p><p name="7c11" id="7c11" class="graf graf--p graf-after--p">The PDF of a normal variable is given by,</p><figure name="dace" id="dace" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*RfDDPZzJBKlSP1dQ4XicCQ.png" data-width="1656" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*RfDDPZzJBKlSP1dQ4XicCQ.png"></figure><p name="c0a0" id="c0a0" class="graf graf--p graf-after--figure">We denote such a situation, i.e., where X is normal by X ~ N(μ, σ²). If we take σ → ∞, f becomes large about μ ⇒ f ≰ 1. Especially, if X ~ N(0, 1), it is called standard normal.</p><p name="30ce" id="30ce" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) The Proof of Whether a Proper PMF or a Proper PDF</strong></p><p name="4ffa" id="4ffa" class="graf graf--p graf-after--p">We use Infinite Series to prove a proper PMF and we use Integration to prove a proper PDF. For example:</p><ul class="postList"><li name="2f63" id="2f63" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Example 1</strong>. Is this a proper PMF?</li></ul><figure name="e51c" id="e51c" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*C3fB4Mu9I3Sam-68tWSr0A.png" data-width="1656" data-height="164" src="https://cdn-images-1.medium.com/max/800/1*C3fB4Mu9I3Sam-68tWSr0A.png"></figure><p name="e3af" id="e3af" class="graf graf--p graf-after--figure">Clearly that <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) ≥ 0, so we have to prove unity. Then,</p><figure name="5bef" id="5bef" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*MAXr1avIRvqrCJHTrunGIA.png" data-width="1656" data-height="140" src="https://cdn-images-1.medium.com/max/800/1*MAXr1avIRvqrCJHTrunGIA.png"></figure><ul class="postList"><li name="1087" id="1087" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Example 2</strong>. Is this a proper PDF?</li></ul><figure name="cca1" id="cca1" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*tc7QPIayNYx32e65pkJiFw.png" data-width="1656" data-height="140" src="https://cdn-images-1.medium.com/max/800/1*tc7QPIayNYx32e65pkJiFw.png"></figure><p name="e236" id="e236" class="graf graf--p graf-after--figure">Clearly that <em class="markup--em markup--p-em">f</em>(<em class="markup--em markup--p-em">x</em>) ≥ 0, so we have to prove unity. Then,</p><figure name="71e6" id="71e6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*EaOKjG_n6ZGfebTBGH48DQ.png" data-width="1494" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*EaOKjG_n6ZGfebTBGH48DQ.png"></figure><p name="aaef" id="aaef" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">5. Cumulative Distribution Function (CDF)</strong></p><p name="7a5b" id="7a5b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of Cumulative Density Function</strong></p><p name="55ce" id="55ce" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">cumulative distribution function</strong> is another way of encoding the information in the PDF or PMF. It is typically denoted<em class="markup--em markup--p-em"> F</em> or <em class="markup--em markup--p-em">F</em>x(<em class="markup--em markup--p-em">t</em>).</p><figure name="cb06" id="cb06" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tAMSgxTYqEIOicpHAzQjeA.png" data-width="1648" data-height="240" src="https://cdn-images-1.medium.com/max/800/1*tAMSgxTYqEIOicpHAzQjeA.png"></figure><p name="727f" id="727f" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Cumulative Density Function: A Discrete Example</strong></p><p name="7bdc" id="7bdc" class="graf graf--p graf-after--p">For example,</p><figure name="d5f8" id="d5f8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YmO8PXO1s_FKAtZBAh4eQQ.png" data-width="1352" data-height="206" src="https://cdn-images-1.medium.com/max/800/1*YmO8PXO1s_FKAtZBAh4eQQ.png"></figure><figure name="b2d9" id="b2d9" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*KA10Yl8qfliaq7c_4nfVmQ.png" data-width="1508" data-height="322" src="https://cdn-images-1.medium.com/max/800/1*KA10Yl8qfliaq7c_4nfVmQ.png"></figure><p name="6919" id="6919" class="graf graf--p graf-after--figure">For a discrete random variable X,</p><figure name="73d5" id="73d5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9o3__zCzUi0c-akq38NXSA.png" data-width="1508" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*9o3__zCzUi0c-akq38NXSA.png"></figure><figure name="3268" id="3268" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*jiUerwi9c3Im6x7YOVPuxg.png" data-width="1224" data-height="324" src="https://cdn-images-1.medium.com/max/800/1*jiUerwi9c3Im6x7YOVPuxg.png"></figure><p name="4666" id="4666" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) Cumulative Density Function: A Continuous Example</strong></p><p name="3035" id="3035" class="graf graf--p graf-after--p">For example,</p><figure name="d661" id="d661" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*QJCPYFk8U24eWqQUwesceQ.png" data-width="1376" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*QJCPYFk8U24eWqQUwesceQ.png"></figure><figure name="0bb6" id="0bb6" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*C60usQBdwe_psa5ELiAl-A.png" data-width="1164" data-height="286" src="https://cdn-images-1.medium.com/max/800/1*C60usQBdwe_psa5ELiAl-A.png"></figure><p name="e2f9" id="e2f9" class="graf graf--p graf-after--figure">For a continuous random variable X,</p><figure name="99c3" id="99c3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*6i5TcX33LUigIJgmyW5JWg.png" data-width="1828" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*6i5TcX33LUigIJgmyW5JWg.png"></figure><figure name="1173" id="1173" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*jUKQNwtYu0tMGcfk6-HBjA.png" data-width="1516" data-height="312" src="https://cdn-images-1.medium.com/max/800/1*jUKQNwtYu0tMGcfk6-HBjA.png"></figure><p name="90cc" id="90cc" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Probabilities of Cumulative Density Functions: </strong>Every function F is a CDF if,</p><ul class="postList"><li name="dd68" id="dd68" class="graf graf--li graf-after--p"><em class="markup--em markup--li-em">F</em> is <strong class="markup--strong markup--li-strong">non-decreasing</strong>, i.e., if <em class="markup--em markup--li-em">s</em> ≤ <em class="markup--em markup--li-em">t</em>, <em class="markup--em markup--li-em">F</em>(<em class="markup--em markup--li-em">s</em>) ≤ <em class="markup--em markup--li-em">F</em>(<em class="markup--em markup--li-em">t</em>)</li><li name="c678" id="c678" class="graf graf--li graf-after--li">As t → -∞, <em class="markup--em markup--li-em">F</em>(<em class="markup--em markup--li-em">t</em>) → 0, which is also,</li></ul><figure name="b598" id="b598" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*IldRDVtVDrXK3vV4ebT5eQ.png" data-width="1564" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*IldRDVtVDrXK3vV4ebT5eQ.png"></figure><ul class="postList"><li name="2867" id="2867" class="graf graf--li graf-after--figure">As t → +∞, <em class="markup--em markup--li-em">F</em>(<em class="markup--em markup--li-em">t</em>) → 1, which is also,</li></ul><figure name="c4bf" id="c4bf" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*EehSTvEhLEzTkh91jTBsfQ.png" data-width="1564" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*EehSTvEhLEzTkh91jTBsfQ.png"></figure><ul class="postList"><li name="7691" id="7691" class="graf graf--li graf-after--figure">F must be a <strong class="markup--strong markup--li-strong">right-continuous</strong> function, i.e., ∀ s∈ℝ,</li></ul><figure name="3d93" id="3d93" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*gq6U_Lvj16GgTRFE1unXgg.png" data-width="1564" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*gq6U_Lvj16GgTRFE1unXgg.png"></figure><p name="998e" id="998e" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">6. Method of Inverse Transformations</strong></p><p name="9d31" id="9d31" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Result of Borel</strong></p><p name="bc71" id="bc71" class="graf graf--p graf-after--p">If you can write down a proper PDF, PMF, or CDF, then there exists a random variable X on some probability space (S, ℙ) such that the PDF, PMF, or CDF associated with your X will be exactly that you wrote down.</p><p name="7cf0" id="7cf0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Uniformly Distribute</strong></p><p name="3e4b" id="3e4b" class="graf graf--p graf-after--p">If X ~ Unif [a, b], we say that X is uniformly distributed over the interval [a, b]. i.e. it has PDF of,</p><figure name="3997" id="3997" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*dlG1RGAOrtAPI6KMFC6lDQ.png" data-width="1648" data-height="144" src="https://cdn-images-1.medium.com/max/800/1*dlG1RGAOrtAPI6KMFC6lDQ.png"></figure><figure name="2eb3" id="2eb3" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*Th-J99d13LTUQOQf2aE4nw.png" data-width="1630" data-height="378" src="https://cdn-images-1.medium.com/max/800/1*Th-J99d13LTUQOQf2aE4nw.png"></figure><p name="784b" id="784b" class="graf graf--p graf-after--figure">then the CDF must be,</p><figure name="0e1b" id="0e1b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*faosB3eoGbH_9mLDm1Vmsw.png" data-width="1634" data-height="338" src="https://cdn-images-1.medium.com/max/800/1*faosB3eoGbH_9mLDm1Vmsw.png"></figure><p name="e42a" id="e42a" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) Method of Inverse Transformations</strong></p><p name="bf24" id="bf24" class="graf graf--p graf-after--p">Three things to get started:</p><ul class="postList"><li name="3f54" id="3f54" class="graf graf--li graf-after--p">You need a random variable X for which you want to simulate a realization (or outcome)</li><li name="af3b" id="af3b" class="graf graf--li graf-after--li">You need an explicit (or even implicit) inverse of the CDF for X, i.e., an inverse Fx‾ ¹</li><li name="f040" id="f040" class="graf graf--li graf-after--li">You need the ability to simulate uniform random numbers on [0, 1]</li></ul><p name="986a" id="986a" class="graf graf--p graf-after--li">Algorithm:</p><ul class="postList"><li name="3a0d" id="3a0d" class="graf graf--li graf-after--p">Simulate a U ~ Unif(0, 1)</li><li name="88ba" id="88ba" class="graf graf--li graf-after--li">Construct,</li></ul><figure name="3aeb" id="3aeb" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*2buMJEnvx-6Zb3gXC5qaQA.png" data-width="1634" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*2buMJEnvx-6Zb3gXC5qaQA.png"></figure><ul class="postList"><li name="c67a" id="c67a" class="graf graf--li graf-after--figure graf--trailing">Store it and loop back to the first step as many times as you need realizations.</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/6dba84f81e80"><time class="dt-published" datetime="2020-08-25T15:00:44.101Z">August 25, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/probability-and-statistics-3-random-experiment-probability-mass-function-probability-density-6dba84f81e80" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>