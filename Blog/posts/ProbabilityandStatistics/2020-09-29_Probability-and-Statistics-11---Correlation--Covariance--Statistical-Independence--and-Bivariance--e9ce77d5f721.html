<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Probability and Statistics 11 | Correlation, Covariance, Statistical Independence, and Bivariance…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Probability and Statistics 11 | Correlation, Covariance, Statistical Independence, and Bivariance…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Probability and Statistics
</section>
<section data-field="body" class="e-content">
<section name="b9b1" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="acce" id="acce" class="graf graf--h3 graf--leading graf--title">Probability and Statistics 11 | <strong class="markup--strong markup--h3-strong">Correlation, Covariance, Statistical Independence, and Bivariance Normality</strong></h3><figure name="8689" id="8689" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*YTeSIjiYirbk4CZavQXCqg.jpeg" data-width="1602" data-height="1141" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*YTeSIjiYirbk4CZavQXCqg.jpeg"></figure><ol class="postList"><li name="1133" id="1133" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Correlation, Covariance, and Independence</strong></li></ol><p name="f1a1" id="f1a1" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) The Definition of Covariance</strong></p><p name="a26a" id="a26a" class="graf graf--p graf-after--p">If X and Y are random variables, then the covariance of X and Y is defined as,</p><figure name="6562" id="6562" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zEmMgvExQ12viTbrC6yAsg.png" data-width="1146" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*zEmMgvExQ12viTbrC6yAsg.png"></figure><p name="ea56" id="ea56" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) A Second Definition the Covariance (aka. Product-Moment or Product-Expectation)</strong></p><p name="29d7" id="29d7" class="graf graf--p graf-after--p">By definition,</p><figure name="45a2" id="45a2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zEmMgvExQ12viTbrC6yAsg.png" data-width="1146" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*zEmMgvExQ12viTbrC6yAsg.png"></figure><p name="ac44" id="ac44" class="graf graf--p graf-after--figure">then,</p><figure name="1a00" id="1a00" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*HaUthkNEYWnPZFWvvY4CYw.png" data-width="1352" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*HaUthkNEYWnPZFWvvY4CYw.png"></figure><p name="6e03" id="6e03" class="graf graf--p graf-after--figure">then,</p><figure name="9732" id="9732" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*-w5A1RgDiGCtZZNSStZJ2A.png" data-width="1352" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*-w5A1RgDiGCtZZNSStZJ2A.png"></figure><p name="0b05" id="0b05" class="graf graf--p graf-after--figure">then,</p><figure name="835c" id="835c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*s_ziO3RaXHITX7F8cCYzDQ.png" data-width="1352" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*s_ziO3RaXHITX7F8cCYzDQ.png"></figure><p name="fb82" id="fb82" class="graf graf--p graf-after--figure">thus,</p><figure name="3830" id="3830" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1x56ifKnHzUtxDg1ytEdxw.png" data-width="1352" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*1x56ifKnHzUtxDg1ytEdxw.png"></figure><p name="f9a9" id="f9a9" class="graf graf--p graf-after--figure">This is the second definition we have about the covariance.</p><p name="e047" id="e047" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) A Fact about the Covariance</strong></p><p name="1b53" id="1b53" class="graf graf--p graf-after--p">Suppose we have two random variables X and Y satisfy,</p><figure name="3393" id="3393" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*hMm06i4z0qXi1NEadp7n1w.png" data-width="1352" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*hMm06i4z0qXi1NEadp7n1w.png"></figure><p name="304a" id="304a" class="graf graf--p graf-after--figure">then,</p><figure name="8ba5" id="8ba5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*z2smrtcJ8ANTE_ybsIbO3g.png" data-width="1352" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*z2smrtcJ8ANTE_ybsIbO3g.png"></figure><p name="8e02" id="8e02" class="graf graf--p graf-after--figure">Note that we can only have this fact but<strong class="markup--strong markup--p-strong"> NOT</strong> vice versa.</p><p name="7b7f" id="7b7f" class="graf graf--p graf-after--p">Proof:</p><figure name="9d06" id="9d06" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*L9qxqWnW4wvaZmeNltlGzA.png" data-width="1352" data-height="116" src="https://cdn-images-1.medium.com/max/800/1*L9qxqWnW4wvaZmeNltlGzA.png"></figure><p name="e9df" id="e9df" class="graf graf--p graf-after--figure">then,</p><figure name="746b" id="746b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*c2TgK--e5_2IM2vwMCWRiA.png" data-width="1352" data-height="116" src="https://cdn-images-1.medium.com/max/800/1*c2TgK--e5_2IM2vwMCWRiA.png"></figure><p name="cc02" id="cc02" class="graf graf--p graf-after--figure">then,</p><figure name="c233" id="c233" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*AyTm5snCd_HH8H5JMDtuWA.png" data-width="1352" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*AyTm5snCd_HH8H5JMDtuWA.png"></figure><p name="a437" id="a437" class="graf graf--p graf-after--figure">then,</p><figure name="3c93" id="3c93" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Dl6_9vjYwPd7-yx7U7pN9Q.png" data-width="1352" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*Dl6_9vjYwPd7-yx7U7pN9Q.png"></figure><p name="793f" id="793f" class="graf graf--p graf-after--figure">then,</p><figure name="709a" id="709a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FRgvSUFNCxDxycff6bQhIg.png" data-width="1304" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*FRgvSUFNCxDxycff6bQhIg.png"></figure><p name="72c4" id="72c4" class="graf graf--p graf-after--figure">then,</p><figure name="291e" id="291e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*4EnU67eFxqdZP9f3a6PmJw.png" data-width="1304" data-height="64" src="https://cdn-images-1.medium.com/max/800/1*4EnU67eFxqdZP9f3a6PmJw.png"></figure><p name="c92a" id="c92a" class="graf graf--p graf-after--figure">thus,</p><figure name="ee12" id="ee12" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Ze4xoaiDcWlou6H-bQ3sNw.png" data-width="1304" data-height="64" src="https://cdn-images-1.medium.com/max/800/1*Ze4xoaiDcWlou6H-bQ3sNw.png"></figure><p name="94c4" id="94c4" class="graf graf--p graf-after--figure">A counterexample for the invalid vice versa that,</p><figure name="f221" id="f221" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*VU5Bq2Gl9t1gmAv6rurrqA.png" data-width="1304" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*VU5Bq2Gl9t1gmAv6rurrqA.png"></figure><p name="70c6" id="70c6" class="graf graf--p graf-after--figure">is when X and Y are <strong class="markup--strong markup--p-strong">jointly Gaussian</strong>, and the proof is as follows. Suppose we let X ~ N(0, 1) and Y = X². Then,</p><figure name="a46c" id="a46c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*xRzNy1_U_83-MP3Wn3Gg6g.png" data-width="1146" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*xRzNy1_U_83-MP3Wn3Gg6g.png"></figure><p name="6549" id="6549" class="graf graf--p graf-after--figure">also,</p><figure name="4da5" id="4da5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*MKK3Smff2YHSVUYl130rpg.png" data-width="1146" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*MKK3Smff2YHSVUYl130rpg.png"></figure><p name="6dd5" id="6dd5" class="graf graf--p graf-after--figure">then,</p><figure name="9da1" id="9da1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*XK_oKNHb4kxZK3Y7-R-lCA.png" data-width="1146" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*XK_oKNHb4kxZK3Y7-R-lCA.png"></figure><p name="37db" id="37db" class="graf graf--p graf-after--figure">then,</p><figure name="d0aa" id="d0aa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WxJFlPT4HuGoPaA1rFiqxQ.png" data-width="1146" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*WxJFlPT4HuGoPaA1rFiqxQ.png"></figure><p name="7cd5" id="7cd5" class="graf graf--p graf-after--figure">But this <strong class="markup--strong markup--p-strong">does not</strong> imply that</p><figure name="8254" id="8254" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1UgyRzUX3RIsfZ2wyWrG-g.png" data-width="1146" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*1UgyRzUX3RIsfZ2wyWrG-g.png"></figure><p name="b934" id="b934" class="graf graf--p graf-after--figure">Because Y depends explicitly upon X.</p><p name="2fef" id="2fef" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) The Meaning of the Covariance: Independence vs. Statistical Independence</strong></p><ul class="postList"><li name="ba59" id="ba59" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Independence</strong></li></ul><p name="fb56" id="fb56" class="graf graf--p graf-after--li">Theoretically, when we mean two random variables X and Y are independent, that means the joint density of these two variables is factorizable and it is defined on a rectangle-like support set. Recall:</p><div name="1246" id="1246" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/adamedelwiess/probability-and-statistics-5-joint-probability-independence-of-random-variables-and-condition-c7fe9e7eafd6" data-href="https://medium.com/adamedelwiess/probability-and-statistics-5-joint-probability-independence-of-random-variables-and-condition-c7fe9e7eafd6" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/adamedelwiess/probability-and-statistics-5-joint-probability-independence-of-random-variables-and-condition-c7fe9e7eafd6"><strong class="markup--strong markup--mixtapeEmbed-strong">Probability and Statistics 5 | Joint Probability, Independence of Random Variables, and Condition…</strong><br><em class="markup--em markup--mixtapeEmbed-em">Series: Probability and Statistics</em>medium.com</a><a href="https://medium.com/adamedelwiess/probability-and-statistics-5-joint-probability-independence-of-random-variables-and-condition-c7fe9e7eafd6" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="318e65be8a7206c0128291b7000f9149" data-thumbnail-img-id="1*YTeSIjiYirbk4CZavQXCqg.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*YTeSIjiYirbk4CZavQXCqg.jpeg);"></a></div><ul class="postList"><li name="5fc3" id="5fc3" class="graf graf--li graf-after--mixtapeEmbed"><strong class="markup--strong markup--li-strong">Statistical Independence</strong></li></ul><p name="f2af" id="f2af" class="graf graf--p graf-after--li">Empirically, when we mean two random variables X and Y are statistically independent, that means the covariance of these two variables is zero or there correlation is zero.</p><p name="92db" id="92db" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Problems Related to the Covariance</strong></p><p name="9307" id="9307" class="graf graf--p graf-after--p">There are basically two problems related to the covariance.</p><ul class="postList"><li name="0d21" id="0d21" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Not invariant with respect to scalings.</strong></li></ul><p name="a562" id="a562" class="graf graf--p graf-after--li">Proof:</p><p name="9deb" id="9deb" class="graf graf--p graf-after--p">Suppose that X and Y are random variables and define that,</p><figure name="be3b" id="be3b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*e9HyRYDmHDhKUpQQkMWYDA.png" data-width="1146" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*e9HyRYDmHDhKUpQQkMWYDA.png"></figure><p name="918a" id="918a" class="graf graf--p graf-after--figure">then,</p><figure name="e43e" id="e43e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*DuioHxsz5y5ZUt6Psti4lA.png" data-width="1312" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*DuioHxsz5y5ZUt6Psti4lA.png"></figure><p name="8962" id="8962" class="graf graf--p graf-after--figure">Aside, if we have,</p><figure name="e44e" id="e44e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0y0ErW0IFHWNjGycZ5AGQw.png" data-width="1312" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*0y0ErW0IFHWNjGycZ5AGQw.png"></figure><p name="1712" id="1712" class="graf graf--p graf-after--figure">then,</p><figure name="cf40" id="cf40" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*st18W2UetpM6-sqON_jjQQ.png" data-width="1312" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*st18W2UetpM6-sqON_jjQQ.png"></figure><p name="ed9b" id="ed9b" class="graf graf--p graf-after--figure">so adding a constant to the random variable will not impact the covariance.</p><ul class="postList"><li name="f965" id="f965" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">You can get weird product units by covariance</strong></li></ul><p name="585d" id="585d" class="graf graf--p graf-after--li">Because the covariance is defined by,</p><figure name="0891" id="0891" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*l3A4kk2gxkbTFbrGXMwLZg.png" data-width="1312" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*l3A4kk2gxkbTFbrGXMwLZg.png"></figure><p name="d17e" id="d17e" class="graf graf--p graf-after--figure">so it is quite meaning less if we have this kind of units of products. To deal with this problem, we can normalize the two random variables so as to make the unit of their product equal to 1.</p><p name="b845" id="b845" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) The Definition of the Correlation</strong></p><p name="a402" id="a402" class="graf graf--p graf-after--p">Suppose we have two random variables X and Y, if we standardize the random variables X and Y by,</p><figure name="9579" id="9579" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*C0ED-u13EdhdSaB0yAcJwg.png" data-width="1312" data-height="124" src="https://cdn-images-1.medium.com/max/800/1*C0ED-u13EdhdSaB0yAcJwg.png"></figure><p name="c4c1" id="c4c1" class="graf graf--p graf-after--figure">if we define the correlation of X and Y as the covariance of Zx, Zy, then,</p><figure name="f5d0" id="f5d0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*uqnlgK2Iq7Xw-whumbmm8Q.png" data-width="1122" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*uqnlgK2Iq7Xw-whumbmm8Q.png"></figure><p name="29c4" id="29c4" class="graf graf--p graf-after--figure">then,</p><figure name="2bee" id="2bee" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*-0-ZGAJ6Ognlmpq72XVyhA.png" data-width="1324" data-height="112" src="https://cdn-images-1.medium.com/max/800/1*-0-ZGAJ6Ognlmpq72XVyhA.png"></figure><p name="aaae" id="aaae" class="graf graf--p graf-after--figure">Thus, we can conclude that the correlation is a normalized covariance.</p><p name="fcf4" id="fcf4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) Properties of Covariance</strong></p><ul class="postList"><li name="8cd6" id="8cd6" class="graf graf--li graf-after--p">Property #1</li></ul><figure name="1d9f" id="1d9f" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*S2-HbSNdgmKdadWhavpRLQ.png" data-width="1256" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*S2-HbSNdgmKdadWhavpRLQ.png"></figure><ul class="postList"><li name="89a7" id="89a7" class="graf graf--li graf-after--figure">Property #2</li></ul><figure name="2c53" id="2c53" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*YU1yyzf78fjjY_1tp7YvxA.png" data-width="1256" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*YU1yyzf78fjjY_1tp7YvxA.png"></figure><ul class="postList"><li name="86ed" id="86ed" class="graf graf--li graf-after--figure">Property #3</li></ul><figure name="d37b" id="d37b" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*tG8LXomWQaqrqYzFdDq1MA.png" data-width="1256" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*tG8LXomWQaqrqYzFdDq1MA.png"></figure><ul class="postList"><li name="d76d" id="d76d" class="graf graf--li graf-after--figure">Property #4</li></ul><figure name="9dcd" id="9dcd" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*xbh1nvDjdrMtKEdBN1Gsvg.png" data-width="1256" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*xbh1nvDjdrMtKEdBN1Gsvg.png"></figure><ul class="postList"><li name="6ae8" id="6ae8" class="graf graf--li graf-after--figure">Property #5</li></ul><figure name="85a4" id="85a4" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*T9ndpKskMEX3PvUsunU0Ow.png" data-width="1256" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*T9ndpKskMEX3PvUsunU0Ow.png"></figure><p name="d872" id="d872" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(8) Properties of Correlation</strong></p><ul class="postList"><li name="1f3f" id="1f3f" class="graf graf--li graf-after--p">Property #1</li></ul><figure name="1ee3" id="1ee3" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*hBwSWwC3fCldWWMaj5s14g.png" data-width="1256" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*hBwSWwC3fCldWWMaj5s14g.png"></figure><p name="5015" id="5015" class="graf graf--p graf-after--figure">where,</p><figure name="0e28" id="0e28" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*BYUZPJZqfcIwODXDKLVfFQ.png" data-width="1256" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*BYUZPJZqfcIwODXDKLVfFQ.png"></figure><ul class="postList"><li name="e181" id="e181" class="graf graf--li graf-after--figure">Property #2</li></ul><figure name="b1a8" id="b1a8" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*MogTjN_M94G6Ie5a2dGVRw.png" data-width="1300" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*MogTjN_M94G6Ie5a2dGVRw.png"></figure><p name="c64b" id="c64b" class="graf graf--p graf-after--figure">warning,</p><figure name="1077" id="1077" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9jObCvPOfmbwyxbn8XoqmA.png" data-width="1300" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*9jObCvPOfmbwyxbn8XoqmA.png"></figure><ul class="postList"><li name="fd46" id="fd46" class="graf graf--li graf-after--figure">Property #3</li></ul><figure name="ef07" id="ef07" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*T-Ehup7seLioudleQkEtcg.png" data-width="1300" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*T-Ehup7seLioudleQkEtcg.png"></figure><ul class="postList"><li name="7bbd" id="7bbd" class="graf graf--li graf-after--figure">Property #4</li></ul><figure name="69f9" id="69f9" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*EtciIqr1gcM66LTL35dweA.png" data-width="1300" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*EtciIqr1gcM66LTL35dweA.png"></figure><ul class="postList"><li name="cf79" id="cf79" class="graf graf--li graf-after--figure">Property #5</li></ul><p name="5989" id="5989" class="graf graf--p graf-after--li">ρ measures only the linear dependence between X and Y. If the dependence is non-linear, then ρ is an inapplicable or inappropriate measure of dependence.</p><p name="754e" id="754e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Bivariance Normality</strong></p><p name="268e" id="268e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of Bivariance Normality</strong></p><p name="8c6a" id="8c6a" class="graf graf--p graf-after--p">Let <em class="markup--em markup--p-em">f</em>(<em class="markup--em markup--p-em">x</em>, <em class="markup--em markup--p-em">y</em>) be a joint PDF of continuous random variable X and Y. We can say that X and Y are bivariate normal if the following four conditions hold.</p><ul class="postList"><li name="4b1d" id="4b1d" class="graf graf--li graf-after--p">The<strong class="markup--strong markup--li-strong"> marginals must be normal</strong></li></ul><figure name="20cb" id="20cb" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*1bYXJnfqKMkV5IgqyW7ZJQ.png" data-width="1300" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*1bYXJnfqKMkV5IgqyW7ZJQ.png"></figure><ul class="postList"><li name="7601" id="7601" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Errors for the regressior are normally distributed</strong></li></ul><p name="9d6b" id="9d6b" class="graf graf--p graf-after--li">The conditional distribution of Y|X=<em class="markup--em markup--p-em">x</em> is also normal for <em class="markup--em markup--p-em">x</em>∈( -∞, ∞). That is, Y|X=<em class="markup--em markup--p-em">x</em> is a random variable that is normal for every X = <em class="markup--em markup--p-em">x</em>.</p><ul class="postList"><li name="c4db" id="c4db" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Linearity</strong></li></ul><p name="c5aa" id="c5aa" class="graf graf--p graf-after--li">The conditional expectation of Y|X=<em class="markup--em markup--p-em">x</em>, for example,</p><figure name="89b9" id="89b9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ovXyIpUadjzBo_e03UPtRA.png" data-width="1300" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*ovXyIpUadjzBo_e03UPtRA.png"></figure><p name="f682" id="f682" class="graf graf--p graf-after--figure">is a linear function of <em class="markup--em markup--p-em">x</em>; that is,</p><figure name="9c8a" id="9c8a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*QrF5P7SRs3vjQifkNOGy2Q.png" data-width="1300" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*QrF5P7SRs3vjQifkNOGy2Q.png"></figure><p name="6c29" id="6c29" class="graf graf--p graf-after--figure">for some <em class="markup--em markup--p-em">a</em> and some <em class="markup--em markup--p-em">b</em>.</p><ul class="postList"><li name="be76" id="be76" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Homoscedasticity</strong></li></ul><p name="d16d" id="d16d" class="graf graf--p graf-after--li">The conditional variance of Y, given X = <em class="markup--em markup--p-em">x</em>, is constant. We will denote it by,</p><figure name="0756" id="0756" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*BJt-TnqdPkh1IsGwHPWKVQ.png" data-width="1300" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*BJt-TnqdPkh1IsGwHPWKVQ.png"></figure><p name="d511" id="d511" class="graf graf--p graf-after--figure">Because it is a constant. It is independent in the functional sense of <em class="markup--em markup--p-em">x</em>.</p><p name="e35b" id="e35b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) The Form of the Bivariance Normality</strong></p><p name="c740" id="c740" class="graf graf--p graf-after--p">The joint density of continuous random variable X and Y is in the form of,</p><figure name="3a04" id="3a04" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*V6TQjlvt7INB08PFRJnm7w.png" data-width="1300" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*V6TQjlvt7INB08PFRJnm7w.png"></figure><p name="de07" id="de07" class="graf graf--p graf-after--figure">where, Q(<em class="markup--em markup--p-em">x</em>, <em class="markup--em markup--p-em">y</em>) is the quadratic form associate to a bivariate normal,</p><figure name="0a95" id="0a95" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*lk-xQMvi3YFLIv5dRM_Ogw.png" data-width="1300" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*lk-xQMvi3YFLIv5dRM_Ogw.png"></figure><p name="44ac" id="44ac" class="graf graf--p graf-after--figure">where,</p><figure name="039d" id="039d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*odPtIaMZ8J024yOlda3oJA.png" data-width="1300" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*odPtIaMZ8J024yOlda3oJA.png"></figure><p name="efb1" id="efb1" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) Conditional Density of Bivariance Normality</strong></p><p name="d840" id="d840" class="graf graf--p graf-after--p">The conditional density of Y given X = <em class="markup--em markup--p-em">x</em> is supposed to be,</p><figure name="d371" id="d371" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*P7TtKUe8yJUOliJkVOKV-g.png" data-width="1300" data-height="112" src="https://cdn-images-1.medium.com/max/800/1*P7TtKUe8yJUOliJkVOKV-g.png"></figure><p name="ec71" id="ec71" class="graf graf--p graf-after--figure">then,</p><figure name="d633" id="d633" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YJriEYfMHmmBieDyz6chxA.png" data-width="1300" data-height="240" src="https://cdn-images-1.medium.com/max/800/1*YJriEYfMHmmBieDyz6chxA.png"></figure><p name="4bdf" id="4bdf" class="graf graf--p graf-after--figure">then,</p><figure name="49b2" id="49b2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0o3OzBz8PfgR8scNcO42OQ.png" data-width="1300" data-height="240" src="https://cdn-images-1.medium.com/max/800/1*0o3OzBz8PfgR8scNcO42OQ.png"></figure><p name="0db4" id="0db4" class="graf graf--p graf-after--figure">then,</p><figure name="67a8" id="67a8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*2I5kiAVSaK3zShKVhgrAkg.png" data-width="1300" data-height="156" src="https://cdn-images-1.medium.com/max/800/1*2I5kiAVSaK3zShKVhgrAkg.png"></figure><p name="8a2f" id="8a2f" class="graf graf--p graf-after--figure">This is a Gaussian density in slight disguise.</p><p name="7f45" id="7f45" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) The Mean and Variance of the Conditional Gaussian Density</strong></p><ul class="postList"><li name="9050" id="9050" class="graf graf--li graf-after--p">Mean</li></ul><figure name="6ea6" id="6ea6" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*xZdB-yN2AzeGPa7VURT6sw.png" data-width="1300" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*xZdB-yN2AzeGPa7VURT6sw.png"></figure><ul class="postList"><li name="0f1e" id="0f1e" class="graf graf--li graf-after--figure">Variance</li></ul><figure name="da88" id="da88" class="graf graf--figure graf-after--li graf--trailing"><img class="graf-image" data-image-id="1*bFUoFNDYQ5eTnjZdnY7MoA.png" data-width="1300" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*bFUoFNDYQ5eTnjZdnY7MoA.png"></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/e9ce77d5f721"><time class="dt-published" datetime="2020-09-29T07:02:16.449Z">September 29, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/probability-and-statistics-11-correlation-covariance-statistical-independence-and-bivariance-e9ce77d5f721" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>