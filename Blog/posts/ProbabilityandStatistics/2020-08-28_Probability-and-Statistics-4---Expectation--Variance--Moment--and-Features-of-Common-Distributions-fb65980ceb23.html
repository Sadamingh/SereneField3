<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Probability and Statistics 4 | Expectation, Variance, Moment, and Features of Common Distributions</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Probability and Statistics 4 | Expectation, Variance, Moment, and Features of Common Distributions</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Probability and Statistics
</section>
<section data-field="body" class="e-content">
<section name="5878" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="417c" id="417c" class="graf graf--h3 graf--leading graf--title">Probability and Statistics 4 | <strong class="markup--strong markup--h3-strong">Expectation, Variance, Moment, and Features of Common Distributions</strong></h3><figure name="6ef7" id="6ef7" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*YTeSIjiYirbk4CZavQXCqg.jpeg" data-width="1602" data-height="1141" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*YTeSIjiYirbk4CZavQXCqg.jpeg"></figure><ol class="postList"><li name="cbc8" id="cbc8" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Expectation</strong></li></ol><p name="b80f" id="b80f" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) The Definition of Expectation</strong></p><p name="d65a" id="d65a" class="graf graf--p graf-after--p">If X is a <strong class="markup--strong markup--p-strong">discrete</strong> random variable, we define the expectation (or expected value) of X by, (which is similar to calculate means and averages)</p><figure name="6ca2" id="6ca2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*juNugWvSWxTU_oZXyYF20g.png" data-width="1880" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*juNugWvSWxTU_oZXyYF20g.png"></figure><p name="b1cc" id="b1cc" class="graf graf--p graf-after--figure">Note that we call the quantity ùîº[X] the <strong class="markup--strong markup--p-strong">first moment</strong> of random variable X.</p><p name="8961" id="8961" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Expectation: An Example</strong></p><p name="9d8b" id="9d8b" class="graf graf--p graf-after--p">Suppose that X is a random variable such that,</p><figure name="33aa" id="33aa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jSdrjK0kpKnVkkFCbH1dBA.png" data-width="1406" data-height="210" src="https://cdn-images-1.medium.com/max/800/1*jSdrjK0kpKnVkkFCbH1dBA.png"></figure><figure name="7aaa" id="7aaa" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*yxvDWw7jXjJtJbcNL_6Rlg.png" data-width="1406" data-height="342" src="https://cdn-images-1.medium.com/max/800/1*yxvDWw7jXjJtJbcNL_6Rlg.png"></figure><p name="a1cd" id="a1cd" class="graf graf--p graf-after--figure">So the expectation of random variable X is,</p><figure name="7ad4" id="7ad4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YBaGdN7XRoBk2mK8m_uZ3g.png" data-width="1920" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*YBaGdN7XRoBk2mK8m_uZ3g.png"></figure><p name="e473" id="e473" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) The Definition of Bernoulli Distribution</strong></p><p name="0cf3" id="0cf3" class="graf graf--p graf-after--p">A random variable X is said to be Bernoulli if it has a PMF such that,</p><figure name="c2fb" id="c2fb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*lKM7HLUHPt2TOmQIQG-Avw.png" data-width="1920" data-height="252" src="https://cdn-images-1.medium.com/max/800/1*lKM7HLUHPt2TOmQIQG-Avw.png"></figure><p name="cce2" id="cce2" class="graf graf--p graf-after--figure">Then, we will write X ~ Ber(<em class="markup--em markup--p-em">p</em>). If X ~ Ber(<em class="markup--em markup--p-em">p</em>), then ùîº[X] = <em class="markup--em markup--p-em">p</em>.</p><p name="c297" id="c297" class="graf graf--p graf-after--p">Proof:</p><figure name="b220" id="b220" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LOLnhaDocrZ2W1kOjwjKgA.png" data-width="1812" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*LOLnhaDocrZ2W1kOjwjKgA.png"></figure><p name="7513" id="7513" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) The Properties of Expectation</strong></p><ul class="postList"><li name="a7c1" id="a7c1" class="graf graf--li graf-after--p">Fact #1</li></ul><figure name="e893" id="e893" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*KyjLWYkhgk3tcN9PGksCOA.png" data-width="1694" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*KyjLWYkhgk3tcN9PGksCOA.png"></figure><p name="2231" id="2231" class="graf graf--p graf-after--figure">Because of this fact, we can conclude that ùîº is a linear operation.</p><ul class="postList"><li name="72a3" id="72a3" class="graf graf--li graf-after--p">Fact #2</li></ul><figure name="2f5e" id="2f5e" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*lCAVcybvspCUCifQEsBhIQ.png" data-width="1694" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*lCAVcybvspCUCifQEsBhIQ.png"></figure><ul class="postList"><li name="3bfd" id="3bfd" class="graf graf--li graf-after--figure">Fact #3</li></ul><figure name="bd0e" id="bd0e" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*3RdqtNR0BJ9tI2zyACcimg.png" data-width="1694" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*3RdqtNR0BJ9tI2zyACcimg.png"></figure><p name="3e68" id="3e68" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(5) Does Expectation Fully Characterize a Random Variable?</strong></p><p name="1c89" id="1c89" class="graf graf--p graf-after--p">The answer is no. Even if we have ùîº[X] = ùîº[Y], X and Y are not the same random variables. For example, in the graph below, even we have ùîº[X] = ùîº[Y], the random variable X and Y do not obey the same distribution. For random variable Y, the data is very spread out, while for random variable X, the data is very tense.</p><figure name="89cb" id="89cb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*DjJ2Yyl4Vd1Kx0D9hWtToA.png" data-width="1550" data-height="460" src="https://cdn-images-1.medium.com/max/800/1*DjJ2Yyl4Vd1Kx0D9hWtToA.png"></figure><p name="6f2c" id="6f2c" class="graf graf--p graf-after--figure">So we would like to have a concept that measures the ‚Äúspread-outness‚Äù of a random variable.</p><p name="03b6" id="03b6" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Variance</strong></p><p name="85cd" id="85cd" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Three Ways to Describe Spread-Outness</strong></p><p name="de59" id="de59" class="graf graf--p graf-after--p">Basically, there are three ways for us to define the ‚Äúspread-outness‚Äù of a random variable.</p><ul class="postList"><li name="c2ec" id="c2ec" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Center X Method (aka. Average Deviation):</strong> Construct new random variable Y = X - ùîº[X]. Then,</li></ul><figure name="11bc" id="11bc" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*cbmBtZf-tqyihhWldUXqxw.png" data-width="1752" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*cbmBtZf-tqyihhWldUXqxw.png"></figure><p name="207f" id="207f" class="graf graf--p graf-after--figure">The practical meaning of the above formula is that when we minus expectation ùîº[X] from every <em class="markup--em markup--p-em">x, </em>then the deviation to the right of that will by definition balanced by average, and the means of the newly created random variable has an expectation of 0. The problem is that the average deviation simply cancels out to zero (i.e. positives canceling negatives).</p><ul class="postList"><li name="13e9" id="13e9" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Absolute Average Deviation Method</strong>: A simple to get rid of the canceling problem is to use an absolute value. So we construct random variable Y = |X - ùîº[X]|. Then,</li></ul><figure name="67fc" id="67fc" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*rp0GM76mUWfdkMylnKXAEg.png" data-width="1426" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*rp0GM76mUWfdkMylnKXAEg.png"></figure><p name="64eb" id="64eb" class="graf graf--p graf-after--figure">This is actually a fine concept that connected to mean absolute deviation. Note that mean absolute deviation is a common loss function in analytics. An example of the absolute average deviation is illustrated below,</p><figure name="826c" id="826c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*D7FsVyj5Jvbdd6qDzYGvfA.png" data-width="1598" data-height="350" src="https://cdn-images-1.medium.com/max/800/1*D7FsVyj5Jvbdd6qDzYGvfA.png"></figure><p name="5148" id="5148" class="graf graf--p graf-after--figure">The main problem of this method is that this function is non-differentiable at zero. So it is going to be a problem in regression, time series analysis, or it turns out other concepts too that it is very highly desirable that the function that we are working with, maybe loss function or else because we are going to fit the, for example, regression models to minimize the spread-outness of the residuals from that particular model. Variance is going to a good thing because we will fit parameters, so as to minimize variance. Whenever we do minimization or maximization, we are doing calculates. So when we have an absolute value sign on something, calculates may not be used because it is not differentiable at each point. So the nice thing for us to think about is a thing that ignores the positive or negative stuff and makes them all positives is absolutely the square method.</p><ul class="postList"><li name="0af7" id="0af7" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Square Method (aka. Variance)</strong>: Finally, based on our idea, we can then construct Y = (X-ùîº[X])¬≤</li></ul><figure name="f8d6" id="f8d6" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*Z9y-qDm66B8flvE7QCA3dw.png" data-width="1598" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*Z9y-qDm66B8flvE7QCA3dw.png"></figure><p name="febd" id="febd" class="graf graf--p graf-after--figure">The notation of variance on the random variable X could also be ùïç(X), or œÉ¬≤x, or œÉ¬≤.</p><p name="b660" id="b660" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Variance for Discrete X: An Example</strong></p><p name="088c" id="088c" class="graf graf--p graf-after--p">Suppose that X is a random variable such that,</p><figure name="12e8" id="12e8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jSdrjK0kpKnVkkFCbH1dBA.png" data-width="1406" data-height="210" src="https://cdn-images-1.medium.com/max/800/1*jSdrjK0kpKnVkkFCbH1dBA.png"></figure><p name="c32b" id="c32b" class="graf graf--p graf-after--figure">Solution:</p><figure name="cfe4" id="cfe4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*-rGtCwiy0sRJDiT31dGJRA.png" data-width="1598" data-height="84" src="https://cdn-images-1.medium.com/max/800/1*-rGtCwiy0sRJDiT31dGJRA.png"></figure><p name="df68" id="df68" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) The Definition of Standard Deviation</strong></p><p name="4fcc" id="4fcc" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">units of the variance</strong> of random variable X are the original units of X, squared. Consequently, we will define the <strong class="markup--strong markup--p-strong">standard deviation</strong> of random variable X as the square root of the variance of X. For example,</p><figure name="91b7" id="91b7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wkhi3T18MpHVWoCBHvmYaA.png" data-width="1694" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*wkhi3T18MpHVWoCBHvmYaA.png"></figure><p name="e5e2" id="e5e2" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Famous Short Cut Formula for Variance</strong></p><p name="2d04" id="2d04" class="graf graf--p graf-after--p">The function ùîº and the function <em class="markup--em markup--p-em">Var</em> on the random variable X has the relationship as,</p><figure name="6fde" id="6fde" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*cvYKGLQaKQv9NplPMnSn4A.png" data-width="1476" data-height="92" src="https://cdn-images-1.medium.com/max/800/1*cvYKGLQaKQv9NplPMnSn4A.png"></figure><p name="3243" id="3243" class="graf graf--p graf-after--figure">Therefore, we have, by Fact #3</p><figure name="3fa6" id="3fa6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*nTdOevbRBu5Dz1mYkVasyQ.png" data-width="1476" data-height="52" src="https://cdn-images-1.medium.com/max/800/1*nTdOevbRBu5Dz1mYkVasyQ.png"></figure><p name="3437" id="3437" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(5) <em class="markup--em markup--p-em">n</em>-th Moment and <em class="markup--em markup--p-em">n</em>-th Absolute Moment</strong></p><p name="2c4b" id="2c4b" class="graf graf--p graf-after--p">In general, we denote the <em class="markup--em markup--p-em">n</em>-th moment of the random variable X as,</p><figure name="f62b" id="f62b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*sbwRV1gU2CtElk7obqFKIQ.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*sbwRV1gU2CtElk7obqFKIQ.png"></figure><p name="16a8" id="16a8" class="graf graf--p graf-after--figure">Whereas, we call the <em class="markup--em markup--p-em">n</em>-th absolute moment of the random variable X as,</p><figure name="7d0e" id="7d0e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qjJ1ub60bFbLEDPXBLh1-g.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*qjJ1ub60bFbLEDPXBLh1-g.png"></figure><p name="40b4" id="40b4" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(6) The Definition of Variance for Continuous X</strong></p><p name="e12c" id="e12c" class="graf graf--p graf-after--p">If X is a continuous random variable, then the result of the expectation of this X is defined by,</p><figure name="3223" id="3223" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LNcgevnG6wdSmjjk643gSA.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*LNcgevnG6wdSmjjk643gSA.png"></figure><p name="ab98" id="ab98" class="graf graf--p graf-after--figure">Similarly, the variance is defined by,</p><figure name="7b22" id="7b22" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pW2cu0CsGytzlgNS8SPEew.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*pW2cu0CsGytzlgNS8SPEew.png"></figure><p name="738b" id="738b" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(7) Properties of Variance: Claim #1</strong></p><p name="c645" id="c645" class="graf graf--p graf-after--p">For some of c ‚àà‚Ñù,</p><figure name="de14" id="de14" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*KN1d52FY_9yXoYjExFG1yA.png" data-width="1476" data-height="46" src="https://cdn-images-1.medium.com/max/800/1*KN1d52FY_9yXoYjExFG1yA.png"></figure><p name="b5a8" id="b5a8" class="graf graf--p graf-after--figure">Proof:</p><p name="12f2" id="12f2" class="graf graf--p graf-after--p">‚áê Suppose that X is a random variable such that ‚Ñô(X = c) = 1</p><p name="5e65" id="5e65" class="graf graf--p graf-after--p">then, we have,</p><figure name="0a4a" id="0a4a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wCiE8gSZ7xkOGieZYs4RzQ.png" data-width="1476" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*wCiE8gSZ7xkOGieZYs4RzQ.png"></figure><p name="b31b" id="b31b" class="graf graf--p graf-after--figure">so that,</p><figure name="cca6" id="cca6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wwATi4pZrT-7O7ItpCp47g.png" data-width="1476" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*wwATi4pZrT-7O7ItpCp47g.png"></figure><p name="bdd0" id="bdd0" class="graf graf--p graf-after--figure">‚áí Assume that Var(X) = 0, without loss of generality, we can assume that X is a discrete random variable.</p><figure name="3dad" id="3dad" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*61r_rGgZK3A8VPUM2g8mPw.png" data-width="1476" data-height="122" src="https://cdn-images-1.medium.com/max/800/1*61r_rGgZK3A8VPUM2g8mPw.png"></figure><p name="d439" id="d439" class="graf graf--p graf-after--figure">then,</p><figure name="22bf" id="22bf" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*gdwy7x98x-LkKyQ9nJRgsA.png" data-width="1476" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*gdwy7x98x-LkKyQ9nJRgsA.png"></figure><p name="946e" id="946e" class="graf graf--p graf-after--figure">then, A has just one member,</p><figure name="509a" id="509a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*dscy-cRV3Ws17Dsg6cvRAg.png" data-width="1476" data-height="52" src="https://cdn-images-1.medium.com/max/800/1*dscy-cRV3Ws17Dsg6cvRAg.png"></figure><p name="e070" id="e070" class="graf graf--p graf-after--figure">then,</p><figure name="34e3" id="34e3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*amaZvuYOsBEWqUXQdhhTaA.png" data-width="1476" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*amaZvuYOsBEWqUXQdhhTaA.png"></figure><p name="f685" id="f685" class="graf graf--p graf-after--figure">then,</p><figure name="c87a" id="c87a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*P3xJbVL_j_R_9Oq2-GIurQ.png" data-width="1476" data-height="52" src="https://cdn-images-1.medium.com/max/800/1*P3xJbVL_j_R_9Oq2-GIurQ.png"></figure><p name="8e14" id="8e14" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(8) Properties of Variance: Claim #2</strong></p><p name="3d86" id="3d86" class="graf graf--p graf-after--p">For ‚àÄ a, b ‚àà ‚Ñù,</p><figure name="eefc" id="eefc" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ctfOqWNCwZWfNCdr1GPTCA.png" data-width="1476" data-height="52" src="https://cdn-images-1.medium.com/max/800/1*ctfOqWNCwZWfNCdr1GPTCA.png"></figure><p name="f3c5" id="f3c5" class="graf graf--p graf-after--figure">Proof:</p><p name="f7ae" id="f7ae" class="graf graf--p graf-after--p">For illustrative purposes, let X be a continuous random variable,</p><figure name="dde0" id="dde0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*TMmSar3FybpRgBaD8MOz_Q.png" data-width="1476" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*TMmSar3FybpRgBaD8MOz_Q.png"></figure><p name="613b" id="613b" class="graf graf--p graf-after--figure">then,</p><figure name="c0e3" id="c0e3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*T0ac_tOwLXvdjAMQEkBv-w.png" data-width="1476" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*T0ac_tOwLXvdjAMQEkBv-w.png"></figure><p name="964d" id="964d" class="graf graf--p graf-after--figure">then,</p><figure name="43ac" id="43ac" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WYDLurxHH7s6QDxLr02B_w.png" data-width="1476" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*WYDLurxHH7s6QDxLr02B_w.png"></figure><p name="c37c" id="c37c" class="graf graf--p graf-after--figure">then,</p><figure name="0f05" id="0f05" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*hwaqJFt5VNXn09RvU8qqSA.png" data-width="1476" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*hwaqJFt5VNXn09RvU8qqSA.png"></figure><p name="5a42" id="5a42" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(9) Properties of Variance: Claim #3</strong></p><p name="b333" id="b333" class="graf graf--p graf-after--p">For ‚àÄ a, b ‚àà ‚Ñù,</p><figure name="5fd7" id="5fd7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pOg6GYaIEl3-pG_0n_EmGQ.png" data-width="1476" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*pOg6GYaIEl3-pG_0n_EmGQ.png"></figure><p name="0e18" id="0e18" class="graf graf--p graf-after--figure">Proof:</p><figure name="2f94" id="2f94" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*6ExngsFDetS4wFj6UZskQQ.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*6ExngsFDetS4wFj6UZskQQ.png"></figure><p name="d758" id="d758" class="graf graf--p graf-after--figure">by claim #2,</p><figure name="418f" id="418f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*TBieWeH6i6tzIz7nnfJFBQ.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*TBieWeH6i6tzIz7nnfJFBQ.png"></figure><p name="bde7" id="bde7" class="graf graf--p graf-after--figure">then,</p><figure name="baaa" id="baaa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*z9CsWAbJVIeOUC6svdkJyA.png" data-width="1476" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*z9CsWAbJVIeOUC6svdkJyA.png"></figure><p name="155b" id="155b" class="graf graf--p graf-after--figure">then,</p><figure name="9a76" id="9a76" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pOg6GYaIEl3-pG_0n_EmGQ.png" data-width="1476" data-height="54" src="https://cdn-images-1.medium.com/max/800/1*pOg6GYaIEl3-pG_0n_EmGQ.png"></figure><p name="0ba0" id="0ba0" class="graf graf--p graf-after--figure">So that we can have the conclusion that the variance ignores translation and the scalar multiplication has a quadratic impact.</p><p name="db30" id="db30" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Different Types of Distributions</strong></p><p name="be6c" id="be6c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of the Moment</strong></p><p name="cf9c" id="cf9c" class="graf graf--p graf-after--p">The moment is a series of quantitative measures that give information related to a function. If the function is a probability distribution, and X is the random variable of this distribution, the general expression of an <em class="markup--em markup--p-em">n</em>-th moment is defined as,</p><figure name="2499" id="2499" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Aw7hk3W44sMEwD2hMA_mKA.png" data-width="1620" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*Aw7hk3W44sMEwD2hMA_mKA.png"></figure><ul class="postList"><li name="59c7" id="59c7" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Zeroth Moment</strong>: the total probability, and by Kolmogorov Axiom #2, this should be 1.</li></ul><figure name="89b9" id="89b9" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*WqnZtGn1SL42LWcUclt1Sg.png" data-width="1620" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*WqnZtGn1SL42LWcUclt1Sg.png"></figure><ul class="postList"><li name="a023" id="a023" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">First Moment</strong>: the expectation</li><li name="0b00" id="0b00" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Second Central Moment</strong>: the variance, i.e. the spread-out</li><li name="3eb8" id="3eb8" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Third Standardized Moment</strong>: the skewness, i.e. the direction of the tail</li></ul><figure name="c479" id="c479" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*fKS_kxSkVISPCB8a1XEM_Q.png" data-width="1660" data-height="342" src="https://cdn-images-1.medium.com/max/800/1*fKS_kxSkVISPCB8a1XEM_Q.png"></figure><ul class="postList"><li name="a67e" id="a67e" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Forth Standardized Moment</strong>: the kurtosis, i.e. how fat the tails are</li></ul><figure name="0bdc" id="0bdc" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*316GQ5-By4J7gX0Di1daig.png" data-width="1602" data-height="322" src="https://cdn-images-1.medium.com/max/800/1*316GQ5-By4J7gX0Di1daig.png"></figure><p name="acf8" id="acf8" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Bernoulli Distribution</strong></p><p name="48e4" id="48e4" class="graf graf--p graf-after--p">Recall that if X follows the Bernoulli distribution, X is noted as X ~ Ber(<em class="markup--em markup--p-em">p</em>).</p><figure name="2db1" id="2db1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*lKM7HLUHPt2TOmQIQG-Avw.png" data-width="1920" data-height="252" src="https://cdn-images-1.medium.com/max/800/1*lKM7HLUHPt2TOmQIQG-Avw.png"></figure><ul class="postList"><li name="5987" id="5987" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Variance</strong></li></ul><p name="3dc4" id="3dc4" class="graf graf--p graf-after--li">So what is the variance of the random variable in Bernoulli distribution? The conclusion is as follows,</p><figure name="40e7" id="40e7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Y2hdjVxMwBHtZbCQ8droww.png" data-width="1700" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*Y2hdjVxMwBHtZbCQ8droww.png"></figure><p name="9018" id="9018" class="graf graf--p graf-after--figure">Proof:</p><figure name="44bd" id="44bd" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LDQaj30FK_dUBJUOkBaTTA.png" data-width="1700" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*LDQaj30FK_dUBJUOkBaTTA.png"></figure><p name="bd51" id="bd51" class="graf graf--p graf-after--figure">then,</p><figure name="dc2b" id="dc2b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*SCLIWwPkGARnXILFMXqfFQ.png" data-width="1700" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*SCLIWwPkGARnXILFMXqfFQ.png"></figure><ul class="postList"><li name="d7d9" id="d7d9" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Moment</strong></li></ul><p name="92b5" id="92b5" class="graf graf--p graf-after--li">The conclusion is that every moment of a Bernoulli random variable is equal to <em class="markup--em markup--p-em">p</em>.</p><p name="bc03" id="bc03" class="graf graf--p graf-after--p">Proof:</p><figure name="5c7b" id="5c7b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WHMCzbzpemvSNNwo5M93pw.png" data-width="1416" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*WHMCzbzpemvSNNwo5M93pw.png"></figure><p name="7087" id="7087" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) Exponential Distribution</strong></p><p name="65db" id="65db" class="graf graf--p graf-after--p">Recall that PDF of the exponential distribution is,</p><figure name="156e" id="156e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pc4vUIl19npW9DZZMtuh7A.png" data-width="1416" data-height="144" src="https://cdn-images-1.medium.com/max/800/1*pc4vUIl19npW9DZZMtuh7A.png"></figure><p name="fb75" id="fb75" class="graf graf--p graf-after--figure">And X is noted as X ~ Exp(Œª).</p><ul class="postList"><li name="9cc9" id="9cc9" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Expectation</strong></li></ul><p name="26e3" id="26e3" class="graf graf--p graf-after--li">The expectation of random variable X that follows the exponential distribution is,</p><figure name="5463" id="5463" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*kcBfeyzzJ3sHSK50KQU0HQ.png" data-width="1494" data-height="96" src="https://cdn-images-1.medium.com/max/800/1*kcBfeyzzJ3sHSK50KQU0HQ.png"></figure><p name="8d66" id="8d66" class="graf graf--p graf-after--figure">Proof:</p><figure name="2897" id="2897" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*KeaR35L070tL8Q_G-jYaYQ.png" data-width="1494" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*KeaR35L070tL8Q_G-jYaYQ.png"></figure><p name="84e6" id="84e6" class="graf graf--p graf-after--figure">then,</p><figure name="c6fc" id="c6fc" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*XZfIvQ52qQTRH2jf3YkLXw.png" data-width="1494" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*XZfIvQ52qQTRH2jf3YkLXw.png"></figure><p name="226f" id="226f" class="graf graf--p graf-after--figure">because we have,</p><figure name="9ebe" id="9ebe" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0XYVSMdutDmEHoxH2qwU1g.png" data-width="1494" data-height="96" src="https://cdn-images-1.medium.com/max/800/1*0XYVSMdutDmEHoxH2qwU1g.png"></figure><p name="07fa" id="07fa" class="graf graf--p graf-after--figure">so that we have,</p><figure name="38b0" id="38b0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*u0a7f5O0tgnDjAR-YiXr_w.png" data-width="1494" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*u0a7f5O0tgnDjAR-YiXr_w.png"></figure><ul class="postList"><li name="3510" id="3510" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Variance</strong></li></ul><p name="5e35" id="5e35" class="graf graf--p graf-after--li">The variance of random variable X that follows the exponential distribution is,</p><figure name="e317" id="e317" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*r2-OrUOlj9OMWpPwAHrJ4Q.png" data-width="1416" data-height="92" src="https://cdn-images-1.medium.com/max/800/1*r2-OrUOlj9OMWpPwAHrJ4Q.png"></figure><p name="3ea0" id="3ea0" class="graf graf--p graf-after--figure">Proof:</p><p name="e8ca" id="e8ca" class="graf graf--p graf-after--p">Because we have,</p><figure name="3363" id="3363" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FagGv0CwCsJDFfegVWtH5A.png" data-width="1494" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*FagGv0CwCsJDFfegVWtH5A.png"></figure><p name="39d6" id="39d6" class="graf graf--p graf-after--figure">then, we have,</p><figure name="ce14" id="ce14" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zl_bJTgeCxwyblJkCIMSqQ.png" data-width="1620" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*zl_bJTgeCxwyblJkCIMSqQ.png"></figure><p name="2385" id="2385" class="graf graf--p graf-after--figure">then,</p><figure name="61a4" id="61a4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*fcarmER22N-M8IeOK5lciA.png" data-width="1802" data-height="112" src="https://cdn-images-1.medium.com/max/800/1*fcarmER22N-M8IeOK5lciA.png"></figure><p name="132a" id="132a" class="graf graf--p graf-after--figure">then,</p><figure name="0597" id="0597" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*W9os8K-5oSzO6TGjLJJguA.png" data-width="1620" data-height="118" src="https://cdn-images-1.medium.com/max/800/1*W9os8K-5oSzO6TGjLJJguA.png"></figure><p name="18ff" id="18ff" class="graf graf--p graf-after--figure">as we have proved that,</p><figure name="2137" id="2137" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*dyoRSzrqx_N5XFbkbEhojg.png" data-width="1620" data-height="118" src="https://cdn-images-1.medium.com/max/800/1*dyoRSzrqx_N5XFbkbEhojg.png"></figure><p name="7cd9" id="7cd9" class="graf graf--p graf-after--figure">then,</p><figure name="3003" id="3003" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*SSzDrA5RWs7hWo_DuyDWkw.png" data-width="1620" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*SSzDrA5RWs7hWo_DuyDWkw.png"></figure><p name="fd15" id="fd15" class="graf graf--p graf-after--figure">thus,</p><figure name="0e49" id="0e49" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*rx7XlB5EUwFOooL-5ULWfA.png" data-width="1620" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*rx7XlB5EUwFOooL-5ULWfA.png"></figure><p name="b978" id="b978" class="graf graf--p graf-after--figure">we also have,</p><figure name="02ed" id="02ed" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zJL-uJwHdqiORJPYfbwsMQ.png" data-width="1620" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*zJL-uJwHdqiORJPYfbwsMQ.png"></figure><p name="3316" id="3316" class="graf graf--p graf-after--figure">As a result, we have,</p><figure name="7617" id="7617" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Rtix2pfMzSxhm4ouS4UIzg.png" data-width="1620" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*Rtix2pfMzSxhm4ouS4UIzg.png"></figure><p name="d490" id="d490" class="graf graf--p graf-after--figure">therefore,</p><figure name="ffa8" id="ffa8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*r2-OrUOlj9OMWpPwAHrJ4Q.png" data-width="1416" data-height="92" src="https://cdn-images-1.medium.com/max/800/1*r2-OrUOlj9OMWpPwAHrJ4Q.png"></figure><ul class="postList"><li name="2fea" id="2fea" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Second Moment</strong></li></ul><p name="82fd" id="82fd" class="graf graf--p graf-after--li">Based on the previous proof, we can then have the second moment of the random variable X as,</p><figure name="18e8" id="18e8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*rx7XlB5EUwFOooL-5ULWfA.png" data-width="1620" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*rx7XlB5EUwFOooL-5ULWfA.png"></figure><ul class="postList"><li name="1175" id="1175" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Third moment</strong></li></ul><p name="c73d" id="c73d" class="graf graf--p graf-after--li">We have the third moment of the random variable X as follows when X ~ <em class="markup--em markup--p-em">Exp</em>(Œª),</p><figure name="3668" id="3668" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*UaxYgtcyjJN6JNhzDEMwJA.png" data-width="1620" data-height="90" src="https://cdn-images-1.medium.com/max/800/1*UaxYgtcyjJN6JNhzDEMwJA.png"></figure><p name="c981" id="c981" class="graf graf--p graf-after--figure">Proof:</p><figure name="3230" id="3230" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*y2zMlgvygNHVAqjxLDTjiw.png" data-width="1620" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*y2zMlgvygNHVAqjxLDTjiw.png"></figure><p name="a523" id="a523" class="graf graf--p graf-after--figure">then,</p><figure name="cf7a" id="cf7a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*j1K_fO829Jg65jMhLuUuOw.png" data-width="1620" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*j1K_fO829Jg65jMhLuUuOw.png"></figure><p name="d5a7" id="d5a7" class="graf graf--p graf-after--figure">then,</p><figure name="45c2" id="45c2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*EZtnqWjqg6gdl2rsiIMAfQ.png" data-width="1620" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*EZtnqWjqg6gdl2rsiIMAfQ.png"></figure><p name="3513" id="3513" class="graf graf--p graf-after--figure">because we already proved that,</p><figure name="ca51" id="ca51" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*BPxAgkDsC3zkJCJn3GMYEA.png" data-width="1620" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*BPxAgkDsC3zkJCJn3GMYEA.png"></figure><p name="a809" id="a809" class="graf graf--p graf-after--figure">then,</p><figure name="83bd" id="83bd" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*f8wPyEopje-4uPkUyRSgmw.png" data-width="1620" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*f8wPyEopje-4uPkUyRSgmw.png"></figure><ul class="postList"><li name="9009" id="9009" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">n</em>-th moment</strong></li></ul><p name="b879" id="b879" class="graf graf--p graf-after--li">We can give the result of the <em class="markup--em markup--p-em">n</em>-th moment based on the previous proof as,</p><figure name="fd1f" id="fd1f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*XLGXAOyGoJcIII64d3Cg2g.png" data-width="1620" data-height="90" src="https://cdn-images-1.medium.com/max/800/1*XLGXAOyGoJcIII64d3Cg2g.png"></figure><p name="e3e3" id="e3e3" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Binomial Distribution</strong></p><p name="1a2e" id="1a2e" class="graf graf--p graf-after--p">A binomial random variable X is a random variable with PMF as,</p><figure name="3960" id="3960" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*lDX8H5oHFEZRYUWa-41n0w.png" data-width="1508" data-height="138" src="https://cdn-images-1.medium.com/max/800/1*lDX8H5oHFEZRYUWa-41n0w.png"></figure><p name="fda2" id="fda2" class="graf graf--p graf-after--figure">and we will denote it by X ~ <em class="markup--em markup--p-em">Bin</em>(<em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">p</em>), where the coefficient <em class="markup--em markup--p-em">n</em> means the number of trials and <em class="markup--em markup--p-em">p</em> means the success probability. We also note that <em class="markup--em markup--p-em">n</em> choose <em class="markup--em markup--p-em">x</em> (i.e. (n x) as it is shown in the PMF above) and this is also the number of district subsets of size <em class="markup--em markup--p-em">x</em> from a greater set of size <em class="markup--em markup--p-em">n</em>. We can calculate this by formula,</p><figure name="82a9" id="82a9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*vcEQPKvo3nJHTkk1fDZyfQ.png" data-width="1508" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*vcEQPKvo3nJHTkk1fDZyfQ.png"></figure><p name="6147" id="6147" class="graf graf--p graf-after--figure">where the notation ‚Äú!‚Äù means factorial and it is defined by,</p><figure name="fa1a" id="fa1a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*hzr4P8o9nQnQG98_6XKmag.png" data-width="1508" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*hzr4P8o9nQnQG98_6XKmag.png"></figure><p name="f678" id="f678" class="graf graf--p graf-after--figure">A binomial random variable is just the sum of independent Bernoulli trials, i.e., if Y ~ <em class="markup--em markup--p-em">Bin</em>(<em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">p</em>), then,</p><figure name="018b" id="018b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*b9SvjWIOEbQjl1s5KzBtNQ.png" data-width="1470" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*b9SvjWIOEbQjl1s5KzBtNQ.png"></figure><p name="b2fd" id="b2fd" class="graf graf--p graf-after--figure">where Xi ~ <em class="markup--em markup--p-em">Ber</em>(<em class="markup--em markup--p-em">p</em>) and the Xi are independent. And this is a common definition of the Bernoulli distribution.</p><ul class="postList"><li name="9fba" id="9fba" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Expectation</strong></li></ul><p name="e3b5" id="e3b5" class="graf graf--p graf-after--li">For X~ <em class="markup--em markup--p-em">Bin</em>(<em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">p</em>), we could have the expectation as,</p><figure name="211f" id="211f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ARimtTzGIXRclui5aHUkXg.png" data-width="1470" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*ARimtTzGIXRclui5aHUkXg.png"></figure><p name="4a7a" id="4a7a" class="graf graf--p graf-after--figure">Proof:</p><p name="481a" id="481a" class="graf graf--p graf-after--p">Suppose that we have Y ~ <em class="markup--em markup--p-em">Bin</em>(<em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">p</em>), then,</p><figure name="b6db" id="b6db" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*b9SvjWIOEbQjl1s5KzBtNQ.png" data-width="1470" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*b9SvjWIOEbQjl1s5KzBtNQ.png"></figure><p name="5753" id="5753" class="graf graf--p graf-after--figure">where Xi ~ <em class="markup--em markup--p-em">Ber</em>(<em class="markup--em markup--p-em">p</em>) and the Xi are independent, then</p><figure name="ee2d" id="ee2d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*OK_-9W5NNVi5tgq8XWH0oQ.png" data-width="1470" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*OK_-9W5NNVi5tgq8XWH0oQ.png"></figure><ul class="postList"><li name="a8c7" id="a8c7" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Variance</strong></li></ul><p name="7dbe" id="7dbe" class="graf graf--p graf-after--li">For X~ <em class="markup--em markup--p-em">Bin</em>(<em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">p</em>), we could have the variance as,</p><figure name="7bf0" id="7bf0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*SgsFpS01rfNkEDCIw6WpnA.png" data-width="1470" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*SgsFpS01rfNkEDCIw6WpnA.png"></figure><p name="67ad" id="67ad" class="graf graf--p graf-after--figure">Proof:</p><p name="8410" id="8410" class="graf graf--p graf-after--p">Suppose that we have Y ~ <em class="markup--em markup--p-em">Bin</em>(<em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">p</em>), then,</p><figure name="8f11" id="8f11" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*b9SvjWIOEbQjl1s5KzBtNQ.png" data-width="1470" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*b9SvjWIOEbQjl1s5KzBtNQ.png"></figure><p name="37d2" id="37d2" class="graf graf--p graf-after--figure">where Xi ~ <em class="markup--em markup--p-em">Ber</em>(<em class="markup--em markup--p-em">p</em>) and the Xi are independent, then</p><figure name="614d" id="614d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Dk2rhI19Sntp2mApt9F9uQ.png" data-width="1470" data-height="126" src="https://cdn-images-1.medium.com/max/800/1*Dk2rhI19Sntp2mApt9F9uQ.png"></figure><p name="fdec" id="fdec" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(5) Geometric Distribution</strong></p><p name="cea3" id="cea3" class="graf graf--p graf-after--p">A random variable X is called geometric, and we denote it by X ~ Geo(<em class="markup--em markup--p-em">p</em>) if its PMF <em class="markup--em markup--p-em">p</em>(<em class="markup--em markup--p-em">x</em>) is,</p><figure name="904a" id="904a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Rt6HWka0VKd6Ju7TnZ4nRw.png" data-width="1470" data-height="138" src="https://cdn-images-1.medium.com/max/800/1*Rt6HWka0VKd6Ju7TnZ4nRw.png"></figure><p name="b1e8" id="b1e8" class="graf graf--p graf-after--figure">This random variable represents the number of coin-flips you need to see the first head, using a (possibly unfair) coin.</p><ul class="postList"><li name="2fad" id="2fad" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Expectation</strong></li></ul><p name="05aa" id="05aa" class="graf graf--p graf-after--li">The conclusion here is pretty directly and common sense. But it could be proved based on the infinity series. However, we are not going to prove this here.</p><figure name="ccee" id="ccee" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YCuLOaYbmH-aV2JJkueRPA.png" data-width="1470" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*YCuLOaYbmH-aV2JJkueRPA.png"></figure><p name="9164" id="9164" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(6) Hypergeometric Distribution</strong></p><p name="f7c4" id="f7c4" class="graf graf--p graf-after--p">We say that X is a hypergeometric random variable if,</p><figure name="5c4d" id="5c4d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*t6SnS5PJKFrdJSnK4aDPVg.png" data-width="1470" data-height="194" src="https://cdn-images-1.medium.com/max/800/1*t6SnS5PJKFrdJSnK4aDPVg.png"></figure><p name="ee41" id="ee41" class="graf graf--p graf-after--figure">Where <em class="markup--em markup--p-em">x</em>, <em class="markup--em markup--p-em">n</em>, D, N satisfy, D ‚â§ N, <em class="markup--em markup--p-em">x </em>‚â§ <em class="markup--em markup--p-em">n</em>, <em class="markup--em markup--p-em">n </em>‚â§ D, and we can denote this case by X ~ Hypergeo(n, D, N).</p><p name="00a4" id="00a4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) Hypergeometric Distribution: An Example</strong></p><p name="f31b" id="f31b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Question</strong>: Suppose we have 34 girls and 66 boys in a class, and we want to randomly conduct a survey based on 10 students in this class. What is the probability that the survey sample has exactly 8 girls?</p><p name="c337" id="c337" class="graf graf--p graf-after--p">Solution:</p><p name="1e27" id="1e27" class="graf graf--p graf-after--p">In this case, D = 34, x = 8, N-D =66, n-x = 2, N = 100, n = 10, so that we have,</p><figure name="f058" id="f058" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tZ8KDjIUfJkaLEo1VsEulg.png" data-width="1470" data-height="140" src="https://cdn-images-1.medium.com/max/800/1*tZ8KDjIUfJkaLEo1VsEulg.png"></figure><p name="22c1" id="22c1" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(8) Continuous Distribution Reminder</strong></p><ul class="postList"><li name="6c40" id="6c40" class="graf graf--li graf-after--p">Uniform Distribution: over [a, b]</li><li name="baa9" id="baa9" class="graf graf--li graf-after--li">Exponential Distribution: with intensity parameter Œª</li><li name="29d5" id="29d5" class="graf graf--li graf-after--li graf--trailing">Normal Distribution: with mean Œº and variance œÉ¬≤</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/fb65980ceb23"><time class="dt-published" datetime="2020-08-28T05:55:55.078Z">August 28, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/probability-and-statistics-4-expectation-variance-moment-and-features-of-common-distributions-fb65980ceb23" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>