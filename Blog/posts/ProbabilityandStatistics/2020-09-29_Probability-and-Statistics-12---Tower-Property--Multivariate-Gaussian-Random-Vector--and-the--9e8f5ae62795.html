<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Probability and Statistics 12 | Tower Property, Multivariate Gaussian Random Vector, and the‚Ä¶</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Probability and Statistics 12 | Tower Property, Multivariate Gaussian Random Vector, and the‚Ä¶</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Probability and Statistics
</section>
<section data-field="body" class="e-content">
<section name="33ec" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="866c" id="866c" class="graf graf--h3 graf--leading graf--title">Probability and Statistics 12 | <strong class="markup--strong markup--h3-strong">Tower Property, Multivariate Gaussian Random Vector, and the Asymptotic Distribution of an¬†MLE</strong></h3><figure name="a01d" id="a01d" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*YTeSIjiYirbk4CZavQXCqg.jpeg" data-width="1602" data-height="1141" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*YTeSIjiYirbk4CZavQXCqg.jpeg"></figure><ol class="postList"><li name="adae" id="adae" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Tower Property (aka. Law of Total Expectation)</strong></li></ol><p name="ebe3" id="ebe3" class="graf graf--p graf-after--li">A fair coin is tossed until two tails occur successively. Let N be the total number of tosses required to terminate the experiment, then compute ùîº[N]. Then, the essence of the tower property is the following:</p><figure name="389c" id="389c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*aOr9dkkUIHErcpi4P3-j5Q.png" data-width="1300" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*aOr9dkkUIHErcpi4P3-j5Q.png"></figure><p name="0774" id="0774" class="graf graf--p graf-after--figure">Obviously, X must be wisely chosen to be helpful, which means X should be an <strong class="markup--strong markup--p-strong">indicator</strong> random variable or <strong class="markup--strong markup--p-strong">dummy</strong> random variable. For example, we let X = 1 if the first toss results in tails and X = 0 if the first toss results in heads, then,</p><figure name="8a7b" id="8a7b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0ounrxyHyJHoRfKwNjckdA.png" data-width="1300" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*0ounrxyHyJHoRfKwNjckdA.png"></figure><p name="11e6" id="11e6" class="graf graf--p graf-after--figure">then,</p><figure name="dcad" id="dcad" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*vUmnU4E6KKMmawd0dXxq-w.png" data-width="1300" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*vUmnU4E6KKMmawd0dXxq-w.png"></figure><p name="c94d" id="c94d" class="graf graf--p graf-after--figure">then,</p><figure name="f05f" id="f05f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*cgYCUatMrLnJKuOjPYU6RA.png" data-width="1300" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*cgYCUatMrLnJKuOjPYU6RA.png"></figure><p name="357e" id="357e" class="graf graf--p graf-after--figure">then,</p><figure name="4d95" id="4d95" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*TIPplSxXJwYvXAsjTbvfdw.png" data-width="1300" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*TIPplSxXJwYvXAsjTbvfdw.png"></figure><p name="fcdf" id="fcdf" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">2. Multivariate Gaussian Random Vector</strong></p><p name="e03e" id="e03e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of the Multivariate Gaussian Random Vector</strong></p><p name="000e" id="000e" class="graf graf--p graf-after--p">If <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> ~N(<strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œº</em></strong>, Œ£), then we say that <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> is a multivariate Gaussian Random Vector with mean vector <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œº</em></strong> and variance-covariance matrix Œ£. Suppose if <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> is k-dimensional, then <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œº</em></strong>‚àà‚Ñù·µè and Œ£ is a <em class="markup--em markup--p-em">k </em>√ó <em class="markup--em markup--p-em">k</em> matrix. The quadratic form of the matrix Œ£ is must be semi-definite, which means, ‚àÄ <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x </em></strong>‚àà‚Ñù·µè, then,</p><figure name="b7e9" id="b7e9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*AMMMzScq4Z6-SCXiyTXJKQ.png" data-width="1300" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*AMMMzScq4Z6-SCXiyTXJKQ.png"></figure><p name="62ea" id="62ea" class="graf graf--p graf-after--figure">The semi-definite also means that for all eigenvalues Œªi of Œ£, Œªi ‚â• 0.</p><p name="339b" id="339b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Mahalanobis Distance</strong></p><p name="24e8" id="24e8" class="graf graf--p graf-after--p">Suppose we have two vectors <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> and <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">y</em></strong>, and Œ£ is the variance-covariance matrix of some underlying set of data.</p><figure name="9461" id="9461" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9sg5zH0Mh-QRDPDF-6RhhQ.png" data-width="1300" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*9sg5zH0Mh-QRDPDF-6RhhQ.png"></figure><p name="3709" id="3709" class="graf graf--p graf-after--figure">Then this distance is called the Mahalanobis distance. This distance has a key role in discriminant analysis and in the k-means clustering.</p><p name="d847" id="d847" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Density Function for Multivariate Gaussian Random Vector</strong></p><p name="875a" id="875a" class="graf graf--p graf-after--p">The density function for vector <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> is,</p><figure name="0717" id="0717" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ZLm6MJkmRx8o4wivfwU58g.png" data-width="1300" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*ZLm6MJkmRx8o4wivfwU58g.png"></figure><p name="a01b" id="a01b" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Facts about Multivariate Gaussian Random Vector</strong></p><p name="5378" id="5378" class="graf graf--p graf-after--p">Suppose that <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> = (x1, x2,¬†‚Ä¶, xk) with <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">x</em></strong> ~N(<strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œº</em></strong>, Œ£), then</p><ul class="postList"><li name="0d6a" id="0d6a" class="graf graf--li graf-after--p">Every linear combination of components of <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">x</em></strong> is again Gaussian. In other words,</li></ul><figure name="1904" id="1904" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*qaMtaqA4xNaDNhtdR8WpOg.png" data-width="1300" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*qaMtaqA4xNaDNhtdR8WpOg.png"></figure><p name="6e03" id="6e03" class="graf graf--p graf-after--figure">We can also have the expectation as,</p><figure name="8d99" id="8d99" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*uIazHGUKnc1PfxbJ0P5mpg.png" data-width="1300" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*uIazHGUKnc1PfxbJ0P5mpg.png"></figure><p name="f903" id="f903" class="graf graf--p graf-after--figure">and the variance as,</p><figure name="ec56" id="ec56" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*QfAwGmRn6vcUYUuunvCflw.png" data-width="1300" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*QfAwGmRn6vcUYUuunvCflw.png"></figure><ul class="postList"><li name="d998" id="d998" class="graf graf--li graf-after--figure">For any such <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">x</em></strong>, there exists a matrix <strong class="markup--strong markup--li-strong">A</strong> so that,</li></ul><figure name="d0bb" id="d0bb" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*iAyWPNTAJERJMQ6pfQLZXQ.png" data-width="1300" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*iAyWPNTAJERJMQ6pfQLZXQ.png"></figure><p name="c36b" id="c36b" class="graf graf--p graf-after--figure">where <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">z</em></strong> is a <em class="markup--em markup--p-em">k</em>-dimensional vector of independent standard normal random variables. In fact, A is related to a square root of Œ£, which Œ£ always has because (a) Œ£ is semi-definite and (b) Œ£ is symmetric.</p><ul class="postList"><li name="fc49" id="fc49" class="graf graf--li graf-after--p">For any <em class="markup--em markup--li-em">k</em>, the level curves (or level sets ) of the density <em class="markup--em markup--li-em">f</em>(<strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">x</em></strong>) are ellipsoids.</li><li name="d279" id="d279" class="graf graf--li graf-after--li">If Xi and Xj are such that œÅ(Xi, Xj) = 0, then Xi and Xj are independent.</li><li name="abd4" id="abd4" class="graf graf--li graf-after--li">Two random variables that are normally distributed are not necessarily multivariate Gaussian.</li></ul><p name="5a22" id="5a22" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) Multivariate Gaussian Random Vector: An Example</strong></p><p name="a6c8" id="a6c8" class="graf graf--p graf-after--p">Suppose we have a random variable X ~ N(0, 1). Then if we define Y as Y = X if |X| &gt;<em class="markup--em markup--p-em"> c</em> and Y = -X if |X| &lt; <em class="markup--em markup--p-em">c</em>. Then it is clearly that Y ~ N(0, 1). Unfortunately, (X, Y) is nor bivariate normal because when |X| &gt;<em class="markup--em markup--p-em"> c</em>, Corr(X, Y) = 1, and when |X| &gt;<em class="markup--em markup--p-em"> c</em>, Corr(X, Y) = -1. Whereas a multivariate Gaussian has the same covariance, or same correlations throughout the support set of the dennsity.</p><p name="16cb" id="16cb" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Asymptotic Distribution of an MLE</strong></p><p name="0916" id="0916" class="graf graf--p graf-after--p">Suppose that X1, X2,¬†‚Ä¶, Xn is a random sample from some density <em class="markup--em markup--p-em">f</em>(<em class="markup--em markup--p-em">x</em>; <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œ∏</em></strong>). Let <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œ∏</em></strong>-cap be an MLE vector for <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œ∏</em></strong>. Under a set of conditions mentioned on the homework,</p><figure name="5853" id="5853" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*lvWWHxcvTxxyF1WYlmF5Tg.png" data-width="1300" data-height="78" src="https://cdn-images-1.medium.com/max/800/1*lvWWHxcvTxxyF1WYlmF5Tg.png"></figure><p name="12f7" id="12f7" class="graf graf--p graf-after--figure">where I is the fisher transformation.</p><p name="e33a" id="e33a" class="graf graf--p graf-after--p">In the case when <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œ∏</em></strong> = Œ∏ is one-dimensional,</p><figure name="4965" id="4965" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0EHn2-OYMrmjnKTy5uGoXA.png" data-width="1300" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*0EHn2-OYMrmjnKTy5uGoXA.png"></figure><p name="aa02" id="aa02" class="graf graf--p graf-after--figure graf--trailing">Whenever you are estimating a k-dimensional parameter vector Œ∏ that vector of MLEs <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Œ∏</em></strong>-cap is asymptotic multivariate Gaussian.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/9e8f5ae62795"><time class="dt-published" datetime="2020-09-29T13:33:32.788Z">September 29, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/probability-and-statistics-12-tower-property-multivariate-gaussian-random-vector-and-the-9e8f5ae62795" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>