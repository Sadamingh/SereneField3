<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Statistics for Application 2 | Confidence Interval, Moment Generating Functions, and Hoeffding’s…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Statistics for Application 2 | Confidence Interval, Moment Generating Functions, and Hoeffding’s…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Statistics for Application
</section>
<section data-field="body" class="e-content">
<section name="e27b" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="a3f7" id="a3f7" class="graf graf--h3 graf--leading graf--title">Statistics for Application 2 | <strong class="markup--strong markup--h3-strong">Confidence Interval, Moment Generating Functions, and </strong>Hoeffding’s Inequality</h3><figure name="1eac" id="1eac" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*xU6O5JeGtmiUtwuR4tX7Ew.png" data-width="1800" data-height="1200" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*xU6O5JeGtmiUtwuR4tX7Ew.png"></figure><ol class="postList"><li name="6cc7" id="6cc7" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Confidence Interval</strong></li></ol><p name="01f0" id="01f0" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) The Definition of Statistical Significance (aka. α) for Normal Distribution</strong></p><p name="5243" id="5243" class="graf graf--p graf-after--p">We define the statistical significance α for normal distribution as</p><figure name="8b2c" id="8b2c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*a1mGwiB3J6g880fJkamqaQ.png" data-width="1390" data-height="78" src="https://cdn-images-1.medium.com/max/800/1*a1mGwiB3J6g880fJkamqaQ.png"></figure><p name="8c53" id="8c53" class="graf graf--p graf-after--figure">We can use a plot to show this definition.</p><figure name="8ce1" id="8ce1" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/ac730d19e9e99e5a143dc816a2a09eda.js"></script></figure><figure name="622d" id="622d" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*FZL-1Rez5a4ETqpfAPyYfQ.png" data-width="1630" data-height="306" src="https://cdn-images-1.medium.com/max/800/1*FZL-1Rez5a4ETqpfAPyYfQ.png"></figure><p name="43c8" id="43c8" class="graf graf--p graf-after--figure">This is called statistical significance because when we are doing the hypothesis testing, what we are actually doing is to test whether or not some statistics are equal to 0 (which means these statistics are not important or two variables have no relationship). Because when the p-value is less than statistical significance, we can have enough evidence to reject the null hypothesis (statistics are equal to 0), so the result of these statistics must be significant.</p><p name="62cc" id="62cc" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Pivotal Distribution</strong></p><p name="0121" id="0121" class="graf graf--p graf-after--p">When we are trying to figure out the confidence interval, what we are actually doing is to switch the distribution under the data context to some distributions that we have already known. Then these distributions we known are called the pivotal distribution. We commonly denote the density function of a pivotal distribution as <em class="markup--em markup--p-em">Φn</em>(<em class="markup--em markup--p-em">x</em>) and we denote the density function of a standard normal distribution as <em class="markup--em markup--p-em">Φ</em>(<em class="markup--em markup--p-em">x</em>).</p><figure name="560e" id="560e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*HR20Oqfh7ThE7BLBlV7sJg.png" data-width="1246" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*HR20Oqfh7ThE7BLBlV7sJg.png"></figure><p name="9803" id="9803" class="graf graf--p graf-after--figure">Based on the CLT, we have that,</p><figure name="774a" id="774a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*rLdjm_MTwnmOheQBcqUhZA.png" data-width="1246" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*rLdjm_MTwnmOheQBcqUhZA.png"></figure><p name="18df" id="18df" class="graf graf--p graf-after--figure">Common pivotal distributions are as follows:</p><ul class="postList"><li name="41d0" id="41d0" class="graf graf--li graf-after--p">Standard normal distribution</li><li name="7458" id="7458" class="graf graf--li graf-after--li">Student’s t distribution</li><li name="da41" id="da41" class="graf graf--li graf-after--li">Χ² distribution</li><li name="42ba" id="42ba" class="graf graf--li graf-after--li">F distribution</li></ul><p name="2d1c" id="2d1c" class="graf graf--p graf-after--li">If we don’t have a computer alongside with us, probably, we can randomly open a statistics textbook and find tables of this pivotal distribution in the reference.</p><p name="4474" id="4474" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Pivotal Qualities (aka. pivots)</strong></p><p name="2d95" id="2d95" class="graf graf--p graf-after--p">The pivotal quality is a function of observations and unobservable parameters such that the function’s probability distribution does not depend on the unknown parameters.</p><p name="69d5" id="69d5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Confidence Interval of Mean</strong></p><p name="d560" id="d560" class="graf graf--p graf-after--p">Suppose we have only got one sample, and we have assumed that the number of random variables X1, X2, …, Xn in this sample is large enough for CLT. Then,</p><figure name="acc6" id="acc6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Chvq0h5UdB-5emry3SixZQ.png" data-width="1246" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*Chvq0h5UdB-5emry3SixZQ.png"></figure><p name="5945" id="5945" class="graf graf--p graf-after--figure">so we have,</p><figure name="3b19" id="3b19" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*khIm9SXkZV1jVzn7d2zI0g.png" data-width="1100" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*khIm9SXkZV1jVzn7d2zI0g.png"></figure><p name="3dda" id="3dda" class="graf graf--p graf-after--figure">then to solve μ, we have,</p><figure name="da08" id="da08" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0uFQol7iOoHwwq_HZhyfLQ.png" data-width="1100" data-height="162" src="https://cdn-images-1.medium.com/max/800/1*0uFQol7iOoHwwq_HZhyfLQ.png"></figure><p name="b869" id="b869" class="graf graf--p graf-after--figure">then,</p><figure name="d07b" id="d07b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*3eZylKzDTJ7C5b_zAoHY1Q.png" data-width="1366" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*3eZylKzDTJ7C5b_zAoHY1Q.png"></figure><p name="d44c" id="d44c" class="graf graf--p graf-after--figure">This is the confidence interval of the mean value of any distribution of random variable X.</p><p name="82f7" id="82f7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Moment Generating Functions</strong></p><p name="e99e" id="e99e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of the Moment Generating Function (aka. mgf)</strong></p><p name="0893" id="0893" class="graf graf--p graf-after--p">Suppose we have a random variable X and a constant t ∈ℝ, then, the moment generating function of X is denoted by <em class="markup--em markup--p-em">M</em>x(<em class="markup--em markup--p-em">t</em>) as,</p><figure name="b83f" id="b83f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*M9bMZXlnLQxCV5ryxmpEoQ.png" data-width="1150" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*M9bMZXlnLQxCV5ryxmpEoQ.png"></figure><p name="086f" id="086f" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) The Moment Generating Function for Discrete r.v. X</strong></p><p name="9de7" id="9de7" class="graf graf--p graf-after--p">Suppose we have a discrete random variable X, then its moment generating function is,</p><figure name="3b54" id="3b54" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wiaiFrKVG5oTsBAdhZRXKQ.png" data-width="1150" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*wiaiFrKVG5oTsBAdhZRXKQ.png"></figure><p name="0b0d" id="0b0d" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) The Moment Generating Function for Continuous r.v. X</strong></p><p name="a389" id="a389" class="graf graf--p graf-after--p">Suppose we have a continuous random variable X, then its moment generating function is,</p><figure name="36cb" id="36cb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LO5hMVL_J8Yy1ZR_aPZyKQ.png" data-width="1150" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*LO5hMVL_J8Yy1ZR_aPZyKQ.png"></figure><p name="34c1" id="34c1" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) The Meaning of the Moment Generating Function</strong></p><p name="4fe3" id="4fe3" class="graf graf--p graf-after--p">The moment generating function is called so because we can use the moment generating function to find the moments of the distribution of a random variable X by taking the derivative of the MGF and evaluating the derivative at zero.</p><p name="8923" id="8923" class="graf graf--p graf-after--p">The first moment is,</p><figure name="1915" id="1915" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*axOuffWWSOb0IZ_hxND9hQ.png" data-width="1388" data-height="114" src="https://cdn-images-1.medium.com/max/800/1*axOuffWWSOb0IZ_hxND9hQ.png"></figure><p name="7831" id="7831" class="graf graf--p graf-after--figure">thus,</p><figure name="65e0" id="65e0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jLi7bbusjDOj1ct-1kMhYw.png" data-width="1388" data-height="116" src="https://cdn-images-1.medium.com/max/800/1*jLi7bbusjDOj1ct-1kMhYw.png"></figure><p name="c12f" id="c12f" class="graf graf--p graf-after--figure">Also, the second moment is,</p><figure name="af79" id="af79" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*DBRfyCwrNEr7pUcrKxiQqQ.png" data-width="1388" data-height="114" src="https://cdn-images-1.medium.com/max/800/1*DBRfyCwrNEr7pUcrKxiQqQ.png"></figure><p name="c76e" id="c76e" class="graf graf--p graf-after--figure">then,</p><figure name="a1bc" id="a1bc" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*covaJJ7-oWsYHO5hY6es-A.png" data-width="1388" data-height="58" src="https://cdn-images-1.medium.com/max/800/1*covaJJ7-oWsYHO5hY6es-A.png"></figure><p name="9e25" id="9e25" class="graf graf--p graf-after--figure">then,</p><figure name="040d" id="040d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*rd1w1jtsIeAFIFeMQTCZkw.png" data-width="1388" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*rd1w1jtsIeAFIFeMQTCZkw.png"></figure><p name="00f4" id="00f4" class="graf graf--p graf-after--figure">then,</p><figure name="1846" id="1846" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Y4yx0yUbo1auRL_h3QwCag.png" data-width="1388" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*Y4yx0yUbo1auRL_h3QwCag.png"></figure><p name="5215" id="5215" class="graf graf--p graf-after--figure">Thus, we can have that,</p><figure name="2d97" id="2d97" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qULyxlbnmUcjTOjdjAR6vg.png" data-width="1134" data-height="236" src="https://cdn-images-1.medium.com/max/800/1*qULyxlbnmUcjTOjdjAR6vg.png"></figure><p name="a163" id="a163" class="graf graf--p graf-after--figure">Then we could have a much easier and general way to calculate the statistics related to the moment (for example, the expectations, the variances, the standard deviation, and etc.).</p><p name="9ad9" id="9ad9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Moment Generating Function: An Example</strong></p><p name="193b" id="193b" class="graf graf--p graf-after--p">Suppose we have a random variable X ~ exp(λ), then the density function of this random variable X should be,</p><figure name="cbee" id="cbee" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0_42m06dQKjk_7Kfc1_UfQ.png" data-width="1134" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*0_42m06dQKjk_7Kfc1_UfQ.png"></figure><p name="b3b7" id="b3b7" class="graf graf--p graf-after--figure">with X &gt; 0.</p><p name="111d" id="111d" class="graf graf--p graf-after--p">then by definition of the moment generating function,</p><figure name="2cf9" id="2cf9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*y4RxZi2Y2zSuarlqWWA0DA.png" data-width="1134" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*y4RxZi2Y2zSuarlqWWA0DA.png"></figure><p name="78ba" id="78ba" class="graf graf--p graf-after--figure">then,</p><figure name="a8a4" id="a8a4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*VJiV7T1bSldUBtMKgumD9w.png" data-width="1134" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*VJiV7T1bSldUBtMKgumD9w.png"></figure><p name="4db6" id="4db6" class="graf graf--p graf-after--figure">then,</p><figure name="89b8" id="89b8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Gh08Z2pesdeI8J4q8ruDnA.png" data-width="1134" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*Gh08Z2pesdeI8J4q8ruDnA.png"></figure><p name="4f64" id="4f64" class="graf graf--p graf-after--figure">thus, this is equal to solve,</p><figure name="93d8" id="93d8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jeVyXk8QynLrmrBPM4hrDQ.png" data-width="1134" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*jeVyXk8QynLrmrBPM4hrDQ.png"></figure><p name="1c2e" id="1c2e" class="graf graf--p graf-after--figure">In order to solve this, because we have assigned the constant <em class="markup--em markup--p-em">t</em> ∈ℝ, now it’s time to make some constraints of it. Suppose we let <em class="markup--em markup--p-em">t</em>-<em class="markup--em markup--p-em">λ &lt; </em>0, which is also to say that <em class="markup--em markup--p-em">t</em> &lt; <em class="markup--em markup--p-em">λ</em>. Then,</p><figure name="2da1" id="2da1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*EGJLgW38IYR8fEuCpWafog.png" data-width="1134" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*EGJLgW38IYR8fEuCpWafog.png"></figure><p name="4d44" id="4d44" class="graf graf--p graf-after--figure">thus, we can have that, when <em class="markup--em markup--p-em">t</em> &lt; <em class="markup--em markup--p-em">λ ,</em></p><figure name="aea8" id="aea8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*PB9qAsXrBDwKkrjRhwW4hQ.png" data-width="1134" data-height="96" src="https://cdn-images-1.medium.com/max/800/1*PB9qAsXrBDwKkrjRhwW4hQ.png"></figure><p name="3fc7" id="3fc7" class="graf graf--p graf-after--figure">So,</p><figure name="5136" id="5136" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*I-cw-P1cVS0YPBDUoZAz0w.png" data-width="1134" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*I-cw-P1cVS0YPBDUoZAz0w.png"></figure><p name="e5f3" id="e5f3" class="graf graf--p graf-after--figure">also,</p><figure name="5e8b" id="5e8b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WmB6Y8UjFoJZ7Niexc79_A.png" data-width="1134" data-height="106" src="https://cdn-images-1.medium.com/max/800/1*WmB6Y8UjFoJZ7Niexc79_A.png"></figure><p name="014e" id="014e" class="graf graf--p graf-after--figure">thus,</p><figure name="4937" id="4937" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*40A8XScIn8XAYwAwouzl0g.png" data-width="1134" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*40A8XScIn8XAYwAwouzl0g.png"></figure><p name="29ac" id="29ac" class="graf graf--p graf-after--figure">Therefore,</p><figure name="00a1" id="00a1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*8gk-FteeMJTS3s-cAM95uw.png" data-width="1134" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*8gk-FteeMJTS3s-cAM95uw.png"></figure><p name="f1a7" id="f1a7" class="graf graf--p graf-after--figure">and,</p><figure name="8a27" id="8a27" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qpt5DHQf8qaYZ0Oy3zjn4A.png" data-width="1134" data-height="94" src="https://cdn-images-1.medium.com/max/800/1*qpt5DHQf8qaYZ0Oy3zjn4A.png"></figure><p name="2632" id="2632" class="graf graf--p graf-after--figure">Note that the moment generating function of X is also,</p><figure name="7681" id="7681" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*-hOwTf_HIHHvy2a_6DP1Yw.png" data-width="1134" data-height="136" src="https://cdn-images-1.medium.com/max/800/1*-hOwTf_HIHHvy2a_6DP1Yw.png"></figure><p name="b038" id="b038" class="graf graf--p graf-after--figure">then this is going to be a quick and easy way to calculate the k-th (k for any integer &gt; 0) moment. We can find the mgf of the common distributions from <a href="https://en.wikipedia.org/wiki/Moment-generating_function" data-href="https://en.wikipedia.org/wiki/Moment-generating_function" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Wikipedia</a>.</p><p name="3e91" id="3e91" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Hoeffding’s Inequality</strong></p><p name="88df" id="88df" class="graf graf--p graf-after--p">In the previous case, we have talked about the CLT when n is large enough, but what if we have a sample that is not that large and we can not say that it will tend to have the CLT. The answer is to use Hoeffding’s Inequality.</p><p name="ddd3" id="ddd3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Markov’s Inequality</strong></p><p name="82d1" id="82d1" class="graf graf--p graf-after--p">Because when N is relatively small, the CLT no longer holds, so we have no idea about how the tails are going to look like. Actually, what we can do is to find the bound for the tails, and one of the most elementary tail bound is Markov’s inequality, which asserts that for a positive random variable X ≥ 0, with finite mean,</p><figure name="7480" id="7480" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jr5e9Vh8sVoVTplMRyeNfg.png" data-width="1246" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*jr5e9Vh8sVoVTplMRyeNfg.png"></figure><p name="40c5" id="40c5" class="graf graf--p graf-after--figure">For example,</p><figure name="9f8a" id="9f8a" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/97eab8002fc846edcface93ec481980a.js"></script></figure><figure name="7465" id="7465" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*TF7Zd3apbmJV3uMlmu2Ugw.png" data-width="1642" data-height="268" src="https://cdn-images-1.medium.com/max/800/1*TF7Zd3apbmJV3uMlmu2Ugw.png"></figure><p name="f869" id="f869" class="graf graf--p graf-after--figure">Proof:</p><p name="19fe" id="19fe" class="graf graf--p graf-after--p">Suppose we have a random variable X ≥ 0 and a positive number <em class="markup--em markup--p-em">t,</em></p><figure name="41e0" id="41e0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pePnBR01dp615rWaWwdIQA.png" data-width="1384" data-height="116" src="https://cdn-images-1.medium.com/max/800/1*pePnBR01dp615rWaWwdIQA.png"></figure><p name="4aa8" id="4aa8" class="graf graf--p graf-after--figure">then,</p><figure name="f1e7" id="f1e7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*epOgndAFNyYACWd62eeU7Q.png" data-width="1384" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*epOgndAFNyYACWd62eeU7Q.png"></figure><p name="7b60" id="7b60" class="graf graf--p graf-after--figure">which is,</p><figure name="3114" id="3114" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*VfpJ8wa-83GsK51y6-bspQ.png" data-width="1384" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*VfpJ8wa-83GsK51y6-bspQ.png"></figure><p name="ca28" id="ca28" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Chebyshev’s Inequality</strong></p><p name="ff89" id="ff89" class="graf graf--p graf-after--p">If we have positive random variable X ≥ 0 that satisfies,</p><figure name="0f60" id="0f60" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Pafk1tf1d3eSDn5gW9b09A.png" data-width="1384" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*Pafk1tf1d3eSDn5gW9b09A.png"></figure><p name="2948" id="2948" class="graf graf--p graf-after--figure">then,</p><figure name="c61a" id="c61a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*oV2JKP5BHnEyLS17l1j62A.png" data-width="1384" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*oV2JKP5BHnEyLS17l1j62A.png"></figure><p name="830c" id="830c" class="graf graf--p graf-after--figure">For example,</p><figure name="d6b9" id="d6b9" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/6084350961c8a5ecaba4ef3a506ee2d1.js"></script></figure><figure name="c077" id="c077" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*NQhRBCsdZ7CQiyC8nVAXNA.png" data-width="1652" data-height="272" src="https://cdn-images-1.medium.com/max/800/1*NQhRBCsdZ7CQiyC8nVAXNA.png"></figure><p name="01b6" id="01b6" class="graf graf--p graf-after--figure">Proof:</p><p name="70f9" id="70f9" class="graf graf--p graf-after--p">By definition,</p><figure name="aa12" id="aa12" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9moqJAvCmAMTBoujQMLRkA.png" data-width="1348" data-height="72" src="https://cdn-images-1.medium.com/max/800/1*9moqJAvCmAMTBoujQMLRkA.png"></figure><p name="4f0b" id="4f0b" class="graf graf--p graf-after--figure">By Markov’s inequation,</p><figure name="72a9" id="72a9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*BJ6os8nIWJUZOyVVJGi1-A.png" data-width="1348" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*BJ6os8nIWJUZOyVVJGi1-A.png"></figure><p name="54bd" id="54bd" class="graf graf--p graf-after--figure">therefore,</p><figure name="8a70" id="8a70" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*oV2JKP5BHnEyLS17l1j62A.png" data-width="1384" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*oV2JKP5BHnEyLS17l1j62A.png"></figure><p name="961b" id="961b" class="graf graf--p graf-after--figure">This is also,</p><figure name="91c8" id="91c8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LgkNxrnskDNqBd_n8VLexg.png" data-width="1300" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*LgkNxrnskDNqBd_n8VLexg.png"></figure><p name="2083" id="2083" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) <em class="markup--em markup--p-em">k</em>-th Central Moment Chebyshev’s Inequality</strong></p><p name="aad3" id="aad3" class="graf graf--p graf-after--p">This is very similar to Chebyshev’s inequality,</p><figure name="2341" id="2341" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*KPiXfKvJWNH_lfFLnPpYcw.png" data-width="1192" data-height="90" src="https://cdn-images-1.medium.com/max/800/1*KPiXfKvJWNH_lfFLnPpYcw.png"></figure><p name="f2f3" id="f2f3" class="graf graf--p graf-after--figure">Proof:</p><figure name="c76d" id="c76d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9o5ViYlX18zHo5MjZRmy0w.png" data-width="1192" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*9o5ViYlX18zHo5MjZRmy0w.png"></figure><figure name="0ffc" id="0ffc" class="graf graf--figure graf--iframe graf-after--figure"><script src="https://gist.github.com/Sadamingh/584ef2b6b97d3e954e414d984353361e.js"></script></figure><figure name="c86e" id="c86e" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*jb9QEkqhL3fYcqtENLHyxg.png" data-width="1632" data-height="596" src="https://cdn-images-1.medium.com/max/800/1*jb9QEkqhL3fYcqtENLHyxg.png"></figure><p name="e8df" id="e8df" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Recall: The Definition of Infimum and Supremum</strong></p><p name="a39c" id="a39c" class="graf graf--p graf-after--p">Assume we have a constant <em class="markup--em markup--p-em">p</em>, for all ϵ &gt; 0 and <em class="markup--em markup--p-em">x</em> ∈A satisfies,</p><figure name="69a3" id="69a3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1JEOdquW5dqskg0MDgOafQ.png" data-width="1150" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*1JEOdquW5dqskg0MDgOafQ.png"></figure><p name="77f7" id="77f7" class="graf graf--p graf-after--figure">then <em class="markup--em markup--p-em">p</em> is called the infimum of A and it is denoted as</p><figure name="6651" id="6651" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*T5RvItapCjZ7E_kH7i8QMw.png" data-width="1150" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*T5RvItapCjZ7E_kH7i8QMw.png"></figure><p name="ad84" id="ad84" class="graf graf--p graf-after--figure">Assume we have a constant <em class="markup--em markup--p-em">p</em>, for all ϵ &gt; 0 and <em class="markup--em markup--p-em">x</em> ∈A satisfies,</p><figure name="1a45" id="1a45" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*K33-G82RPYfJ87tE3wAD_g.png" data-width="1150" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*K33-G82RPYfJ87tE3wAD_g.png"></figure><p name="09c3" id="09c3" class="graf graf--p graf-after--figure">then <em class="markup--em markup--p-em">p</em> is called the supremum of A and it is denoted as</p><figure name="3a7e" id="3a7e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*o87H9L_dKZrizlwG8Bp5oQ.png" data-width="1150" data-height="64" src="https://cdn-images-1.medium.com/max/800/1*o87H9L_dKZrizlwG8Bp5oQ.png"></figure><p name="7240" id="7240" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Recall: Infimum and Supremum vs. Minimum and Maximum</strong></p><p name="a80a" id="a80a" class="graf graf--p graf-after--p">For a discrete finite set A,</p><figure name="d9bb" id="d9bb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qARlAdfIGX5UrHoItoEH-Q.png" data-width="1150" data-height="64" src="https://cdn-images-1.medium.com/max/800/1*qARlAdfIGX5UrHoItoEH-Q.png"></figure><p name="5e98" id="5e98" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(5) Chernoff Method</strong></p><p name="a0a7" id="a0a7" class="graf graf--p graf-after--p">By Markov’s inequality,</p><figure name="7e1a" id="7e1a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jr5e9Vh8sVoVTplMRyeNfg.png" data-width="1246" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*jr5e9Vh8sVoVTplMRyeNfg.png"></figure><p name="080d" id="080d" class="graf graf--p graf-after--figure">then the 1st central moment Chebyshev’s inequality is,</p><figure name="2d3a" id="2d3a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Dwzy5rPou_KZpEhspwoaLQ.png" data-width="1150" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*Dwzy5rPou_KZpEhspwoaLQ.png"></figure><p name="0b1e" id="0b1e" class="graf graf--p graf-after--figure">Suppose we let,</p><figure name="122a" id="122a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*-2bCekD6jNKgb4d2VS0-EA.png" data-width="1150" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*-2bCekD6jNKgb4d2VS0-EA.png"></figure><p name="8619" id="8619" class="graf graf--p graf-after--figure">then,</p><figure name="d046" id="d046" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*8EGBBOn8O0yypOC02RBDTQ.png" data-width="1150" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*8EGBBOn8O0yypOC02RBDTQ.png"></figure><p name="7aff" id="7aff" class="graf graf--p graf-after--figure">then, if we represent <em class="markup--em markup--p-em">t</em> as <em class="markup--em markup--p-em">u</em> and make <em class="markup--em markup--p-em">t</em> a new constant &gt; 0,</p><figure name="b1c4" id="b1c4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Xgo4dR1v0cCJbaHKiHiPcA.png" data-width="1150" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*Xgo4dR1v0cCJbaHKiHiPcA.png"></figure><p name="9351" id="9351" class="graf graf--p graf-after--figure">then,</p><figure name="4218" id="4218" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*j3sUR0m00iDm7lHhmogy0A.png" data-width="1150" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*j3sUR0m00iDm7lHhmogy0A.png"></figure><p name="0f84" id="0f84" class="graf graf--p graf-after--figure">then, because the exponential function is an increasing function, then,</p><figure name="e975" id="e975" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*nHVowiw8M0KNShhwE6Bjcg.png" data-width="1150" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*nHVowiw8M0KNShhwE6Bjcg.png"></figure><p name="2ec1" id="2ec1" class="graf graf--p graf-after--figure">Because μ is a constant, so that,</p><figure name="23d5" id="23d5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*sZF3G0ukhuOIraYFKXjLCA.png" data-width="1150" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*sZF3G0ukhuOIraYFKXjLCA.png"></figure><p name="b59d" id="b59d" class="graf graf--p graf-after--figure">then,</p><figure name="0c23" id="0c23" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*w4YdQH4-UTqaCiOdGHOJuQ.png" data-width="1150" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*w4YdQH4-UTqaCiOdGHOJuQ.png"></figure><p name="cfbe" id="cfbe" class="graf graf--p graf-after--figure">For many random variables, the moment generating function (we will talk about them later) will exist in a neighborhood around 0. This is to say that for some constant <em class="markup--em markup--p-em">b</em> &gt; 0, the moment generating function is finite for all |<em class="markup--em markup--p-em">t</em>| &lt; <em class="markup--em markup--p-em">b</em>. Because we also have that <em class="markup--em markup--p-em">t </em>&gt; 0, thus the support set of <em class="markup--em markup--p-em">t</em> should be 0 &lt; <em class="markup--em markup--p-em">t</em> &lt; <em class="markup--em markup--p-em">b</em>. Then, if we choose to get a tighter upper bound, we can have,</p><figure name="9b50" id="9b50" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*UvVq3vE0wb2ENFaToICPdw.png" data-width="1150" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*UvVq3vE0wb2ENFaToICPdw.png"></figure><p name="ebcf" id="ebcf" class="graf graf--p graf-after--figure">this is also,</p><figure name="7fa4" id="7fa4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ZH5JKA_kpRp5YsEK9Umu7Q.png" data-width="1150" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*ZH5JKA_kpRp5YsEK9Umu7Q.png"></figure><p name="966d" id="966d" class="graf graf--p graf-after--figure">also,</p><figure name="546d" id="546d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*dg3MW65e45403JyqI9Wo6A.png" data-width="1134" data-height="84" src="https://cdn-images-1.medium.com/max/800/1*dg3MW65e45403JyqI9Wo6A.png"></figure><p name="9083" id="9083" class="graf graf--p graf-after--figure">This is called Chernoff’s method of the bound.</p><p name="3007" id="3007" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Example #1 of Chernoff Method: Gaussian Tail Bounds</strong></p><p name="d984" id="d984" class="graf graf--p graf-after--p">Suppose we have a random variable X ~ N( <em class="markup--em markup--p-em">μ</em>, σ² ), we have the mgf as</p><figure name="408d" id="408d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*kmr2irX_sf_pfw0ztM7baA.png" data-width="1234" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*kmr2irX_sf_pfw0ztM7baA.png"></figure><p name="6b97" id="6b97" class="graf graf--p graf-after--figure">To apply Chernoff bound we then to compute,</p><figure name="75a6" id="75a6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ylORchyQbqHM093B2RewRQ.png" data-width="1302" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*ylORchyQbqHM093B2RewRQ.png"></figure><p name="4516" id="4516" class="graf graf--p graf-after--figure">By the fact that,</p><figure name="0243" id="0243" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*xl-bqr_jzIpfnYVE7mmdVw.png" data-width="1302" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*xl-bqr_jzIpfnYVE7mmdVw.png"></figure><p name="27b4" id="27b4" class="graf graf--p graf-after--figure">then,</p><figure name="0d54" id="0d54" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1frFtzBXk-Jb-NieWjX4ow.png" data-width="1302" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*1frFtzBXk-Jb-NieWjX4ow.png"></figure><p name="f733" id="f733" class="graf graf--p graf-after--figure">then,</p><figure name="447d" id="447d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*oOBTK8sczS5ia4ZAZeRp8A.png" data-width="1302" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*oOBTK8sczS5ia4ZAZeRp8A.png"></figure><p name="873e" id="873e" class="graf graf--p graf-after--figure">so that,</p><figure name="0c11" id="0c11" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tLT9eCw2Lc7XjvPWoC7OJg.png" data-width="1302" data-height="84" src="https://cdn-images-1.medium.com/max/800/1*tLT9eCw2Lc7XjvPWoC7OJg.png"></figure><p name="6bb9" id="6bb9" class="graf graf--p graf-after--figure">This is often referred to as a one-sided or upper tail bound of the Gaussian tail bound. We can check this by,</p><figure name="7550" id="7550" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/6797f22086ce86c33eeb7327a99c7bdb.js"></script></figure><p name="23ee" id="23ee" class="graf graf--p graf-after--figure">We can edit the times of trials N, μ, σ, and also u in this program to get the same output:</p><pre name="9c16" id="9c16" class="graf graf--pre graf-after--p">The inequation holds in {N} times trials</pre><p name="abe7" id="abe7" class="graf graf--p graf-after--pre">We can repeat the above calculation to obtain the analogous lower tail bound,</p><figure name="2312" id="2312" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*_nXCJPirvMBgce2e9pt25A.png" data-width="1300" data-height="90" src="https://cdn-images-1.medium.com/max/800/1*_nXCJPirvMBgce2e9pt25A.png"></figure><p name="c59b" id="c59b" class="graf graf--p graf-after--figure">So to put these two pieces together, we can get the <strong class="markup--strong markup--p-strong">two-sided Gaussian tail bound</strong>,</p><figure name="be27" id="be27" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*P4i5lULSHGhT41mXcBWQPQ.png" data-width="1300" data-height="90" src="https://cdn-images-1.medium.com/max/800/1*P4i5lULSHGhT41mXcBWQPQ.png"></figure><p name="c3a6" id="c3a6" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(7) Chernoff Method Gaussian Tail Bounds and CLT</strong></p><p name="6d1a" id="6d1a" class="graf graf--p graf-after--p">Suppose we have <em class="markup--em markup--p-em">i.i.d.</em> Gaussian random variables X1, X2, …, Xn ~ N(μ, σ²). We can construct the estimate:</p><figure name="7f2e" id="7f2e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jPlj0NHrO-OfSiWPouhASQ.png" data-width="1300" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*jPlj0NHrO-OfSiWPouhASQ.png"></figure><p name="63d1" id="63d1" class="graf graf--p graf-after--figure">When n is large enough, by CLT,</p><figure name="834f" id="834f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YmMYsUekN93TmrsdbWvKqw.png" data-width="1300" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*YmMYsUekN93TmrsdbWvKqw.png"></figure><p name="2588" id="2588" class="graf graf--p graf-after--figure">Thus, we can have the conclusion that,</p><figure name="3512" id="3512" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YwMLowMG5YPBeH5AhBDNIQ.png" data-width="1300" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*YwMLowMG5YPBeH5AhBDNIQ.png"></figure><p name="0577" id="0577" class="graf graf--p graf-after--figure">However, when n is not large enough, this equation no longer holds. But by Chernoff’s bounds of Gaussian tail, we can have the bound of the tails. First of all, we know that,</p><figure name="bdf6" id="bdf6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*GQ3Spux0g-hoC7Cf78euXA.png" data-width="1300" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*GQ3Spux0g-hoC7Cf78euXA.png"></figure><p name="cddf" id="cddf" class="graf graf--p graf-after--figure">then,</p><figure name="1362" id="1362" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wnoHhV1mxeitVy5OWWDfBw.png" data-width="1300" data-height="126" src="https://cdn-images-1.medium.com/max/800/1*wnoHhV1mxeitVy5OWWDfBw.png"></figure><p name="244f" id="244f" class="graf graf--p graf-after--figure">thus,</p><figure name="c7af" id="c7af" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*kmjPM5pnahnqs6JUbuxDmg.png" data-width="1300" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*kmjPM5pnahnqs6JUbuxDmg.png"></figure><p name="f778" id="f778" class="graf graf--p graf-after--figure">this bound works for all n’s.</p><p name="21e2" id="21e2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(8) The Definition of the Hoeffding’s Inequality</strong></p><p name="57ca" id="57ca" class="graf graf--p graf-after--p">By Chernoff’s bounds of Gaussian tail, we can have,</p><figure name="69a1" id="69a1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*kmjPM5pnahnqs6JUbuxDmg.png" data-width="1300" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*kmjPM5pnahnqs6JUbuxDmg.png"></figure><p name="c8a3" id="c8a3" class="graf graf--p graf-after--figure">if we let,</p><figure name="2096" id="2096" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*95DSJBRn-fjEHdTO8jTbjQ.png" data-width="1300" data-height="108" src="https://cdn-images-1.medium.com/max/800/1*95DSJBRn-fjEHdTO8jTbjQ.png"></figure><p name="0a0a" id="0a0a" class="graf graf--p graf-after--figure">then,</p><figure name="d64b" id="d64b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*QLNFOJ3eyzj-DDVefAMFDw.png" data-width="1102" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*QLNFOJ3eyzj-DDVefAMFDw.png"></figure><p name="b987" id="b987" class="graf graf--p graf-after--figure">Suppose ΣX/n∈[<em class="markup--em markup--p-em">a</em>, <em class="markup--em markup--p-em">b</em>] (<em class="markup--em markup--p-em">a</em> &lt; <em class="markup--em markup--p-em">b</em> and they are given numbers),</p><figure name="df5b" id="df5b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jEs84hc_aBmoE9xWpI7B5Q.png" data-width="1102" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*jEs84hc_aBmoE9xWpI7B5Q.png"></figure><p name="d859" id="d859" class="graf graf--p graf-after--figure">then, if we let u = t,</p><figure name="e9ff" id="e9ff" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*GymlJJhgKTE428LuC0lIxA.png" data-width="1102" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*GymlJJhgKTE428LuC0lIxA.png"></figure><p name="4369" id="4369" class="graf graf--p graf-after--figure">With some effort you can derive a slightly tighter bound (not going to prove here),</p><figure name="4212" id="4212" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*49vM8UhQ_7diJnlP1CUzWw.png" data-width="1102" data-height="88" src="https://cdn-images-1.medium.com/max/800/1*49vM8UhQ_7diJnlP1CUzWw.png"></figure><p name="65b0" id="65b0" class="graf graf--p graf-after--figure">Thus, let <em class="markup--em markup--p-em">n</em> be a positive integer and X, X1, X2, …, Xn are independent and identically distributed random variables such that X∈[<em class="markup--em markup--p-em">a</em>, <em class="markup--em markup--p-em">b</em>] (<em class="markup--em markup--p-em">a</em> &lt; <em class="markup--em markup--p-em">b</em> and they are given numbers). Let <em class="markup--em markup--p-em">μ = </em>𝔼[X]. Then for all ϵ &gt; 0, we have that,</p><figure name="d5ea" id="d5ea" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*3bOWvgNWmkvGvM-04owlkw.png" data-width="1246" data-height="98" src="https://cdn-images-1.medium.com/max/800/1*3bOWvgNWmkvGvM-04owlkw.png"></figure><p name="fb7c" id="fb7c" class="graf graf--p graf-after--figure graf--trailing">This is called the Hoeffding’s inequality.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/1f94c684f5cf"><time class="dt-published" datetime="2020-10-04T19:32:55.421Z">October 4, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/statistics-for-application-2-confidence-interval-moment-generating-functions-and-hoeffdings-1f94c684f5cf" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>