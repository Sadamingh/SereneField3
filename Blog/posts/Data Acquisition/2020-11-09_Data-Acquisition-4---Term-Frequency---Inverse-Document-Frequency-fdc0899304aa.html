<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Data Acquisition 4 | Term Frequency — Inverse Document Frequency</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Data Acquisition 4 | Term Frequency — Inverse Document Frequency</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Data Acquisition
</section>
<section data-field="body" class="e-content">
<section name="1cd8" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="9885" id="9885" class="graf graf--h3 graf--leading graf--title">Data Acquisition 4 | T<strong class="markup--strong markup--h3-strong">erm Frequency — Inverse Document Frequency</strong></h3><figure name="d20e" id="d20e" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*TPcfJZwTaWoP2o_HiQBOVw.png" data-width="1150" data-height="604" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*TPcfJZwTaWoP2o_HiQBOVw.png"></figure><ol class="postList"><li name="d996" id="d996" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Tokenization</strong></li></ol><p name="9a99" id="9a99" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) The Definition of Tokenization</strong></p><p name="1c67" id="1c67" class="graf graf--p graf-after--p">Given a character sequence (string) or a defined document unit, tokenization is the task of chopping it up into pieces (smaller chunks), called <em class="markup--em markup--p-em">tokens. </em>For example, we can tokenize the following string,</p><pre name="77bd" id="77bd" class="graf graf--pre graf-after--p">&#39;He can can a can.&#39;</pre><p name="b31d" id="b31d" class="graf graf--p graf-after--pre">By,</p><figure name="9555" id="9555" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/d7f6112fb11a26b5afd1c58cd68be03e.js"></script></figure><p name="698d" id="698d" class="graf graf--p graf-after--figure">then,</p><pre name="2467" id="2467" class="graf graf--pre graf-after--p">[&#39;He&#39;, &#39;can&#39;, &#39;can&#39;, &#39;a&#39;, &#39;can&#39;, &#39;.&#39;]</pre><p name="0f9b" id="0f9b" class="graf graf--p graf-after--pre">If you are meeting a punkt error, please refer to the article,</p><div name="39bd" id="39bd" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/adamedelwiess/manually-download-the-nltk-data-packages-529f81df3deb" data-href="https://medium.com/adamedelwiess/manually-download-the-nltk-data-packages-529f81df3deb" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/adamedelwiess/manually-download-the-nltk-data-packages-529f81df3deb"><strong class="markup--strong markup--mixtapeEmbed-strong">Manually Download the NLTK Data Packages</strong><br><em class="markup--em markup--mixtapeEmbed-em">Series: NLTK</em>medium.com</a><a href="https://medium.com/adamedelwiess/manually-download-the-nltk-data-packages-529f81df3deb" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="001e1ea72c6f6e51b7d5019131409dde" data-thumbnail-img-id="1*jVPRnTJJ8vQB8Uu68Tuqog.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*jVPRnTJJ8vQB8Uu68Tuqog.png);"></a></div><p name="b1d8" id="b1d8" class="graf graf--p graf-after--mixtapeEmbed">We can also<strong class="markup--strong markup--p-strong"> </strong>at the same time throwing away certain characters, such as punctuation.</p><figure name="c736" id="c736" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/846036263e652a0b2f83a8aa343b48a4.js"></script></figure><p name="438e" id="438e" class="graf graf--p graf-after--figure">Note that the process of tokenization is one step in preparing for NLP.</p><p name="0830" id="0830" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) String Split vs. Tokenizing</strong></p><p name="d539" id="d539" class="graf graf--p graf-after--p">Someone may think that the tokenizing is similar to split. However, this is not right. The tokenizing method achieves tokens in the linguistics sense, while the string split based only on the specific character. We can see the following example,</p><p name="e58b" id="e58b" class="graf graf--p graf-after--p">By tokenizing,</p><pre name="45ff" id="45ff" class="graf graf--pre graf-after--p">word_tokenize(&#39;I\&#39;m not split.&#39;)</pre><p name="bc6f" id="bc6f" class="graf graf--p graf-after--pre">then, we are going to have,</p><pre name="d71c" id="d71c" class="graf graf--pre graf-after--p">[&#39;I&#39;, &quot;&#39;m&quot;, &#39;not&#39;, &#39;split&#39;, &#39;.&#39;]</pre><p name="4140" id="4140" class="graf graf--p graf-after--pre">By string split,</p><pre name="0cdd" id="0cdd" class="graf graf--pre graf-after--p">&#39;I\&#39;m not split.&#39;.split(&#39; &#39;)</pre><p name="24ea" id="24ea" class="graf graf--p graf-after--pre">then, we are going to have,</p><pre name="6d6f" id="6d6f" class="graf graf--pre graf-after--p">[&quot;I&#39;m&quot;, &#39;not&#39;, &#39;split.&#39;]</pre><p name="0092" id="0092" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(3) Word Token vs. Word Type</strong></p><p name="7112" id="7112" class="graf graf--p graf-after--p">See <a href="https://en.wikipedia.org/wiki/Type%E2%80%93token_distinction#:~:text=The%20type%E2%80%93token%20distinction%20separates,object%20that%20instantiates%20that%20type." data-href="https://en.wikipedia.org/wiki/Type%E2%80%93token_distinction#:~:text=The%20type%E2%80%93token%20distinction%20separates,object%20that%20instantiates%20that%20type." class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Wikipedia</a> for more information.</p><p name="7df7" id="7df7" class="graf graf--p graf-after--p">The main difference between token and type is the type of a string only includes distinct tokens. For example, we can get the type by,</p><figure name="a7b2" id="a7b2" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/8b5223689a1147f77cf45c3a6248765e.js"></script></figure><p name="747f" id="747f" class="graf graf--p graf-after--figure">then,</p><pre name="b3b2" id="b3b2" class="graf graf--pre graf-after--p">[&#39;He&#39;, &#39;can&#39;, &#39;a&#39;]</pre><p name="5ed3" id="5ed3" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">2. TFIDF</strong></p><p name="5a0e" id="5a0e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of the Term Frequency</strong></p><p name="b9c9" id="b9c9" class="graf graf--p graf-after--p">People always talking about the term frequency and the term means token. It is defined by,</p><figure name="f30c" id="f30c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FBwYnG1TNH0sB-ZYClVlSA.png" data-width="1236" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*FBwYnG1TNH0sB-ZYClVlSA.png"></figure><p name="03ff" id="03ff" class="graf graf--p graf-after--figure">where <em class="markup--em markup--p-em">d</em> is a specific document and |d| means the number of terms in this d file.</p><p name="cef8" id="cef8" class="graf graf--p graf-after--p">Suppose we are given three documents,</p><pre name="cea1" id="cea1" class="graf graf--pre graf-after--p">d1 = &quot;in the new york times in&quot;<br>d2 = &quot;the new york post&quot;<br>d3 = &quot;the los angeles times&quot;<br>docstrs = [d1,d2,d3]</pre><p name="c15c" id="c15c" class="graf graf--p graf-after--pre">then we can calculate the term frequency of each document by,</p><figure name="f521" id="f521" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/f2c8c91e83b3a7b09938369bc32868c7.js"></script></figure><p name="4896" id="4896" class="graf graf--p graf-after--figure">the output is,</p><pre name="2c7e" id="2c7e" class="graf graf--pre graf-after--p">[[(&#39;in&#39;, 0.3333333333333333),<br>  (&#39;the&#39;, 0.16666666666666666),<br>  (&#39;new&#39;, 0.16666666666666666),<br>  (&#39;york&#39;, 0.16666666666666666),<br>  (&#39;times&#39;, 0.16666666666666666)],<br> [(&#39;the&#39;, 0.25), (&#39;new&#39;, 0.25), (&#39;york&#39;, 0.25), (&#39;post&#39;, 0.25)],<br> [(&#39;the&#39;, 0.25), (&#39;los&#39;, 0.25), (&#39;angeles&#39;, 0.25), (&#39;times&#39;, 0.25)]]</pre><p name="fccb" id="fccb" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(2) The Definition of the Document Frequency</strong></p><p name="3806" id="3806" class="graf graf--p graf-after--p">The document frequency is defined by the number of documents with a specific term divided by the number of all terms of all documents, which is,</p><figure name="0cfe" id="0cfe" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*fCkydZJoYUReJ_XC2gos-A.png" data-width="1236" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*fCkydZJoYUReJ_XC2gos-A.png"></figure><p name="4a71" id="4a71" class="graf graf--p graf-after--figure">where N is the number of all the terms in all the documents.</p><p name="d250" id="d250" class="graf graf--p graf-after--p">then we can calculate the document frequency of each document by,</p><figure name="2501" id="2501" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/09c1d101637092c9797365f72667f964.js"></script></figure><p name="a7b8" id="a7b8" class="graf graf--p graf-after--figure">the output is,</p><pre name="0c9e" id="0c9e" class="graf graf--pre graf-after--p">[(&#39;in&#39;, 0.3333333333333333),<br> (&#39;the&#39;, 1.0),<br> (&#39;new&#39;, 0.6666666666666666),<br> (&#39;york&#39;, 0.6666666666666666),<br> (&#39;times&#39;, 0.6666666666666666),<br> (&#39;post&#39;, 0.3333333333333333),<br> (&#39;los&#39;, 0.3333333333333333),<br> (&#39;angeles&#39;, 0.3333333333333333)]</pre><p name="a7a9" id="a7a9" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(3) Additive Smoothing Document Frequency</strong></p><p name="1710" id="1710" class="graf graf--p graf-after--p">To use the <a href="https://en.wikipedia.org/wiki/Additive_smoothing" data-href="https://en.wikipedia.org/wiki/Additive_smoothing" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">additive smoothing</a> method (we don’t have to understand this) onto the document frequency, we are supposed to get a better result,</p><figure name="dbaa" id="dbaa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LIYVZi9b9jT8KcVIvr10Ng.png" data-width="1106" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*LIYVZi9b9jT8KcVIvr10Ng.png"></figure><p name="d086" id="d086" class="graf graf--p graf-after--figure">The program of the additive smoothing document frequency is,</p><figure name="2f69" id="2f69" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/ceacad0a0fa9e054484aa3712ad2acb2.js"></script></figure><p name="bdc3" id="bdc3" class="graf graf--p graf-after--figure">The output of this program is,</p><pre name="57b2" id="57b2" class="graf graf--pre graf-after--p">[(&#39;in&#39;, 0.5),<br> (&#39;the&#39;, 1.0),<br> (&#39;new&#39;, 0.75),<br> (&#39;york&#39;, 0.75),<br> (&#39;times&#39;, 0.75),<br> (&#39;post&#39;, 0.5),<br> (&#39;los&#39;, 0.5),<br> (&#39;angeles&#39;, 0.5)]</pre><p name="a6ce" id="a6ce" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(4) Inverse Additive Smoothing Document Frequency</strong></p><p name="1f8d" id="1f8d" class="graf graf--p graf-after--p">The IDF is the inverse document frequency, it can be calculated by,</p><figure name="4f36" id="4f36" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*avcfeQneil_BgwQD-JKa4g.png" data-width="1106" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*avcfeQneil_BgwQD-JKa4g.png"></figure><p name="32b9" id="32b9" class="graf graf--p graf-after--figure">Then the program is,</p><figure name="5059" id="5059" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/329a2742399db5ebbde38ded081a51ca.js"></script></figure><p name="df48" id="df48" class="graf graf--p graf-after--figure">The output of this program is,</p><pre name="6d90" id="6d90" class="graf graf--pre graf-after--p">[(&#39;in&#39;, 2.0),<br> (&#39;the&#39;, 1.0),<br> (&#39;new&#39;, 1.3333333333333333),<br> (&#39;york&#39;, 1.3333333333333333),<br> (&#39;times&#39;, 1.3333333333333333),<br> (&#39;post&#39;, 2.0),<br> (&#39;los&#39;, 2.0),<br> (&#39;angeles&#39;, 2.0)]</pre><p name="26f2" id="26f2" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(5) Log Inverse Additive Smoothing Document Frequency</strong></p><p name="c50e" id="c50e" class="graf graf--p graf-after--p">The log IDF is the log result of the inverse document frequency, it can be calculated by,</p><figure name="bdb3" id="bdb3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*_luE9Wr9eCOmkH0UZOt7cg.png" data-width="1106" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*_luE9Wr9eCOmkH0UZOt7cg.png"></figure><p name="ee07" id="ee07" class="graf graf--p graf-after--figure">it doesn’t matter whether you are using 2, e, or 10 for the basement of the log because it won’t change the overall rank of this document frequency. We choose to use 10 as our basement but you can also replace this with some other values,</p><figure name="e920" id="e920" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/34f43a4417035b6450335eca2af46d2b.js"></script></figure><p name="7c46" id="7c46" class="graf graf--p graf-after--figure">The output of this program is,</p><pre name="fd81" id="fd81" class="graf graf--pre graf-after--p">[(&#39;in&#39;, 0.3010299956639812),<br> (&#39;the&#39;, 0.0),<br> (&#39;new&#39;, 0.12493873660829993),<br> (&#39;york&#39;, 0.12493873660829993),<br> (&#39;times&#39;, 0.12493873660829993),<br> (&#39;post&#39;, 0.3010299956639812),<br> (&#39;los&#39;, 0.3010299956639812),<br> (&#39;angeles&#39;, 0.3010299956639812)]</pre><p name="30ef" id="30ef" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(6) Combine All the Results</strong></p><p name="c4d5" id="c4d5" class="graf graf--p graf-after--p">We have calculated TFs and IDF, then we want to combine them in a data frame. The program should be,</p><figure name="0b29" id="0b29" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/3a3a2eb22d403095b8399c990964cb5f.js"></script></figure><p name="ceb5" id="ceb5" class="graf graf--p graf-after--figure">The output is,</p><figure name="fb75" id="fb75" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*HejER17iTrPewVsn2qv1JA.png" data-width="1192" data-height="464" src="https://cdn-images-1.medium.com/max/800/1*HejER17iTrPewVsn2qv1JA.png"></figure><p name="d275" id="d275" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(7) Calculate TF-IDF</strong></p><p name="3344" id="3344" class="graf graf--p graf-after--p">The TFIDF can be calculated by,</p><figure name="8c8f" id="8c8f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tx9BsONJesDrX6VqED7vVg.png" data-width="1106" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*tx9BsONJesDrX6VqED7vVg.png"></figure><p name="bb0f" id="bb0f" class="graf graf--p graf-after--figure">The program is,</p><figure name="6e5a" id="6e5a" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/a3557f61b0b45bbfe54927d476a48554.js"></script></figure><p name="f193" id="f193" class="graf graf--p graf-after--figure">The output is,</p><figure name="2cea" id="2cea" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*R1ueJeHtPwyZj-fRBpozBQ.png" data-width="1256" data-height="448" src="https://cdn-images-1.medium.com/max/800/1*R1ueJeHtPwyZj-fRBpozBQ.png"></figure><p name="9baf" id="9baf" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">3. TFIDF with Sklearn</strong></p><p name="d365" id="d365" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Count Vectorizer</strong></p><p name="b26e" id="b26e" class="graf graf--p graf-after--p">We can calculate the following matrix by sklearn, this matrix is called the count vectorizer,</p><figure name="a4f5" id="a4f5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*b21heAWjdOREFqYuSY7JnA.png" data-width="1056" data-height="226" src="https://cdn-images-1.medium.com/max/800/1*b21heAWjdOREFqYuSY7JnA.png"></figure><p name="28d9" id="28d9" class="graf graf--p graf-after--figure">This table counts terms in each document and it provides us all the information that we have to collect in order to calculate TFIDF. The program is,</p><figure name="6e70" id="6e70" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/8b6cce5383b313240c589b30ff32fadd.js"></script></figure><p name="05a6" id="05a6" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) TFIDF by Sklearn</strong></p><p name="e0f2" id="e0f2" class="graf graf--p graf-after--p">Because count vectorizer X gives us all the information that we need to calculate TFIDF, then we can calculate TFIDF by this matrix,</p><figure name="a977" id="a977" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/2aeb1ca65174eb109f6825c2f7502477.js"></script></figure><p name="f9c4" id="f9c4" class="graf graf--p graf-after--figure">the output of this program is,</p><figure name="7deb" id="7deb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ftwg19f5E94UvqARubshXg.png" data-width="1490" data-height="230" src="https://cdn-images-1.medium.com/max/800/1*ftwg19f5E94UvqARubshXg.png"></figure><p name="2436" id="2436" class="graf graf--p graf-after--figure graf--trailing">Note that we have a different result of TFIDF, this is because the formula that sklearn uses to calculate IDF has a sight difference from our formula. In general, it won’t change our final conclusion because of this difference.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/fdc0899304aa"><time class="dt-published" datetime="2020-11-09T11:38:48.756Z">November 9, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/data-acquisition-4-term-frequency-inverse-document-frequency-fdc0899304aa" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>