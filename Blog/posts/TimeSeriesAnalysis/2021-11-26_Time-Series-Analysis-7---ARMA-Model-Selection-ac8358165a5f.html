<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Time Series Analysis 7 | ARMA Model Selection</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Time Series Analysis 7 | ARMA Model Selection</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Time Series Analysis
</section>
<section data-field="body" class="e-content">
<section name="09fa" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7ded" id="7ded" class="graf graf--h3 graf--leading graf--title">Time Series Analysis 7 | ARMA Model Selection</h3><figure name="d11d" id="d11d" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*kH-Uz3L7F2wswxIpCW-R3A.png" data-width="1396" data-height="782" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*kH-Uz3L7F2wswxIpCW-R3A.png"></figure><ol class="postList"><li name="1f6b" id="1f6b" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Order Selection</strong></li></ol><p name="4c83" id="4c83" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Recall: AIC and BIC</strong></p><p name="ea26" id="ea26" class="graf graf--p graf-after--p">We have discussed AIC and BIC in the <a href="https://medium.com/adamedelwiess/linear-regression-9-model-diagnosis-process-for-mlr-part-3-a4fa4e870952" data-href="https://medium.com/adamedelwiess/linear-regression-9-model-diagnosis-process-for-mlr-part-3-a4fa4e870952" class="markup--anchor markup--p-anchor" target="_blank">linear regression</a> series, and now let’s review them before we continue. AIC and BIC metrics choose the model with the largest log-likelihood with a penalty term on the number of estimate parameters.</p><ul class="postList"><li name="9396" id="9396" class="graf graf--li graf-after--p">Akaike Information Criterion (AIC)</li></ul><figure name="7e6e" id="7e6e" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*57a9rQ8Sc4Nhx8-HVTvSkg.png" data-width="1680" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*57a9rQ8Sc4Nhx8-HVTvSkg.png"></figure><ul class="postList"><li name="f5b6" id="f5b6" class="graf graf--li graf-after--figure">Bayesian Information Criterion (BIC)</li></ul><figure name="5a29" id="5a29" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*cihjslyRvGeiyKfT16NUxw.png" data-width="1680" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*cihjslyRvGeiyKfT16NUxw.png"></figure><p name="246a" id="246a" class="graf graf--p graf-after--figure">where, for an ARMA(<em class="markup--em markup--p-em">p</em>, <em class="markup--em markup--p-em">q</em>) model, <em class="markup--em markup--p-em">k</em> should equal to,</p><figure name="4ba8" id="4ba8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*5OCaNqk8zMPeJSX1ffZJ4w.png" data-width="1344" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*5OCaNqk8zMPeJSX1ffZJ4w.png"></figure><p name="b840" id="b840" class="graf graf--p graf-after--figure">Also, <em class="markup--em markup--p-em">n</em> in BIC is the number of observations.</p><p name="1200" id="1200" class="graf graf--p graf-after--p">Because they are both model selection metrics, we can also refer to the following table,</p><figure name="5a9a" id="5a9a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*EActTua_M3ofYgHz.png" data-width="1400" data-height="424" src="https://cdn-images-1.medium.com/max/800/0*EActTua_M3ofYgHz.png"></figure><p name="9b04" id="9b04" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Properties of AIC/BIC for Model Selection</strong></p><ul class="postList"><li name="b283" id="b283" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">BIC tends to choose simpler models</strong>: This is because <em class="markup--em markup--li-em">n</em> ≫ e² ≈ 8.</li><li name="bf00" id="bf00" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Generality</strong>: They can protect us from overfitting by constraining the number of parameters.</li><li name="85c9" id="85c9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">No need for train-test splitting</strong>: the whole data gives the best estimate of the likelihood.</li><li name="7edb" id="7edb" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Only works for the same model family</strong>: for example, we can compare an ARMA(1,2) process and an ARMA(2,3) process, but we can not compare an ARMA(1,2) process to a Prophet model.</li></ul><p name="f444" id="f444" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Train/Validation/Test Sets</strong></p><p name="4d65" id="4d65" class="graf graf--p graf-after--p">For a given dataset, we have to split it for performance measurements.</p><ul class="postList"><li name="9238" id="9238" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Train Set</strong>: used for <strong class="markup--strong markup--li-strong">fitting</strong> the model</li><li name="4838" id="4838" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Validation Set</strong>: used for evaluating forecasting performance of different models and then select the model with the smallest prediction error</li><li name="dcb6" id="dcb6" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Test Set</strong>: Measure the performance of the final model by pretending the testing observed values are unknown</li></ul><p name="1252" id="1252" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Prediction Metrics for Cross-Validation</strong></p><p name="2460" id="2460" class="graf graf--p graf-after--p">We have discussed that AIC and BIC work the best for the whole dataset, but commonly we would like to measure the performance of the cross-validation. Therefore, there have to be some other prediction metrics.</p><ul class="postList"><li name="4c46" id="4c46" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Root Mean Square Error (RMSE)</strong></li></ul><figure name="4e2a" id="4e2a" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*0A0kygQJJ5FjhxSrgthpqg.png" data-width="1344" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*0A0kygQJJ5FjhxSrgthpqg.png"></figure><p name="efbe" id="efbe" class="graf graf--p graf-after--figure">For a training set of <code class="markup--code markup--p-code">X_0</code> to <code class="markup--code markup--p-code">X_m</code> and a validation set from <code class="markup--code markup--p-code">X_{m+1}</code> to <code class="markup--code markup--p-code">X_{n}</code> , we have,</p><figure name="cf1f" id="cf1f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*a_i2LhALGdCipcNP8d0Suw.png" data-width="1344" data-height="142" src="https://cdn-images-1.medium.com/max/800/1*a_i2LhALGdCipcNP8d0Suw.png"></figure><ul class="postList"><li name="3ae6" id="3ae6" class="graf graf--li graf-after--figure">Mean Absolute Error (MAE)</li></ul><figure name="0bcd" id="0bcd" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*CryWZndplR5wPIrL989F2Q.png" data-width="1344" data-height="68" src="https://cdn-images-1.medium.com/max/800/1*CryWZndplR5wPIrL989F2Q.png"></figure><p name="e8b0" id="e8b0" class="graf graf--p graf-after--figure">For a training set of <code class="markup--code markup--p-code">X_0</code> to <code class="markup--code markup--p-code">X_m</code> and a validation set from <code class="markup--code markup--p-code">X_{m+1}</code> to <code class="markup--code markup--p-code">X_{n}</code> , we have,</p><figure name="9d69" id="9d69" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*cB3dLcBs1KTSHt8SLemJeQ.png" data-width="1344" data-height="124" src="https://cdn-images-1.medium.com/max/800/1*cB3dLcBs1KTSHt8SLemJeQ.png"></figure><ul class="postList"><li name="3b13" id="3b13" class="graf graf--li graf-after--figure">Mean Absolute Percentage Error (MAPE)</li></ul><p name="2eae" id="2eae" class="graf graf--p graf-after--li">We should keep in mind that using different metrics might result in a different model.</p><p name="9ea5" id="9ea5" class="graf graf--p graf-after--p">Another problem is that why don’t we choose R² as a metric for time series cross-validation? This is because R² is calculated only by the training set (i.e. SSE shows how well the training results fit the real data) and it gives no information of the validation set. So a higher R² doesn&#39;t show anything about whether the model makes good forecasts.</p><p name="4f77" id="4f77" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Rolling Forward Cross-Validation</strong></p><p name="3420" id="3420" class="graf graf--p graf-after--p">In practice, it is rare to see just one train-validation set and commonly we don’t choose the training set and validation set randomly. Basically, we can conduct a rolling forward cross-validation.</p><ul class="postList"><li name="4579" id="4579" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Rolling one-step forward Cross-Validation</strong></li></ul><p name="c993" id="c993" class="graf graf--p graf-after--li">Let’s suppose we have a dataset {X_t} of seven observations.</p><figure name="0ec8" id="0ec8" class="graf graf--figure graf--startsWithDoubleQuote graf-after--p"><img class="graf-image" data-image-id="1*oboEF230ztu0IXoZJ2gs7A.png" data-width="1720" data-height="366" src="https://cdn-images-1.medium.com/max/800/1*oboEF230ztu0IXoZJ2gs7A.png"><figcaption class="imageCaption">“Leave” means we don’t use it in the current validation. This is a 1-step CV with a rolling window = 1.</figcaption></figure><p name="8ab5" id="8ab5" class="graf graf--p graf-after--figure">Based on this figure above, we can generate three train-validation pairs,</p><pre name="0be3" id="0be3" class="graf graf--pre graf-after--p">Train = [X1, X2, X3, X4]; VALID = [X5]<br>Train = [X1, X2, X3, X4, X5]; VALID = [X6]<br>Train = [X1, X2, X3, X4, X5, X6]; VALID = [X7]</pre><p name="6755" id="6755" class="graf graf--p graf-after--pre">Here, the rolling window is 1.</p><ul class="postList"><li name="cba4" id="cba4" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Rolling two-step forward Cross-Validation</strong></li></ul><figure name="f0de" id="f0de" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*Tqn4y1xbUQDPssJu0oRYHQ.png" data-width="1720" data-height="366" src="https://cdn-images-1.medium.com/max/800/1*Tqn4y1xbUQDPssJu0oRYHQ.png"><figcaption class="imageCaption">This is a 2-step CV with a rolling window = 1.</figcaption></figure><p name="f477" id="f477" class="graf graf--p graf-after--figure">Based on this figure above, we can generate three train-validation pairs as</p><pre name="6a35" id="6a35" class="graf graf--pre graf-after--p">Train = [X1, X2, X3]; VALID = [X4, X5]<br>Train = [X1, X2, X3, X4]; VALID = [X5, X6]<br>Train = [X1, X2, X3, X4, X5]; VALID = [X6, X7]</pre><p name="730f" id="730f" class="graf graf--p graf-after--pre">We should change the rolling window <em class="markup--em markup--p-em">k</em> based on how it performs in short term and long term.</p><p name="264c" id="264c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Cross-Validation Coding Template</strong></p><p name="8553" id="8553" class="graf graf--p graf-after--p">For rolling forward cross-validation with window 2,</p><pre name="f116" id="f116" class="graf graf--pre graf-after--p">Train, Test = Test_Train_Split(X)<br>Train_i = Train</pre><pre name="39df" id="39df" class="graf graf--pre graf-after--pre">Loop from i = 0 to (n-m):<br>    Model = ARIMA(Train_i)<br>    Train_i = Train + i   <br>    y-hat_1 = Model.forecast(2)[0]<br>    y-hat_2 = Model.forecast(2)[1]</pre><pre name="365b" id="365b" class="graf graf--pre graf-after--pre">Test_1 = ...<br>Test_2 = ...</pre><pre name="66ae" id="66ae" class="graf graf--pre graf-after--pre graf--trailing">RMSE_1 = foo(Test_1, y-hat_1)<br>RMSE_2 = foo(Test_2, y-hat_2)</pre></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/ac8358165a5f"><time class="dt-published" datetime="2021-11-26T05:29:28.533Z">November 26, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/time-series-analysis-7-arma-model-selection-ac8358165a5f" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>