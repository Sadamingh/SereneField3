<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Time Series Analysis 2 | Stationary Time Series and Theoretical Autocorrelation Function</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Time Series Analysis 2 | Stationary Time Series and Theoretical Autocorrelation Function</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Time Series Analysis
</section>
<section data-field="body" class="e-content">
<section name="5676" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="2c65" id="2c65" class="graf graf--h3 graf--leading graf--title">Time Series Analysis 2 | <strong class="markup--strong markup--h3-strong">Stationary Time Series and Theoretical Autocorrelation Function</strong></h3><figure name="a3a3" id="a3a3" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*8DcGAITcOShvndvJ.png" data-width="1338" data-height="748" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*8DcGAITcOShvndvJ.png"></figure><ol class="postList"><li name="b165" id="b165" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Stationary Time Series (Weak)</strong></li></ol><p name="64a1" id="64a1" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Problems for the Basic EDA</strong></p><p name="a3b1" id="a3b1" class="graf graf--p graf-after--p">MA soothing and classical decomposition are just averaging the data instead of modeling. Therefore, although they can have pretty inspired graphs, they are not really a good model that provides good forecasting.</p><p name="5789" id="5789" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) The Approach of Modeling Time Series Data by ARIMA</strong></p><p name="f1fa" id="f1fa" class="graf graf--p graf-after--p">The statistical modeling of time series data mostly focuses on modeling the first and second moments, including the most famous family of ARIMA models.</p><ul class="postList"><li name="a72d" id="a72d" class="graf graf--li graf-after--p">De-trending original time series for stationary residuals: focus on eliminating the trend and seasonality in the data</li><li name="f852" id="f852" class="graf graf--li graf-after--li">Modeling stationary residuals: we have to generate a model under the assumption that the remaining residual <code class="markup--code markup--li-code">R_t</code> is stationary, which is a property that we will talk about later. This <code class="markup--code markup--li-code">R_t</code> under the stationary assumption is also called the stationary residuals.</li><li name="e7b7" id="e7b7" class="graf graf--li graf-after--li">Forecasting based on the stationary residuals</li><li name="3fb5" id="3fb5" class="graf graf--li graf-after--li">Add trend and seasonality to estimate the original time series</li></ul><p name="52e5" id="52e5" class="graf graf--p graf-after--li">So in this process, the critical part is when we model the stationary residuals and forecast based on them. Next up, we would like to talk about how to use the ARMA (i.e. Autoregressive Moving Average) model for modeling a stationary time series.</p><p name="7565" id="7565" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) The Definition of Weakly Stationary Time Series</strong></p><p name="6149" id="6149" class="graf graf--p graf-after--p">The time series <code class="markup--code markup--p-code">{X_t}</code> is (weakly) stationary if,</p><ul class="postList"><li name="c72c" id="c72c" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">ùîº(X_t)</code> is independent of time <em class="markup--em markup--li-em">t</em>: this means the mean of the series should not change significantly over the time</li><li name="3c9f" id="3c9f" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">Var(X_t)</code> is independent of time <em class="markup--em markup--li-em">t</em>: this means the variance of the series should not change significantly over the time</li><li name="8100" id="8100" class="graf graf--li graf-after--li">For each <em class="markup--em markup--li-em">h</em>, <code class="markup--code markup--li-code">Cov(X_(t+h), X_t)</code> is independent of time <em class="markup--em markup--li-em">t</em>: this means the covariance within the same window <em class="markup--em markup--li-em">k</em> (aka. seasonal lag) should not change over time</li></ul><p name="943f" id="943f" class="graf graf--p graf-after--li">Although the first two conditions seem reasonable and fair to us, the third one doesn‚Äôt seem familiar. So now, let‚Äôs introduce the next important term in the time series theory called autocorrelation.</p><p name="97e1" id="97e1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Theoretical Autocorrelation Function</strong></p><p name="a22f" id="a22f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of Autocovariance Function (ACVF)</strong></p><p name="e86a" id="e86a" class="graf graf--p graf-after--p">Based on the definition of covariance, the autocovariance function (ACVF) of a stationary time series <code class="markup--code markup--p-code">{X_t}</code> at lag <em class="markup--em markup--p-em">h</em> (i.e. the distance between two observations) is,</p><figure name="fe22" id="fe22" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*JrAINOAZoCexaDm1O5jpLQ.png" data-width="1342" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*JrAINOAZoCexaDm1O5jpLQ.png"></figure><p name="d60b" id="d60b" class="graf graf--p graf-after--figure">This is because that for each <em class="markup--em markup--p-em">h</em>, <code class="markup--code markup--p-code">Cov(X_(t+h), X_t)</code> is independent of time <em class="markup--em markup--p-em">t</em>.</p><p name="2431" id="2431" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) The Definition of Autocorrelation Function (ACF)</strong></p><p name="a713" id="a713" class="graf graf--p graf-after--p">Based on the definition of correlation and covariance, the autocorrelation function (ACF) <code class="markup--code markup--p-code">œÅ_X(h)</code> of a stationary time series <code class="markup--code markup--p-code">{X_t}</code> at lag <em class="markup--em markup--p-em">h</em> is then defined as,</p><figure name="2ab5" id="2ab5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*DlTsX8eu_YFdAa7YtMx-ow.png" data-width="1556" data-height="124" src="https://cdn-images-1.medium.com/max/800/1*DlTsX8eu_YFdAa7YtMx-ow.png"></figure><p name="8631" id="8631" class="graf graf--p graf-after--figure">Again, you should think about proving it with <code class="markup--code markup--p-code">Var(X_t)</code> is independent of time <em class="markup--em markup--p-em">t</em>.</p><p name="b4f5" id="b4f5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Theoretical Vs. Computational</strong></p><p name="50d2" id="50d2" class="graf graf--p graf-after--p">In time series analysis, it‚Äôs often useful to understand the theoretical/population case (e.g. we have some data distribution and we have to develop a model) and the computational/sample case (e.g. we assume to have the theoretical model and see if the data fits). Theoretical cases would help understand how the model is developed and the sample case help understands the algorithm and difference from the theoretical case.</p><p name="1317" id="1317" class="graf graf--p graf-after--p">So if we are given the theoretical distribution or time distribution of time series <code class="markup--code markup--p-code">{X_t}</code> and we have to prove it using the definition of stationary. This is mainly for the purpose of developing the models. If you are given data without knowing the true model, we should do some tests to find out if it is stationary. This is mainly for the purpose of choosing a developed model.</p><p name="ff3f" id="ff3f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Theoretical/Population Example: White Noise</strong></p><p name="364e" id="364e" class="graf graf--p graf-after--p">So for a given model, we can prove if this model can be used to model a stationary time series.</p><p name="cefd" id="cefd" class="graf graf--p graf-after--p">Suppose we have a time series that follows the distribution of white noise, can we confirm that this series is stationary? The answer is yes, and we can prove it through the definition of white noise and stationary.</p><p name="4804" id="4804" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) First-order Autoregression </strong><code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">AR(1)</strong></code><strong class="markup--strong markup--p-strong"> Process</strong></p><p name="0fee" id="0fee" class="graf graf--p graf-after--p">Let‚Äôs see more theoretical/population models,</p><p name="f2eb" id="f2eb" class="graf graf--p graf-after--p">Suppose the AR(1) process follows the pattern below,</p><figure name="e669" id="e669" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*bEff5gdzHILMfNeGbqTOuw.png" data-width="1342" data-height="74" src="https://cdn-images-1.medium.com/max/800/1*bEff5gdzHILMfNeGbqTOuw.png"><figcaption class="imageCaption">(or t = -‚àû,¬†‚Ä¶, -2, -1, 0, 1, 2,¬†‚Ä¶,¬†‚àû)</figcaption></figure><figure name="e99d" id="e99d" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*Tuha-q5V_B-K8yx2FbSgig.png" data-width="1342" data-height="74" src="https://cdn-images-1.medium.com/max/800/1*Tuha-q5V_B-K8yx2FbSgig.png"></figure><p name="683c" id="683c" class="graf graf--p graf-after--figure">So the problem is that is AR(1) stationary?</p><ul class="postList"><li name="5fb3" id="5fb3" class="graf graf--li graf-after--p">Prove expectation: the expectation depends on the coefficient <code class="markup--code markup--li-code">œï</code>.</li></ul><figure name="db63" id="db63" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*aG26ow2d-gBKxRiOoO8jvw.png" data-width="1342" data-height="74" src="https://cdn-images-1.medium.com/max/800/1*aG26ow2d-gBKxRiOoO8jvw.png"></figure><p name="c11c" id="c11c" class="graf graf--p graf-after--figure">So <code class="markup--code markup--p-code">œï</code> should be 1, or <code class="markup--code markup--p-code">ùîº(X_t)</code> should be 0 for the first condition.</p><figure name="2616" id="2616" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*C2mlBAA1Z8AwEOuGSeM6kA.png" data-width="1342" data-height="134" src="https://cdn-images-1.medium.com/max/800/1*C2mlBAA1Z8AwEOuGSeM6kA.png"></figure><ul class="postList"><li name="e2f5" id="e2f5" class="graf graf--li graf-after--figure">Prove variance: We have,</li></ul><figure name="e2bf" id="e2bf" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*L-GGfGbrS_IOqTfRBMMcmA.png" data-width="1342" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*L-GGfGbrS_IOqTfRBMMcmA.png"></figure><p name="03ca" id="03ca" class="graf graf--p graf-after--figure">To continue the proof, we have to add an assumption of <code class="markup--code markup--p-code">X_t</code> is uncorrelated to <code class="markup--code markup--p-code">Z_t</code> for model simplification.</p><figure name="b2a9" id="b2a9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*E6JtUDvVqic-6KzkgV-5tQ.png" data-width="1342" data-height="74" src="https://cdn-images-1.medium.com/max/800/1*E6JtUDvVqic-6KzkgV-5tQ.png"></figure><p name="cf59" id="cf59" class="graf graf--p graf-after--figure">Based on this result, we can know that <code class="markup--code markup--p-code">œï</code> should not be 1 because œÉ¬≤ &gt; 0.</p><figure name="0eb2" id="0eb2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WYu1_k1o3zypdd8NP_ds5g.png" data-width="1342" data-height="112" src="https://cdn-images-1.medium.com/max/800/1*WYu1_k1o3zypdd8NP_ds5g.png"></figure><p name="7ee5" id="7ee5" class="graf graf--p graf-after--figure">Therefore, because <code class="markup--code markup--p-code">œï</code> should not be 1, <code class="markup--code markup--p-code">ùîº(X_t)</code> must be 0 if we want to prove a stationary AR(1) series <code class="markup--code markup--p-code">{X_t}</code>. So,</p><figure name="ce9d" id="ce9d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*nvaWslNoTwW9En_JRelROw.png" data-width="1334" data-height="80" src="https://cdn-images-1.medium.com/max/800/1*nvaWslNoTwW9En_JRelROw.png"></figure><p name="6c39" id="6c39" class="graf graf--p graf-after--figure">And the variance of <code class="markup--code markup--p-code">{X_t}</code> is,</p><figure name="b803" id="b803" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ax8_1Kpv2VTbbZGH--S-Dw.png" data-width="1334" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*ax8_1Kpv2VTbbZGH--S-Dw.png"></figure><p name="8cfd" id="8cfd" class="graf graf--p graf-after--figure">And we can find out that it is independent of the time <em class="markup--em markup--p-em">t</em>.</p><ul class="postList"><li name="e268" id="e268" class="graf graf--li graf-after--p">Prove covariance:</li></ul><figure name="f6a7" id="f6a7" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*n5gYLBZtykJaRNc93mKFPQ.png" data-width="1334" data-height="76" src="https://cdn-images-1.medium.com/max/800/1*n5gYLBZtykJaRNc93mKFPQ.png"></figure><p name="fd5d" id="fd5d" class="graf graf--p graf-after--figure">Based on our previous discussion,</p><figure name="fecf" id="fecf" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ybGfj3tqkauIQ21H_M_Rjw.png" data-width="1334" data-height="78" src="https://cdn-images-1.medium.com/max/800/1*ybGfj3tqkauIQ21H_M_Rjw.png"></figure><p name="c3f3" id="c3f3" class="graf graf--p graf-after--figure">If h ‚â• 1 (positive),</p><figure name="ef4d" id="ef4d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zdzVvES3Ji1Y8kCpkah0XQ.png" data-width="1334" data-height="216" src="https://cdn-images-1.medium.com/max/800/1*zdzVvES3Ji1Y8kCpkah0XQ.png"></figure><p name="de61" id="de61" class="graf graf--p graf-after--figure">Continue this iteration, we can finally have,</p><figure name="360e" id="360e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jBkO2aydbn8x_u8vLUFczg.png" data-width="1334" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*jBkO2aydbn8x_u8vLUFczg.png"></figure><p name="2f8b" id="2f8b" class="graf graf--p graf-after--figure">This is also,</p><figure name="eca5" id="eca5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*xohTd1vdrg3YBI4lsue4Mw.png" data-width="1334" data-height="262" src="https://cdn-images-1.medium.com/max/800/1*xohTd1vdrg3YBI4lsue4Mw.png"></figure><p name="897d" id="897d" class="graf graf--p graf-after--figure">So we have proved that AR(1) can be stationary under the following conditions,</p><ul class="postList"><li name="34c8" id="34c8" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">ùîº(X_t) = 0, |œï| &lt; 1</code> (because the variance should be larger than 0)</li></ul><figure name="75f0" id="75f0" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*XqJraIEE3goUtHdpDrA8Qw.png" data-width="1334" data-height="218" src="https://cdn-images-1.medium.com/max/800/1*XqJraIEE3goUtHdpDrA8Qw.png"></figure><p name="2e61" id="2e61" class="graf graf--p graf-after--figure">Also,</p><figure name="45c1" id="45c1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Cal4ctqdNB7HiABqNxcPTQ.png" data-width="1334" data-height="130" src="https://cdn-images-1.medium.com/max/800/1*Cal4ctqdNB7HiABqNxcPTQ.png"></figure><p name="06f0" id="06f0" class="graf graf--p graf-after--figure">The negative case should be just the same.</p><p name="2ba9" id="2ba9" class="graf graf--p graf-after--p">(5) First-order Moving Average <code class="markup--code markup--p-code">MA(1)</code> Process</p><p name="46f9" id="46f9" class="graf graf--p graf-after--p">So now, let‚Äôs continue to talk about the MA process,</p><figure name="2224" id="2224" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*P5-_KIF1Withewxl8oxe3w.png" data-width="1334" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*P5-_KIF1Withewxl8oxe3w.png"></figure><p name="7a28" id="7a28" class="graf graf--p graf-after--figure">Is MA(1) stationary?</p><ul class="postList"><li name="ce7e" id="ce7e" class="graf graf--li graf-after--p">Prove expectation:</li></ul><figure name="6dbc" id="6dbc" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*crBJ4sixcnKSMT9kLx4x0g.png" data-width="1334" data-height="78" src="https://cdn-images-1.medium.com/max/800/1*crBJ4sixcnKSMT9kLx4x0g.png"></figure><p name="f86e" id="f86e" class="graf graf--p graf-after--figure">So it is independent of <em class="markup--em markup--p-em">t</em>.</p><ul class="postList"><li name="dae1" id="dae1" class="graf graf--li graf-after--p">Prove variance:</li></ul><figure name="e225" id="e225" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*XOWxujMD-GYjWUvSOyN7iw.png" data-width="1334" data-height="214" src="https://cdn-images-1.medium.com/max/800/1*XOWxujMD-GYjWUvSOyN7iw.png"></figure><ul class="postList"><li name="ae69" id="ae69" class="graf graf--li graf-after--figure">Prove covariance:</li></ul><figure name="2bc2" id="2bc2" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*hA6GLyM-iQUIdy3DaY1-VQ.png" data-width="1524" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*hA6GLyM-iQUIdy3DaY1-VQ.png"></figure><p name="2562" id="2562" class="graf graf--p graf-after--figure">So,</p><figure name="29e1" id="29e1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*EARKBNjWn8uhUA151T4kDA.png" data-width="1350" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*EARKBNjWn8uhUA151T4kDA.png"></figure><p name="8a19" id="8a19" class="graf graf--p graf-after--figure">So,</p><figure name="1514" id="1514" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0gVKMnL60zZOKtSL08Nhiw.png" data-width="1350" data-height="102" src="https://cdn-images-1.medium.com/max/800/1*0gVKMnL60zZOKtSL08Nhiw.png"></figure><p name="2571" id="2571" class="graf graf--p graf-after--figure">So as a conclusion, this is also independent of time <em class="markup--em markup--p-em">t</em>. In a summary, MA(1) is always stationary.</p><figure name="7fc3" id="7fc3" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*FTwwCuv7w_Bp_AlOtzSCEg.png" data-width="1350" data-height="214" src="https://cdn-images-1.medium.com/max/800/1*FTwwCuv7w_Bp_AlOtzSCEg.png"></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/491ecf5eaf0"><time class="dt-published" datetime="2021-11-04T16:41:46.865Z">November 4, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/time-series-analysis-2-stationary-time-series-and-theoretical-autocorrelation-function-491ecf5eaf0" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>