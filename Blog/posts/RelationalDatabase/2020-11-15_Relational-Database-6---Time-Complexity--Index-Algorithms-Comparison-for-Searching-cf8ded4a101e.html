<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Relational Database 6 | Time Complexity, Index Algorithms Comparison for Searching</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Relational Database 6 | Time Complexity, Index Algorithms Comparison for Searching</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Relational Database
</section>
<section data-field="body" class="e-content">
<section name="79f6" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="4d66" id="4d66" class="graf graf--h3 graf--leading graf--title">Relational Database 6 | Time Complexity, Index Algorithms <strong class="markup--strong markup--h3-strong">Comparison for Searching</strong></h3><figure name="88c5" id="88c5" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*3IaCF_vbefdstmWFpZxCRw.png" data-width="1600" data-height="1200" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*3IaCF_vbefdstmWFpZxCRw.png"></figure><ol class="postList"><li name="36b4" id="36b4" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">A Quick Intro on the Big-Oh Notation and the Time Complexity</strong></li></ol><p name="20c1" id="20c1" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Basic Assumption</strong></p><p name="760e" id="760e" class="graf graf--p graf-after--p">We can make an assumption (actually this is a fact but we are not going to prove this. If you are curious, you can study the assembly language) that the running time of a program has a linear relationship with the number of the executed lines (or<strong class="markup--strong markup--p-strong"> problem size</strong>). We can easily see this relationship through the following program.</p><figure name="8fb6" id="8fb6" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/Sadamingh/dfd8a75f7c90535e69b32dffd15a9b97.js"></script></figure><figure name="83e7" id="83e7" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*damRffa4TZpkMsvDmuL9XQ.png" data-width="1826" data-height="496" src="https://cdn-images-1.medium.com/max/800/1*damRffa4TZpkMsvDmuL9XQ.png"></figure><p name="3810" id="3810" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) The Definition of Operation Blocks</strong></p><p name="696f" id="696f" class="graf graf--p graf-after--p">Because we have known that the running time of a program is positively related to the number of the executed lines N. Then we can write,</p><figure name="ad44" id="ad44" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*JBsDdQOutcyQ3qaYuNg6uw.png" data-width="954" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*JBsDdQOutcyQ3qaYuNg6uw.png"></figure><p name="4072" id="4072" class="graf graf--p graf-after--figure">Suppose we define that an operation block is a block of several executed lines that will be looped, then we can have the relationship that the final number of the executed lines N is a function <em class="markup--em markup--p-em">f</em> of the number of executed lines in an operation block,</p><figure name="f874" id="f874" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*reSpjdQfSQQ-rRofZNvlGQ.png" data-width="954" data-height="50" src="https://cdn-images-1.medium.com/max/800/1*reSpjdQfSQQ-rRofZNvlGQ.png"></figure><p name="444a" id="444a" class="graf graf--p graf-after--figure">thus,</p><figure name="9c1e" id="9c1e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LyO8GGfpbabLDQAyzduB3A.png" data-width="872" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*LyO8GGfpbabLDQAyzduB3A.png"></figure><p name="91e0" id="91e0" class="graf graf--p graf-after--figure">so that we can know the running time T is a function of the number of executed lines in an operation block, which can be defined as <em class="markup--em markup--p-em">T</em>(n).</p><p name="08e1" id="08e1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Typical Time Complexity Curve</strong></p><p name="a15f" id="a15f" class="graf graf--p graf-after--p">The expression of T(n) can be in various formations, typically, the time complexity curves can be,</p><figure name="e944" id="e944" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LzehvRTT4ajCFFbQ1Dr9Rg.png" data-width="1352" data-height="548" src="https://cdn-images-1.medium.com/max/800/1*LzehvRTT4ajCFFbQ1Dr9Rg.png"></figure><p name="57a5" id="57a5" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) The Definition of Big-Oh Notation</strong></p><p name="07c6" id="07c6" class="graf graf--p graf-after--p">Let <em class="markup--em markup--p-em">f</em>(n) and <em class="markup--em markup--p-em">g</em>(n) be nonnegative-valued functions defined on nonnegative integers n, then the function <em class="markup--em markup--p-em">g</em>(n) is O(<em class="markup--em markup--p-em">f</em>) (read: <em class="markup--em markup--p-em">g</em>(n) is Big-Oh of <em class="markup--em markup--p-em">f</em>(n)) if and only if there exists a positive real constant <em class="markup--em markup--p-em">c</em> and a positive integer <em class="markup--em markup--p-em">n</em>0 such that,</p><figure name="c61d" id="c61d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*c7RuMTzzeqVl0-VJhkx38g.png" data-width="1026" data-height="62" src="https://cdn-images-1.medium.com/max/800/1*c7RuMTzzeqVl0-VJhkx38g.png"></figure><p name="ac9e" id="ac9e" class="graf graf--p graf-after--figure">Actually, the big oh describes the upper bound of the time complexity.</p><figure name="9e7d" id="9e7d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1etMgmze6qRmgWdA3DVHDw.png" data-width="1026" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*1etMgmze6qRmgWdA3DVHDw.png"></figure><p name="afbe" id="afbe" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">Example #1.</strong> Prove that running time T(n) = n³ + 20n + 1 is O(n³).</p><p name="27ec" id="27ec" class="graf graf--p graf-after--p">Proof:</p><figure name="866d" id="866d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LLAPWiw23iNsuEINI8rdFQ.png" data-width="1026" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*LLAPWiw23iNsuEINI8rdFQ.png"></figure><p name="6430" id="6430" class="graf graf--p graf-after--figure">Thus, the running time T(n) = n³ + 20n + 1 is O(n³).</p><p name="5ca7" id="5ca7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example #2.</strong> Prove that running time T(n) = n³ + 20n + 1 is O(n⁴).</p><p name="bd32" id="bd32" class="graf graf--p graf-after--p">Proof:</p><figure name="a894" id="a894" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*gCgsFPqH-IZZNRyjMJmrzQ.png" data-width="1026" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*gCgsFPqH-IZZNRyjMJmrzQ.png"></figure><p name="ef3c" id="ef3c" class="graf graf--p graf-after--figure">Thus, the running time T(n) = n³ + 20n + 1 is O(n⁴).</p><p name="9193" id="9193" class="graf graf--p graf-after--p">Okay, now, then there seems like a conflict. Based on the examples above, we can know that the running time T(n) can be treated as both O(n³) and O(n⁴). So which one is the time complexity we would like to have?</p><p name="f800" id="f800" class="graf graf--p graf-after--p">For time complexity, we define that the lowest Big-Oh complexity or the lowest upper bound of the time complexity will be the notation that we use to describe the time complexity of an algorithm. Based on this definition, we can have the conclusion that O(n³) is our time complexity for the previous algorithm.</p><p name="74c1" id="74c1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) The Dominant Term of Big-Oh Notation</strong></p><p name="6437" id="6437" class="graf graf--p graf-after--p">The dominant term in a time complexity is the term that grows the fastest. Find the dominant term is the quickest way that we can calculate the time complexity of an algorithm. The common relationship of the terms is,</p><p name="58e0" id="58e0" class="graf graf--p graf-after--p">1 &lt; log(n) &lt; n &lt; nlog(n) &lt; n² &lt; n³ &lt; 2ⁿ</p><p name="6f1b" id="6f1b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Example #3.</strong> Find the lowest Big-Oh complexity of the running time,</p><figure name="572b" id="572b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Jmz4LTX49kDwRkmHdEgBPg.png" data-width="1026" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*Jmz4LTX49kDwRkmHdEgBPg.png"></figure><p name="6cf9" id="6cf9" class="graf graf--p graf-after--figure">Answer:</p><figure name="be76" id="be76" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*TdIJMBfLvLDAW-oO9A1Uvg.png" data-width="1026" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*TdIJMBfLvLDAW-oO9A1Uvg.png"></figure><p name="1c62" id="1c62" class="graf graf--p graf-after--figure">then,</p><figure name="d282" id="d282" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*uZtK-S0cXDn4Cbeo3h3Q7w.png" data-width="1026" data-height="128" src="https://cdn-images-1.medium.com/max/800/1*uZtK-S0cXDn4Cbeo3h3Q7w.png"></figure><p name="455d" id="455d" class="graf graf--p graf-after--figure">So n^(1.5) is the dominant term of the running time, and,</p><figure name="e619" id="e619" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FeIWc_CoAHlZzj4wAJC4XQ.png" data-width="1026" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*FeIWc_CoAHlZzj4wAJC4XQ.png"></figure><p name="0775" id="0775" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">2. Time Complexity Example: Self-Balanced Binary Search Tree (AVL tree)</strong></p><p name="570b" id="570b" class="graf graf--p graf-after--p">An AVL tree is a self-balancing binary search tree. We can see a visualization of this data structure from <a href="https://www.cs.usfca.edu/~galles/visualization/AVLtree.html" data-href="https://www.cs.usfca.edu/~galles/visualization/AVLtree.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><p name="c2cc" id="c2cc" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The Definition of the Height of an AVL Tree</strong></p><p name="cbfe" id="cbfe" class="graf graf--p graf-after--p">A single-node tree has height 0, and a complete binary tree on <em class="markup--em markup--p-em">k</em> + 1 levels has height <em class="markup--em markup--p-em">k</em>. Suppose <em class="markup--em markup--p-em">n</em> is the number of the nodes that we have for an AVL tree, then the height <em class="markup--em markup--p-em">h</em> of this tree satisfies,</p><figure name="ce3e" id="ce3e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*soX7LmOildWDkHfZVn9neg.png" data-width="1026" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*soX7LmOildWDkHfZVn9neg.png"></figure><p name="25d4" id="25d4" class="graf graf--p graf-after--figure">Proof:</p><p name="d3dd" id="d3dd" class="graf graf--p graf-after--p">See <a href="https://people.csail.mit.edu/alinush/6.006-spring-2014/avl-height-proof.pdf" data-href="https://people.csail.mit.edu/alinush/6.006-spring-2014/avl-height-proof.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><p name="c9d6" id="c9d6" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) The Time Complexity For Searching the AVL Tree</strong></p><p name="9d16" id="9d16" class="graf graf--p graf-after--p">At the worst case, we have to go to the deepest level of this tree in order to find the result we want. Then we have to do the search for <em class="markup--em markup--p-em">h</em> times and <em class="markup--em markup--p-em">h</em> is the height of this tree. Becasue <em class="markup--em markup--p-em">h</em> satisfies,</p><figure name="ee7b" id="ee7b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*szooV2wX5UrPpZ0Ut5glkA.png" data-width="1026" data-height="66" src="https://cdn-images-1.medium.com/max/800/1*szooV2wX5UrPpZ0Ut5glkA.png"></figure><p name="1d83" id="1d83" class="graf graf--p graf-after--figure">where <em class="markup--em markup--p-em">n</em> is the number of the nodes in this tree. Then the time complexity for searching an AVL tree is O(log n).</p><p name="1fde" id="1fde" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Memory vs. Disk Storage</strong></p><figure name="d322" id="d322" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*c9V1Z7ZnS5Hkcprg-x_i2A.png" data-width="1516" data-height="316" src="https://cdn-images-1.medium.com/max/800/1*c9V1Z7ZnS5Hkcprg-x_i2A.png"></figure><p name="59a7" id="59a7" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">4. Index Performance Comparison</strong></p><p name="8456" id="8456" class="graf graf--p graf-after--p">In order to compare the performance between different algorithms, we have to define the table below,</p><pre name="9ec6" id="9ec6" class="graf graf--pre graf-after--p">B           # the # of pages<br>R           # the # of records per page<br>D           # the avg time to r/w to a disk page<br>C           # the avg time to r/w to a record<br>H           # the time to hash a record<br>F           # the fan-out (avg number of child for non-leaf nodes)</pre><p name="3111" id="3111" class="graf graf--p graf-after--pre">Then, (we don’t have to prove this)</p><figure name="7686" id="7686" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*heXBoctgEy2TRltxkTleiA.png" data-width="1544" data-height="344" src="https://cdn-images-1.medium.com/max/800/1*heXBoctgEy2TRltxkTleiA.png"></figure><p name="7b72" id="7b72" class="graf graf--p graf-after--figure">It is easy to find out that when a table is under construction (with new values keep updating to it), then it will be time saving if we remove all the indexes of this table. However, if the table is stable with no new values to insert, when we are going to conduct more sorted searching (ORDER BY) or range searching (WHERE a &gt; b), then it will be better if we build a index of binary tree. When we are going to conduct more equality search (WHERE a = b), then we are going to build a index of hashing.</p><p name="1f62" id="1f62" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">5. Index for SQL</strong></p><ul class="postList"><li name="aa3f" id="aa3f" class="graf graf--li graf-after--p">Create an index for the table</li></ul><pre name="7469" id="7469" class="graf graf--pre graf-after--li">CREATE INDEX &lt;indexname&gt;<br>ON &lt;tablename&gt;<br>USING &lt;indexmethod&gt; (&lt;colname&gt;);</pre><p name="c064" id="c064" class="graf graf--p graf-after--pre">The index methods are,</p><pre name="cd31" id="cd31" class="graf graf--pre graf-after--p">btree (default)<br>hash<br>gist<br>gin</pre><ul class="postList"><li name="9bfa" id="9bfa" class="graf graf--li graf-after--pre">Delete the index of a table</li></ul><pre name="22b2" id="22b2" class="graf graf--pre graf-after--li">DROP INDEX IF EXISTS &lt;indexname&gt; CASCADE;</pre><ul class="postList"><li name="b0db" id="b0db" class="graf graf--li graf-after--pre">Cluster the index of a table (btree)</li></ul><pre name="0985" id="0985" class="graf graf--pre graf-after--li">CLUSTER &lt;tablename&gt; <br>USING &lt;indexname&gt;;</pre><p name="23bf" id="23bf" class="graf graf--p graf-after--pre graf--trailing">Note that a cluster btree will take more time to construct but it will perform better for searching and sorting.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/cf8ded4a101e"><time class="dt-published" datetime="2020-11-15T12:56:50.686Z">November 15, 2020</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/relational-database-6-time-complexity-index-algorithms-comparison-for-searching-cf8ded4a101e" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>