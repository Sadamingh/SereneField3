<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Operating System 20 | Introduction to Synchronization, Spinlock Implementation, and Spinlock…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Operating System 20 | Introduction to Synchronization, Spinlock Implementation, and Spinlock…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Operating System
</section>
<section data-field="body" class="e-content">
<section name="3c67" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="95e8" id="95e8" class="graf graf--h3 graf--leading graf--title">Operating System 20 | <strong class="markup--strong markup--h3-strong">Introduction to Synchronization, Spinlock Implementation, and Spinlock Alternatives</strong></h3><figure name="c03c" id="c03c" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*HZwUUKcW97-3EP2e.png" data-width="1508" data-height="794" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*HZwUUKcW97-3EP2e.png"></figure><ol class="postList"><li name="067d" id="067d" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Introduction to Synchronization</strong></li></ol><p name="6dab" id="6dab" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Synchronization Metaphor</strong></p><p name="4767" id="4767" class="graf graf--p graf-after--p">Before we introduce the implementation of a synchronization construct, let’s see a metaphor. Suppose you and other students are working on a group project together and you would like to synchronize the process of your work. In fact, you may do the following things to celebrate with others,</p><ul class="postList"><li name="0510" id="0510" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Repeatedly check</strong> if you can continue: Are you done?</li><li name="d553" id="d553" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Send signals</strong> to let others continue: Hey, I am done.</li></ul><p name="f2b9" id="f2b9" class="graf graf--p graf-after--li">Sometimes, you may find it is terrifying to celebrate with your groupmates if they don’t respond to your messages. What you have to do is to keep waiting for others to respond and this <strong class="markup--strong markup--p-strong">hurts your performance</strong>.</p><p name="967e" id="967e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Spinlocks: Repeatedly Check</strong></p><p name="b376" id="b376" class="graf graf--p graf-after--p">The spinlock is something like a mutex, but they have some differences. The spinlock can also be used to protect the critical section as follows,</p><pre name="7147" id="7147" class="graf graf--pre graf-after--p">spinlock_lock(s);<br>   // critical section<br>spinlock_unlock(s);</pre><p name="a622" id="a622" class="graf graf--p graf-after--pre">The way that spinlock differs from mutex is that when the spinlock is busy, the thread that is suspended at the moment is not block like mutexes. Instead, the thread will be <strong class="markup--strong markup--p-strong">spinning</strong> and continue running on the CPU repeated checking to see whether this lock becomes free. With mutexes, the thread will have relinquished the CPU and allowed for another thread to run.</p><p name="bdf1" id="bdf1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Semaphores: Repeatedly Check</strong></p><p name="a419" id="a419" class="graf graf--p graf-after--p">Another synchronization construction in the OS kernel is called the semaphore and this is also similar to a mutex. However, a semaphore can be <strong class="markup--strong markup--p-strong">more generalized</strong> than a mutex. Semaphore is originally designed by <a href="https://en.wikipedia.org/wiki/Edsger_W._Dijkstra" data-href="https://en.wikipedia.org/wiki/Edsger_W._Dijkstra" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">E. W. Dijkstra</a>, who was a Dutch computer scientist and also a Turing award winner.</p><p name="28f4" id="28f4" class="graf graf--p graf-after--p">Semaphores are represented initially via a positive integer number, and this value is treated as the maximum number of threads that can access the critical section simultaneously. If we <code class="markup--code markup--p-code">wait</code> for a semaphore when the value of it is non-zero, the present thread will proceed and the semaphore will decrement by 1. When the semaphore is zero, then the current thread will be spinning.</p><p name="e3f5" id="e3f5" class="graf graf--p graf-after--p">It is quite clear that we can thus have two kinds of semaphores,</p><ul class="postList"><li name="5667" id="5667" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">binary semaphore</strong>: when the semaphore is initialized by 1</li><li name="8b4e" id="8b4e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">general semaphore</strong>: when the semaphore is initialized by a value of more than 1</li></ul><p name="e494" id="e494" class="graf graf--p graf-after--li">After exiting the critical section, we will <code class="markup--code markup--p-code">post</code> to the semaphore, and this operation will increment the semaphore’s counter. For a binary semaphore, this is equivalent to unlocking a mutex.</p><p name="c169" id="c169" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) POSIX Semaphore API</strong></p><p name="d281" id="d281" class="graf graf--p graf-after--p">In the POSIX semaphore API, we can use the following statements. If we want to use this API, we have to first include the <code class="markup--code markup--p-code">semaphore.h</code> header file.</p><pre name="8814" id="8814" class="graf graf--pre graf-after--p">#include &lt;semaphore.h&gt;</pre><p name="b360" id="b360" class="graf graf--p graf-after--pre">The semaphore variable can be defined by <code class="markup--code markup--p-code">sem_t</code> , and it should be initialized after it is defined. We will use the function <code class="markup--code markup--p-code">sem_init</code> to initialize it,</p><pre name="33f6" id="33f6" class="graf graf--pre graf-after--p">sem_t sem;<br>sem_init(&amp;sem, pshared, count);</pre><p name="213b" id="213b" class="graf graf--p graf-after--pre">The <code class="markup--code markup--p-code">pshared</code> flag is used to assign whether this semaphore is shared within a single process or it can be shared for all the processes. When this value is set to 1, it means that all the processes can access this semaphore. The <code class="markup--code markup--p-code">count</code> is clearly the initial value we would like to assign to this semaphore. If we want to have a binary semaphore, this argument should be set by 1.</p><p name="6903" id="6903" class="graf graf--p graf-after--p">Then, based on our discussions above, we can simply know that the critical section can be protected by,</p><pre name="9d72" id="9d72" class="graf graf--pre graf-after--p">sem_wait(&amp;sem);<br>  // critical section<br>sem_post(&amp;sem);</pre><p name="e2bf" id="e2bf" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(5) Semaphore Vs. Mutex</strong></p><p name="ea5e" id="ea5e" class="graf graf--p graf-after--p">Finally, let’s see why the semaphore can be treated as a more generalized mutex. We have known that a mutex works within a single process and it will only allow a single thread to enter its critical section. As a result, we can find out that the mutex is a specific kind of semaphore. We can construct a mutex by,</p><pre name="cb35" id="cb35" class="graf graf--pre graf-after--p">sem_t mutex;<br>sem_init(&amp;mutex, 0, 1);</pre><p name="e5ed" id="e5ed" class="graf graf--p graf-after--pre">Then this semaphore will act like a mutex.</p><p name="42bc" id="42bc" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Reading/Writing to Shared files</strong></p><p name="9c10" id="9c10" class="graf graf--p graf-after--p">Suppose we have several threads that would either read (means accessing without modifying) or write (means accessing with modifying) to a shared file. Then how can we synchronize between these threads?</p><p name="5f13" id="5f13" class="graf graf--p graf-after--p">Let’s suppose we are currently reading from the file, then if there is a reading access from another, we don’t have to block this thread because all these two reads can happen simultaneously. However, when there’s a thread with a writing request, we have to block it until we finish our reading.</p><p name="f253" id="f253" class="graf graf--p graf-after--p">What’s more, when if the thread is initially writing to the file, then it will simply block all the access to the file because both reads and writes will have wrong results without synchronization.</p><p name="83b4" id="83b4" class="graf graf--p graf-after--p">Therefore, we can find out that for different types of accesses, the reading threads can have <strong class="markup--strong markup--p-strong">shared accesses</strong>, while the writing threads can only have <strong class="markup--strong markup--p-strong">exclusive accesses</strong>. Because we have only one shared file in the critical section, have to use only one lock for this synchronization, and this specific lock used to synchronize reads and writes is called the <strong class="markup--strong markup--p-strong">reader/writer locks</strong> (aka. <strong class="markup--strong markup--p-strong">RW lock</strong>, <strong class="markup--strong markup--p-strong">rwlock</strong>).</p><p name="c947" id="c947" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) RW locks for Linux</strong></p><p name="0b24" id="0b24" class="graf graf--p graf-after--p">The Linux OS provides us an in-built data type called <code class="markup--code markup--p-code">rwlock_t</code> for reader/writer locks. When we want to access and quit a reading section, we can use the provided interfaces <code class="markup--code markup--p-code">read_lock</code> and <code class="markup--code markup--p-code">read_unlock</code>. Similarly, when we want to access and quit a writing section, we can use the provided interfaces <code class="markup--code markup--p-code">write_lock</code> and <code class="markup--code markup--p-code">write_unlock</code>. These APIs are provided in the <code class="markup--code markup--p-code">linux/spinlock.h</code> header file.</p><pre name="d26d" id="d26d" class="graf graf--pre graf-after--p">#include &lt;<code class="markup--code markup--pre-code">linux/spinlock.h&gt;</code></pre><pre name="7e73" id="7e73" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">rwlock_t rwlock;</code></pre><pre name="41e7" id="41e7" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">read_lock(&amp;rwlock);<br>  // critical section: for reading<br>read_unlock(&amp;rwlock);</code></pre><pre name="837d" id="837d" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">write_lock(&amp;rwlock);<br>  // critical section: for writing<br>write_unlock(&amp;rwlock);</code></pre><p name="706c" id="706c" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">(8) Monitors</strong></p><p name="d949" id="d949" class="graf graf--p graf-after--p">What we have seen so far is that all these synchronizations require developers to pay attention to the use of the peer-wise operations lock/unlock, wait signal, etc. and these operations are significant causes of errors. Therefore, we would like to deal with the problem.</p><p name="953c" id="953c" class="graf graf--p graf-after--p">The monitor is a higher-level synchronization construct that helps. It will explicitly specify the <strong class="markup--strong markup--p-strong">shared resource</strong>, all the possible <strong class="markup--strong markup--p-strong">entry procedures</strong> (e.g. to differ reads and writes), and it will also specify any <strong class="markup--strong markup--p-strong">condition variables</strong> that potentially be used to wake up different types of waiting threads.</p><p name="feba" id="feba" class="graf graf--p graf-after--p">When performing certain types of access on entry, all of the necessary locking and checking will take place when the thread is entering the monitor. Similarly, when a thread is done with the shared resource and it’s exiting the monitor, all of the necessary unlock operations, checks, any of the signaling that’s necessary for the condition variables, all of that will happen automatically, will be hidden from the programmer.</p><p name="17e1" id="17e1" class="graf graf--p graf-after--p">Historically, monitors were included in the MESA language developed by SEROX PARC. Nowadays, Java also supports monitors. Every single object in Java has an internal lock and methods that are declared to be synchronized are entry points into this monitor. When compiled, the resulting code will include all of the appropriate locking and checking. The only thing is that <code class="markup--code markup--p-code">notify()</code> has to be done explicitly.</p><p name="a46c" id="a46c" class="graf graf--p graf-after--p">Monitors also refer to the <strong class="markup--strong markup--p-strong">programming style</strong> that uses mutexes and condition variables to describe the entry and exit codes from the critical section.</p><p name="bc0a" id="bc0a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(9) More Synchronization Constructs</strong></p><p name="c8dc" id="c8dc" class="graf graf--p graf-after--p">We have introduced some of the synchronization constructs like spinlock, semaphore, mutex, condition variable, RW lock, and monitor. Now, let’s talk about more constructs beyond them,</p><ul class="postList"><li name="6ee4" id="6ee4" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">serializer</strong>: make it easier to define priority, hide explicit use of condition variable</li><li name="53d0" id="53d0" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">path expressions</strong>: programmer specify regex captures the correct synchronization behavior</li><li name="c2df" id="c2df" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">barriers</strong>: a barrier will block threads until it figures all of them reach a certain condition. You can find a detailed explanation from <a href="https://medium.com/adamedelwiess/high-performance-computer-architecture-31-the-introduction-of-synchronization-atomic-exchange-5286132300f9" data-href="https://medium.com/adamedelwiess/high-performance-computer-architecture-31-the-introduction-of-synchronization-atomic-exchange-5286132300f9" class="markup--anchor markup--li-anchor" target="_blank">this article</a>.</li><li name="0c3c" id="0c3c" class="graf graf--li graf-after--li">rendezvous points</li><li name="7a66" id="7a66" class="graf graf--li graf-after--li">optimistic wait-free synchronization (RCU)</li></ul><p name="85ca" id="85ca" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">2. Spinlock Implementation</strong></p><p name="021f" id="021f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) An Incorrect Implementation</strong></p><p name="63a2" id="63a2" class="graf graf--p graf-after--p">Now, let’s see a false implementation of the spinlock.</p><pre name="e9ca" id="e9ca" class="graf graf--pre graf-after--p">spinlock_init(lock):<br>    lock = free;    // 0=free, 1=busy</pre><pre name="b72f" id="b72f" class="graf graf--pre graf-after--pre">spinlock_lock(lock):<br>    spin:<br>        if (lock == free)  lock = busy;<br>        else goto spin;</pre><pre name="a9e4" id="a9e4" class="graf graf--pre graf-after--pre">spinlock_unlock(lock):<br>    lock = free;</pre><p name="9ccf" id="9ccf" class="graf graf--p graf-after--pre">This is false because if we have two threads access the lock simultaneously when the lock is free, all of these two threads will be unlocked. This problem continues to happen even when we use a single while loop like,</p><pre name="b0d2" id="b0d2" class="graf graf--pre graf-after--p">spinlock_init(lock):<br>    lock = free;    // 0=free, 1=busy</pre><pre name="05c3" id="05c3" class="graf graf--pre graf-after--pre">spinlock_lock(lock):<br>    while (lock == busy);<br>    lock = busy;</pre><pre name="a37b" id="a37b" class="graf graf--pre graf-after--pre">spinlock_unlock(lock):<br>    lock = free;</pre><p name="5b70" id="5b70" class="graf graf--p graf-after--pre">To deal with this problem, we need what are so-called hardware supported <strong class="markup--strong markup--p-strong">atomic instructions</strong>.</p><p name="c2bf" id="c2bf" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Atomic Instructions</strong></p><p name="807d" id="807d" class="graf graf--p graf-after--p">As the name of the atomic instructions implies, these instructions can only be accessed atomically supported by the hardware. In general, there are three common types of atomic instructions,</p><ul class="postList"><li name="b949" id="b949" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">test_and_set</code>: if fits the condition, then set the value</li><li name="5d09" id="5d09" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">read_and_increment</code>: get the value, and then increase it</li><li name="f91c" id="f91c" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">compare_and_swap</code>: compare the values, and then swap them</li></ul><p name="cd44" id="cd44" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Spinlock Implementation: by </strong><code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">test_and_set</strong></code></p><p name="db08" id="db08" class="graf graf--p graf-after--p">We can implement the spinlock simply by the <code class="markup--code markup--p-code">test_and_set</code> atomic instruction. The <code class="markup--code markup--p-code">test_and_set</code> function will first atomically check the value of the lock. Then if the lock is free (i.e. lock = 0), the value will be set to 1. Then the threads come after will know that the lock is currently busy and they should spin and wait.</p><p name="d976" id="d976" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. Spinlock Alternatives</strong></p><p name="5355" id="5355" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Recall: Shared-Memory Multiprocessors</strong></p><p name="a2c3" id="a2c3" class="graf graf--p graf-after--p">Before we move on to Anderson’s paper <a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-anderson-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-anderson-paper.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors</em></a>, let’s first refresh the shared-memory multiprocessor systems.</p><p name="9c5e" id="9c5e" class="graf graf--p graf-after--p">In the past, all cores will communicate the coherence information through a single <strong class="markup--strong markup--p-strong">shared bus</strong>, but there will be a bottleneck of the performance because of the bus bandwidth.</p><figure name="c7e7" id="c7e7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*k5TodHaoo0O1CDiO.png" data-width="1650" data-height="282" src="https://cdn-images-1.medium.com/max/800/0*k5TodHaoo0O1CDiO.png"></figure><p name="72a9" id="72a9" class="graf graf--p graf-after--figure">Therefore, for a multicore system, it can be more reasonable if we use some interconnection links between cores for transferring the data. These links between the cores consist of a network called <strong class="markup--strong markup--p-strong">mesh</strong>,</p><figure name="523e" id="523e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*gNZMDZniJ_R2KwSS.png" data-width="1270" data-height="572" src="https://cdn-images-1.medium.com/max/800/0*gNZMDZniJ_R2KwSS.png"></figure><p name="23ad" id="23ad" class="graf graf--p graf-after--figure">Because all these cores actually share 1 or more memories (DRAMs), they are also called the <strong class="markup--strong markup--p-strong">shared-memory CPUs </strong>(aka. <strong class="markup--strong markup--p-strong">shared-memory multiprocessors</strong>, <strong class="markup--strong markup--p-strong">symmetric processors</strong>, or <strong class="markup--strong markup--p-strong">SMPs</strong>). In addition, each of these CPUs in this kind of system can have caches. This is because the caches are faster so that we are able to hide the memory latency.</p><p name="a988" id="a988" class="graf graf--p graf-after--p">However, when the CPU performs a write to the memory, several things can happen,</p><ul class="postList"><li name="cefa" id="cefa" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">No-write to cache</strong>: because all the caches shared the data should be replaced now, the operation of writing to cache may not be allowed to happen. Instead, we may directly write to the memory and then invalidate all the previous copies of this memory location in the caches</li><li name="6521" id="6521" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Write-through</strong>: there is another technique that the result will be writing both in the current cache and the memory. Then the all the previous copies of this memory location will simply be invalidated</li><li name="6ee3" id="6ee3" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Write-back</strong>: We can also first write to the cache and invalidate all the previous copies of this memory location in others caches without writing to the memory. This is because the other caches can retrieve the data from the current cache instead of the memory for the reason that a memory I/O can be slow and inefficient. Only when the dirty block (means the block with the data not written to cache) is kicked out from the cache, we will write the data back to the memory.</li></ul><p name="e648" id="e648" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) Cache Coherence: Software VS. Hardware</strong></p><p name="c699" id="c699" class="graf graf--p graf-after--p">From the previous discussion, when we have an SMP system, the read and write to the memory is not that simple. We have to maintain <strong class="markup--strong markup--p-strong">cache coherence</strong> so that different caches will always have the same data of a specific memory location. There are several ways to maintain the cache coherence,</p><ul class="postList"><li name="2198" id="2198" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Non-Cache-Coherent (NCC)</strong>: NCC means that we actually support no hardware cache coherence and all these coherent operations should be adopted by the software.</li><li name="4a7d" id="4a7d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Cache-Coherent (CC)</strong>: while on some other platforms (called <strong class="markup--strong markup--li-strong">cache-coherent platforms</strong>), the hardware can actually take care of all of the necessary steps to make sure that all the caches are coherent.</li></ul><p name="22ca" id="22ca" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(3) Cache Coherence: Write-Invalidate Vs. Write-Update</strong></p><p name="e831" id="e831" class="graf graf--p graf-after--p">The basic methods that are used for managing the cache coherence are called the <strong class="markup--strong markup--p-strong">write-invalidate</strong> (<strong class="markup--strong markup--p-strong">WI</strong>) and the <strong class="markup--strong markup--p-strong">write-update</strong> (<strong class="markup--strong markup--p-strong">WU</strong>). The method we have talked about when introducing the write-through and write-back is the write-invalidate method. Now, let’s discuss both of them,</p><ul class="postList"><li name="fac8" id="fac8" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Write-Invalidate</strong>: the write-invalidate method means that if we write to the cache, all the blocks in other caches corresponding to the same memory location will be <strong class="markup--strong markup--li-strong">invalidated</strong></li><li name="b2bf" id="b2bf" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Write-Update</strong>: the write-update method means that if we write to the cache, all the blocks in other caches corresponding to the same memory location will be <strong class="markup--strong markup--li-strong">updated. </strong>We don’t use this quite much because this method requires a higher bandwidth after each write, which can be costly for the general performance.</li></ul><p name="8e8b" id="8e8b" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(4) Implementing Atomic Instructions</strong></p><p name="d25c" id="d25c" class="graf graf--p graf-after--p">If we all the atomic instructions to read from the cache, there can be multiple problems we have to maintain. We will have multiple CPUs with multiple threads, we have WU and WI protocol, we have latency on the chip, and etc. Given all these concerns, it is very difficult to know if a particular atomic is applied to the cache on one CPU to know whether or not on another CPU, another atomic is attempted against the cache value in that core.</p><p name="0f24" id="0f24" class="graf graf--p graf-after--p">For that reason, the atomic instructions are designed to bypass the caches and they can directly issue to the memory controller. The benefit is clear, all the threads can be easily synchronized without considering the cache coherence issues when we access the memory.</p><p name="618e" id="618e" class="graf graf--p graf-after--p">However, the downside is that the atomic instruction will therefore take much longer than a normal instruction because we can not benefit from cache reads. In addition, in order to guarantee atomic behavior, we have to generate the coherence traffic after we read/write from the memory. Even if the memory doesn’t change after the atomic instructions, we have to force a cache coherence procedure for some safety purposes.</p><p name="313d" id="313d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Spinlock Performance Metrics</strong></p><p name="7286" id="7286" class="graf graf--p graf-after--p">Finally, before our discussion on the paper, let’s discuss the <strong class="markup--strong markup--p-strong">standard</strong> for a good spinlock.</p><ul class="postList"><li name="87fe" id="87fe" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Latency</strong>: first, we want to have <strong class="markup--strong markup--li-strong">low latency</strong> for our spinlock. Ideally, we want to acquire a free lock immediately, but we have just mentioned that the atomic instructions can be quite slow. And if there are more operations, it takes some time before we acquire the free lock</li><li name="bd54" id="bd54" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Delay</strong>: next, we want our lock to have a <strong class="markup--strong markup--li-strong">low waiting time</strong>, which means that we want to reduce the time when the current thread stops spinning and then acquire the lock that has just been freed</li><li name="2e01" id="2e01" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Contention</strong>: also, we want to <strong class="markup--strong markup--li-strong">reduce the traffic</strong> on the shared bus/network. Both the actually atomic memory references and the coherence traffic should be considered.</li></ul><p name="d4ab" id="d4ab" class="graf graf--p graf-after--li">However, there is a conflict between our goals. If we want to have lower latency and a lower delay, we have to send more messages to the shared bus/network so that we don’t have to read from the memory. So these attempts will result in a higher contention with more traffics.</p><p name="caa1" id="caa1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Performance of Test-and-Set Spinlock</strong></p><p name="e0fd" id="e0fd" class="graf graf--p graf-after--p">Now, let’s look back to discuss the performance of a test-and-set spinlock. As we have discussed briefly, the test-and-set spinlock can be implemented as follows,</p><pre name="6096" id="6096" class="graf graf--pre graf-after--p">spinlock_init(lock):<br>    lock = free;    // 0=free, 1=busy</pre><pre name="ebfe" id="ebfe" class="graf graf--pre graf-after--pre">spinlock_lock(lock):<br>    while(test_and_set(lock) == busy);</pre><pre name="bc88" id="bc88" class="graf graf--pre graf-after--pre">spinlock_unlock(lock):<br>    lock = free;</pre><p name="bf87" id="bf87" class="graf graf--p graf-after--pre">The <strong class="markup--strong markup--p-strong">latency and the delay </strong>of this implementation<strong class="markup--strong markup--p-strong"> are very low</strong> because the lock and unlock are simplest. We only have atomic instructions in for the locking process and the delay is also maintained by the minimum requirements with spinning continuously on the automatic instructions.</p><p name="7ff8" id="7ff8" class="graf graf--p graf-after--p">However, as long as the thread is spinning, every processor will repeatedly go on to shared bus/interconnected links to the memory location. This will <strong class="markup--strong markup--p-strong">create contention</strong> on the shared bus/interconnected links which will scare out other CPUs or it will even delay the thread with the critical section.</p><p name="f675" id="f675" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) Alternative Implementation #1: Test-Test-Set Spinlock</strong></p><p name="79a2" id="79a2" class="graf graf--p graf-after--p">In the previous case, we have found out that the contention is caused because we have to execute the atomic test-then-set instruction in every spinning. One way to deal with this problem is that we can add another test before the atomic instruction and only for those we have to write to the memory, we will conduct the test-then-set instruction.</p><pre name="92ea" id="92ea" class="graf graf--pre graf-after--p">spinlock_lock(lock):<br>    while (1) {<br>        if (lock == free)<br>            while(test_and_set(lock) == busy);<br>        else<br>            while(lock == busy);      // wait for lock becomes free<br>    }</pre><p name="d548" id="d548" class="graf graf--p graf-after--pre">Now, let’s consider the performance of this lock. For the <strong class="markup--strong markup--p-strong">latency and delay</strong>, this lock is <strong class="markup--strong markup--p-strong">okay </strong>but it is worse than the previous case because we do one extra check before we enter the atomic instruction.</p><p name="7296" id="7296" class="graf graf--p graf-after--p">But if we consider the <strong class="markup--strong markup--p-strong">intention</strong> problem, this lock is much better because we are now allowed to spin on the cache without accessing the memory. However, this conclusion is only made when we have a write-update coherent protocol. When we have a write-invalidate protocol, we should also read from the memory and what’s worse, we will generate invalidation traffic. As a result, the WI situation will become <strong class="markup--strong markup--p-strong">horrible</strong>.</p><p name="f72e" id="f72e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(8) Alternative Implementation #2: Delay Spinlock</strong></p><p name="b757" id="b757" class="graf graf--p graf-after--p">A simple idea to<strong class="markup--strong markup--p-strong"> improve the intention</strong> is that we can add a delay time after the thread figures out that the lock is free. By this delay time, we will have more threads entering the <code class="markup--code markup--p-code">while(lock == busy)</code> loop instead of entering the while loop of <code class="markup--code markup--p-code">while(test_and_set(lock) == busy)</code> with atomic instructions which will result in higher contention.</p><p name="5cc5" id="5cc5" class="graf graf--p graf-after--p">Another question is that how can we pick the time for this delay? Actually, we have two methods. We can use either a <strong class="markup--strong markup--p-strong">statistic delay</strong> or a <strong class="markup--strong markup--p-strong">dynamic delay</strong>.</p><ul class="postList"><li name="1df5" id="1df5" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">static delay</strong>: means that we can assign the delay time with some static value (e.g. CPU ID). This is simple but it will cause some unnecessary delay under low contention</li><li name="305b" id="305b" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">dynamic delay</strong>: means that each process will pick a random delay value on the current perception of contention in the system. If we have low contention, then the delay time is chosen from a smaller range. However, if we have higher contention, then the delay time is chosen from a larger range. The number we can the contention problem in the system is that we can check the filed <code class="markup--code markup--li-code">test_and_set</code> operations. If the <code class="markup--code markup--li-code">test_and_set</code> operation fails, there’s a higher possibility of a higher contention.</li></ul><pre name="f247" id="f247" class="graf graf--pre graf-after--li">spinlock_lock(lock):<br>    while (1) {<br>        if (lock == free)<br>            while(test_and_set(lock) == busy);<br>        else {<br>            while(lock == busy);      // wait for lock becomes free<br><strong class="markup--strong markup--pre-strong">            delay();</strong><br>        }  <br>    }</pre><p name="6837" id="6837" class="graf graf--p graf-after--pre">The <strong class="markup--strong markup--p-strong">latency is okay</strong> because we have to perform one extra check before we acquire the lock, but that can be tolerated. However, the <strong class="markup--strong markup--p-strong">delay becomes much worse</strong> because now threads have to wait for a longer time because we add a new delay time. If there’s no contention at a time, the delay will be just a wait of the time.</p><p name="6029" id="6029" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(9) Alternative Implementation #3: Queuing Spinlock</strong></p><p name="b6f5" id="b6f5" class="graf graf--p graf-after--p">The alternative lock described in Anderson’s paper is called a <strong class="markup--strong markup--p-strong">queuing lock </strong>or <strong class="markup--strong markup--p-strong">Anderson’s lock</strong>. The idea of this lock is that a queue of flags is used to control who gets to execute and what needs to happen when a critical section is complete. This method makes each thread acquire the lock at a different time once the lock is freed.</p><p name="927f" id="927f" class="graf graf--p graf-after--p">The array has N elements, where N is the number of processors in the system times the size of the cache lines, and every single one of the elements will have one of the two values (<code class="markup--code markup--p-code">has_lock</code> or <code class="markup--code markup--p-code">must_wait</code>). In addition, we will have two pointers, which will indicate the current lock holder (with <code class="markup--code markup--p-code">has_lock</code>) and the index of the last element in the queue <code class="markup--code markup--p-code">queuelast</code>. So the initialization of this queue would be,</p><pre name="3236" id="3236" class="graf graf--pre graf-after--p">init:<br>    flags[0] = <code class="markup--code markup--pre-code">has_lock</code>;<br>    flags[1 ... N-1] = <code class="markup--code markup--pre-code">must_wait</code>;<br>    <code class="markup--code markup--pre-code">queuelast = 0;                    // global</code></pre><p name="ea87" id="ea87" class="graf graf--p graf-after--pre">When a new thread arrives at the lock, it will get a <code class="markup--code markup--p-code">ticket</code> from the lock, and then a new element will be added to the end of the queue. Since multiple threads may be arriving at the lock at the same time, we will clearly make sure that this queue should be maintained atomically. Therefore, this queue depends on some sort of <code class="markup--code markup--p-code">read_and_increment</code> reads, and these are less common atomic instructions that are not generally supported. So the lock function should be,</p><pre name="56e7" id="56e7" class="graf graf--pre graf-after--p">lock:<br>    myplace = <code class="markup--code markup--pre-code">read_and_increment(queuelast);<br>    // spin<br>    while (flags[</code>myplace%N<code class="markup--code markup--pre-code">] == must_wait);</code></pre><pre name="5fe3" id="5fe3" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">        // now in critical section</code></pre><pre name="6b86" id="6b86" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">    // finally reset the entry in the queue for next thread<br>    flags[</code>myplace%N<code class="markup--code markup--pre-code">] = must_wait;</code></pre><p name="9eed" id="9eed" class="graf graf--p graf-after--pre">Releasing the lock means that we have to change the value of the next element to <code class="markup--code markup--p-code">has_lock</code> in the array,</p><pre name="76a5" id="76a5" class="graf graf--pre graf-after--p">unlock:<br>    flags<code class="markup--code markup--pre-code">[</code>myplace%N + 1<code class="markup--code markup--pre-code">] = has_lock;</code></pre><p name="12aa" id="12aa" class="graf graf--p graf-after--pre">For the <strong class="markup--strong markup--p-strong">latency</strong> concerns, this method is much <strong class="markup--strong markup--p-strong">worse</strong> because we have to execute some more inefficient <code class="markup--code markup--p-code">read_and_increment</code> instructions. However, the <strong class="markup--strong markup--p-strong">delay is quite good</strong> because we can directly signal the next CPU/thread to run without waiting. From a <strong class="markup--strong markup--p-strong">contention</strong> perspective, this lock is much <strong class="markup--strong markup--p-strong">better</strong> than any other alternatives we have discussed because the atomic instruction <code class="markup--code markup--p-code">read_and_increment</code> is only executed once upfront and it is not part of the spinning code.</p><p name="1dda" id="1dda" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(10) Experimental Results</strong></p><p name="5257" id="5257" class="graf graf--p graf-after--p">Finally, let’s see one of the results from the performance of the locks that are shown in Anderson’s paper.</p><figure name="4cee" id="4cee" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*rLNz8TOUnI-vZPbAsteQFw.png" data-width="1454" data-height="540" src="https://cdn-images-1.medium.com/max/800/1*rLNz8TOUnI-vZPbAsteQFw.png"></figure><p name="c03a" id="c03a" class="graf graf--p graf-after--figure">This figure is gathered from executing a program with multiple processes and each program contains a critical section that will be executed in a loop of 1 million times. The platform was cache-coherent with write-invalidate. The metrics computed was the overhead compared to an ideal performance with all the measurements bond to a theoretical limit.</p><p name="c201" id="c201" class="graf graf--p graf-after--p">So now let’s see the result when we have <strong class="markup--strong markup--p-strong">high loads</strong> with more threads/cores,</p><ul class="postList"><li name="6407" id="6407" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">queuing lock</strong> is the best one with the most scalable curve</li><li name="821c" id="821c" class="graf graf--li graf-after--li">the <strong class="markup--strong markup--li-strong">test-test-set lock</strong> (i.e. spin on read) will perform worse because we have a very high contention of O(N²)</li><li name="4aaf" id="4aaf" class="graf graf--li graf-after--li">the <strong class="markup--strong markup--li-strong">static delay locks</strong> (i.e. static release/ref.) are slightly better than <strong class="markup--strong markup--li-strong">dynamic delay locks </strong>(i.e. backoff release/ref.) since under high loads with static, we end up nicely balancing out the atomic constructions</li></ul><p name="e70d" id="e70d" class="graf graf--p graf-after--li">However, for the lighter loads, we have,</p><ul class="postList"><li name="ea08" id="ea08" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">test-test-set lock </strong>performs pretty in this case because a spinlock will have low latency</li><li name="4f7a" id="4f7a" class="graf graf--li graf-after--li">the <strong class="markup--strong markup--li-strong">dynamic delay locks </strong>perform better than the <strong class="markup--strong markup--li-strong">static delay locks </strong>because it has a lower delay</li><li name="37e5" id="37e5" class="graf graf--li graf-after--li graf--trailing"><strong class="markup--strong markup--li-strong">queuing lock</strong> is the worst one because we have a pretty high latency because of the <code class="markup--code markup--li-code">read_and_increment</code> instructions</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/c926af1412e6"><time class="dt-published" datetime="2021-04-12T20:47:25.163Z">April 12, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/operating-system-20-introduction-to-synchronization-spinlock-implementation-and-spinlock-c926af1412e6" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>