<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Operating System 12 | Interactions between Kernel-Level Threads and User-Level Threads with SunOS…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Operating System 12 | Interactions between Kernel-Level Threads and User-Level Threads with SunOS…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Operating System
</section>
<section data-field="body" class="e-content">
<section name="12c0" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6091" id="6091" class="graf graf--h3 graf--leading graf--title">Operating System 12 | Interactions between Kernel-Level Threads and User-Level Threads with SunOS and Linux Examples</h3><figure name="4e47" id="4e47" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*yVM32tTU-RJMBn-y.png" data-width="1508" data-height="794" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*yVM32tTU-RJMBn-y.png"></figure><ol class="postList"><li name="0d7b" id="0d7b" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Recall: Kernel vs User Level Threads</strong></li></ol><p name="49ac" id="49ac" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Kernel-Level Threads</strong></p><p name="fa5a" id="fa5a" class="graf graf--p graf-after--p">Supporting threads at the kernel level means that the <strong class="markup--strong markup--p-strong">OS kernel itself is multithreaded</strong>. To do this, the OS kernel maintains some abstraction, for our threads data structure to represent threads, and it performs all of the operations like synchronization, scheduling, etc.</p><p name="b885" id="b885" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) User-Level Threads</strong></p><p name="32b3" id="32b3" class="graf graf--p graf-after--p">Supporting threads at the user level means that there is a <strong class="markup--strong markup--p-strong">user-level library</strong> that is linked with the application, and this library provides all of the management and runtime support for threads. Different processes may use entirely different user-level libraries that have different ways to represent threads that support the different scheduling mechanisms.</p><p name="42d7" id="42d7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Mapping Mechanisms</strong></p><p name="a475" id="a475" class="graf graf--p graf-after--p">We also discussed several mechanisms on how user-level threads can be mapped onto the underlying kernel level-threads, and we said these include one-to-one, many-to-one, and many-to-many mapping.</p><p name="622f" id="622f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) One-to-one Mapping</strong></p><p name="dac3" id="dac3" class="graf graf--p graf-after--p">All of the information for this process is contained in the <strong class="markup--strong markup--p-strong">PCB</strong>, including virtual address mapping, stack, registers, etc. Whenever the process makes a system call, it traps it into the kernel.</p><p name="6848" id="6848" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Many-to-one Mapping</strong></p><p name="1dd6" id="1dd6" class="graf graf--p graf-after--p">Let’s then make the thread multithreaded, and then there will be a <strong class="markup--strong markup--p-strong">user-level thread library (ULTlib)</strong> used to manage these threads. Because the thread library is used to manage these threads, it tracks some of the <strong class="markup--strong markup--p-strong">user-level thread (ULT)</strong> data structures.</p><p name="c620" id="c620" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">PCB</strong> contains the virtual address mappings as well as the stack and register information for the kernel-level thread.</p><p name="261a" id="261a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Many-to-many Mapping</strong></p><p name="16bd" id="16bd" class="graf graf--p graf-after--p">Although we have multi-threads at the kernel level, we don’t want to recreate all of the information in PCB for the multiple kernel-level threads. So we are going to split some information in the original PCB to <strong class="markup--strong markup--p-strong">kernel-level thread control blocks (KLTCB) </strong>including the stack and the register pointer for <strong class="markup--strong markup--p-strong">kernel-level threads (KLT)</strong>. The virtual address mapping will be left in the PCB so all the KLTs can share the information easily.</p><p name="a1be" id="a1be" class="graf graf--p graf-after--p">Compared with the user-level threads, each kernel-level thread looks like a virtual CPU.</p><p name="c1ff" id="c1ff" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Thread Data Structure</strong></p><p name="3805" id="3805" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) At Scale Thread Data Structure</strong></p><p name="118a" id="118a" class="graf graf--p graf-after--p">For the data structure of a multithreading process and multiple CPUs,</p><ul class="postList"><li name="f1b2" id="f1b2" class="graf graf--li graf-after--p">each ULT maintains a <strong class="markup--strong markup--li-strong">pointer</strong> to the corresponding PCB and vice versa</li><li name="a58e" id="a58e" class="graf graf--li graf-after--li">each KLT keeps a <strong class="markup--strong markup--li-strong">pointer</strong> to the corresponding PCB and vice versa</li><li name="2370" id="2370" class="graf graf--li graf-after--li">each KLT maintains a <strong class="markup--strong markup--li-strong">pointer</strong> to which CPU it is running via a shared CPU data structure</li></ul><p name="e6a4" id="e6a4" class="graf graf--p graf-after--li">So when the kernel needs to context switch amongst KLTs that belong to different processes, it can quickly determine whether they point to different PCBs. Therefore it can easily decide it needs to completely invalidate the existing address mapping (different PCBs) or it can directly use the current ones (same PCB).</p><p name="7bed" id="7bed" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Process State</strong></p><p name="71d3" id="71d3" class="graf graf--p graf-after--p">If two KLTs point to the same address space (meaning that they belong to the same kernel-level process and have the same virtual address mapping), there is certain information in PCB for either the current KLT or all the KLTs of this KLP. The information is called the <strong class="markup--strong markup--p-strong">process state</strong>.</p><p name="e77f" id="e77f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Hard Process State</strong></p><p name="ba0a" id="ba0a" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">hard process state</strong> refers to the information that applies to all threads within a process (i.e. virtual address mappings). When we do the context switch between different KLTs, we want to <strong class="markup--strong markup--p-strong">maintain</strong> the hard process state.</p><p name="2624" id="2624" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Light Process State</strong></p><p name="0959" id="0959" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">light process state</strong> refers to the information specific to a certain KLT within a process (i.e. signal mask/ syscall args). When we do the context switch between different KLTs, we want to <strong class="markup--strong markup--p-strong">replace</strong> the light process state.</p><p name="63e5" id="63e5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(5) Process State Separation</strong></p><p name="3324" id="3324" class="graf graf--p graf-after--p">Because we want to <strong class="markup--strong markup--p-strong">abort </strong>the current light process state and <strong class="markup--strong markup--p-strong">maintain</strong> the current hard process state in the procedure of context switch, we have to split the process state to the hard process state and the light process state.</p><p name="d042" id="d042" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Reasons for Choosing Multiple Data Structures</strong></p><ul class="postList"><li name="4f43" id="4f43" class="graf graf--li graf-after--p">Scalability</li></ul><p name="f800" id="f800" class="graf graf--p graf-after--li">A single PCB must have a large continuous data structure, while the multiple data structures maintain the same information with smaller data structures and this increases the scalability.</p><ul class="postList"><li name="cc49" id="cc49" class="graf graf--li graf-after--p">Overheads</li></ul><p name="a710" id="a710" class="graf graf--p graf-after--li">A single PCB should have private copies for each entity, while the multiple data structures are easier to share.</p><ul class="postList"><li name="a310" id="a310" class="graf graf--li graf-after--p">Performance</li></ul><p name="faa7" id="faa7" class="graf graf--p graf-after--li">A single PCB should save/restore all the information (i.e. process state) on each context switch, while the multiple data structures only save/restore the information that needs to change (i.e. light process state).</p><ul class="postList"><li name="cb4a" id="cb4a" class="graf graf--li graf-after--p">Flexibility</li></ul><p name="d3d0" id="d3d0" class="graf graf--p graf-after--li">A single PCB should update the ULTlib for any change, while the multiple data structures will update a much smaller portion of the state.</p><p name="7168" id="7168" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) KLT Data Structure Example</strong></p><p name="da2a" id="da2a" class="graf graf--p graf-after--p">Now, let’s take a look at an actual Linux kernel implementation. We are going to use the the <a href="https://elixir.bootlin.com/linux/v3.17/source/" data-href="https://elixir.bootlin.com/linux/v3.17/source/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">version 3.17</a> of the Linux kernel and from the file <a href="https://elixir.bootlin.com/linux/v3.17/source/include/linux/kthread.h#L66" data-href="https://elixir.bootlin.com/linux/v3.17/source/include/linux/kthread.h#L66" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">kthread.h</a>, we can find a C structure named <code class="markup--code markup--p-code">kthread_worder</code> providing a simple interface for creating and stopping kernel threads. The <code class="markup--code markup--p-code">task_struct</code> element inside this structure is a holding place for tons of important information regarding its process.</p><p name="aa85" id="aa85" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. User Level Structures in Solaris 2.0 (SunOS 5.0)</strong></p><p name="43d0" id="43d0" class="graf graf--p graf-after--p">SunOS was brought by ORACLE in 2010 and it is no longer maintained now. But it is very well known for the quality and the stability of its UNIX distributions. The most of this part is based on the paper <a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-eykholt-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-eykholt-paper.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Beyond Multiprocessing … Multithreading the SunOS Kernel</em></a><em class="markup--em markup--p-em"> </em>and the paper<em class="markup--em markup--p-em"> </em><a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-stein-shah-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-stein-shah-paper.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Implementing Lightweight Threads</em></a>. If you have trouble reading a paper, you can refer to <a href="http://people.mpi-sws.org/~jcmace/teaching/cds-ss20/paper-reading.pdf" data-href="http://people.mpi-sws.org/~jcmace/teaching/cds-ss20/paper-reading.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">this paper</a> about <em class="markup--em markup--p-em">how to read a paper</em> in the first place.</p><p name="cab0" id="cab0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) The General Overview</strong></p><p name="7ecd" id="7ecd" class="graf graf--p graf-after--p">From the Stein and Shah’s paper, we can find the following figure,</p><figure name="308e" id="308e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*npDUyw8XCueGV5KFfTKorg.png" data-width="1174" data-height="510" src="https://cdn-images-1.medium.com/max/800/1*npDUyw8XCueGV5KFfTKorg.png"><figcaption class="imageCaption"><a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-stein-shah-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-stein-shah-paper.pdf" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank"><em class="markup--em markup--figure-em">Implementing Lightweight Threads</em></a><em class="markup--em markup--figure-em"> Figure 1</em></figcaption></figure><p name="e135" id="e135" class="graf graf--p graf-after--figure">You can also find a similar figure in another paper.</p><figure name="f931" id="f931" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jovWs1WXb6iWtJe6zMfgdw.png" data-width="1432" data-height="564" src="https://cdn-images-1.medium.com/max/800/1*jovWs1WXb6iWtJe6zMfgdw.png"><figcaption class="imageCaption"><a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-eykholt-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-eykholt-paper.pdf" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Beyond Multiprocessing … Multithreading the SunOS Kernel</a><em class="markup--em markup--figure-em"> Figure 1</em></figcaption></figure><p name="d118" id="d118" class="graf graf--p graf-after--figure">Let’s now analyze this figure.</p><p name="34b7" id="34b7" class="graf graf--p graf-after--p">Going from the bottom up,</p><ul class="postList"><li name="bd5e" id="bd5e" class="graf graf--li graf-after--p">the OS intended for multiprocessors with <strong class="markup--strong markup--li-strong">multiple CPUs</strong></li><li name="f17b" id="f17b" class="graf graf--li graf-after--li">the kernel itself is multiple threaded with <strong class="markup--strong markup--li-strong">multiple KLTs</strong></li><li name="919d" id="919d" class="graf graf--li graf-after--li">the processes can be <strong class="markup--strong markup--li-strong">single</strong> or <strong class="markup--strong markup--li-strong">multithreaded in the UL (user level)</strong></li><li name="6137" id="6137" class="graf graf--li graf-after--li">both <strong class="markup--strong markup--li-strong">one-to-one</strong> and <strong class="markup--strong markup--li-strong">many-to-many</strong> mappings are supported</li><li name="9b5b" id="9b5b" class="graf graf--li graf-after--li">each KLT that is executing a ULT has a <strong class="markup--strong markup--li-strong">lightweight process (LWP)</strong> data structure associated with it</li><li name="d7e7" id="d7e7" class="graf graf--li graf-after--li">to the ULTlib, the LWP represent the <strong class="markup--strong markup--li-strong">virtual CPU</strong> on which it will be scheduling its threads on</li><li name="4a84" id="4a84" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">kernel-level scheduler (KLS)</strong> will be used to manage and schedule the KLTs onto the physical CPUs (not shown in the figures)</li></ul><p name="7a57" id="7a57" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(2) ULT Data Structures</strong></p><p name="ac3d" id="ac3d" class="graf graf--p graf-after--p">Let’s now see the data structures of a ULT at the UL. This is introduced in Stein and Shah’s paper section <strong class="markup--strong markup--p-strong">Thread Library Implementation</strong> in page 3 to page 4.</p><p name="11f1" id="11f1" class="graf graf--p graf-after--p">Recall that for the POSIX thread, when a thread is created, a thread ID is returned and this ID can be used as a pointer to the thread structure. However, the SunOS uses a slightly different way to implement this. The thread ID is not treated as a pointer but as an index. We can use this index for a <strong class="markup--strong markup--p-strong">table of pointers</strong> and find the corresponding pointer pointing to the thread structure (page 4).</p><figure name="901f" id="901f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*5sqUdNLpR6SmDWcj_VajOw.png" data-width="1434" data-height="486" src="https://cdn-images-1.medium.com/max/800/1*5sqUdNLpR6SmDWcj_VajOw.png"></figure><p name="4cf1" id="4cf1" class="graf graf--p graf-after--figure">For the data structure of each ULT, it is represented by (page 3),</p><ul class="postList"><li name="1a03" id="1a03" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">thread ID</strong></li><li name="92d4" id="92d4" class="graf graf--li graf-after--li">an area to save the thread <strong class="markup--strong markup--li-strong">execution context</strong></li><li name="1945" id="1945" class="graf graf--li graf-after--li">the thread <strong class="markup--strong markup--li-strong">signal mask</strong></li><li name="5f1e" id="5f1e" class="graf graf--li graf-after--li">the <strong class="markup--strong markup--li-strong">thread priority</strong></li><li name="1547" id="1547" class="graf graf--li graf-after--li">a pointer to the thread stack (<strong class="markup--strong markup--li-strong">stack pointer</strong>)</li></ul><figure name="aeee" id="aeee" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*4pKB96120k-ZHhx8Z2lPfw.png" data-width="1434" data-height="484" src="https://cdn-images-1.medium.com/max/800/1*4pKB96120k-ZHhx8Z2lPfw.png"></figure><p name="db31" id="db31" class="graf graf--p graf-after--figure">We have two ways to specify the storage for the stack. One way is to automatically allocate the storage by the library. The other way is to pass an area in by the user or the application. The library allocated stacks are obtained by mapping in pages of anonymous memory (Page 3).</p><figure name="e4ac" id="e4ac" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tuYopcKmbYPdpFz8UlO0Dw.png" data-width="1626" data-height="800" src="https://cdn-images-1.medium.com/max/800/1*tuYopcKmbYPdpFz8UlO0Dw.png"></figure><p name="849d" id="849d" class="graf graf--p graf-after--figure">However, there is a problem. The ULT only knows the stack pointer but it doesn’t know where it ends, so there will be a <strong class="markup--strong markup--p-strong">stack overflow problem</strong>.</p><figure name="a67b" id="a67b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*VvNLiTEUevsAF3wr4tdD7g.png" data-width="1626" data-height="800" src="https://cdn-images-1.medium.com/max/800/1*VvNLiTEUevsAF3wr4tdD7g.png"></figure><p name="ecdf" id="ecdf" class="graf graf--p graf-after--figure">When the stack is overflowed, even though thread 2 will raise an overwrite error, it is hard for debugging because we can hardly figure out that this overflow problem is caused by thread 1.</p><p name="e676" id="e676" class="graf graf--p graf-after--p">In Stein and Shah’s paper, the design of “<strong class="markup--strong markup--p-strong">Red Zone</strong>” is used to deal with this problem. We add red zones to split different ULTs, and when the stack storage writes to the red zone, an error will be raised and we can easily figure out the thread 1 runs out stack (page 3).</p><figure name="d57b" id="d57b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*MgDdwzreNP4YzS3k_SZOnQ.png" data-width="1626" data-height="800" src="https://cdn-images-1.medium.com/max/800/1*MgDdwzreNP4YzS3k_SZOnQ.png"></figure><p name="4310" id="4310" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(3) KL Data Structures</strong></p><p name="ee1c" id="ee1c" class="graf graf--p graf-after--p">From the Eykholt’s paper at page 2, we can find the following figure about the KL data structures,</p><figure name="4828" id="4828" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*AZWuOtHGmAfKkyH2RqcJ7g.png" data-width="1376" data-height="650" src="https://cdn-images-1.medium.com/max/800/1*AZWuOtHGmAfKkyH2RqcJ7g.png"><figcaption class="imageCaption"><a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-eykholt-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-eykholt-paper.pdf" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank"><em class="markup--em markup--figure-em">Beyond Multiprocessing … Multithreading the SunOS Kernel</em></a><em class="markup--em markup--figure-em"> Figure 2</em></figcaption></figure><p name="94d7" id="94d7" class="graf graf--p graf-after--figure">The <code class="markup--code markup--p-code">proc</code> is a process data structure that contains information about the user in <code class="markup--code markup--p-code">User</code>, points to the VM address space, and then points to <strong class="markup--strong markup--p-strong">a list of KLT data structures</strong>.</p><figure name="c023" id="c023" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*mqwtnxghOkzMWPqo4JlLhg.png" data-width="1376" data-height="650" src="https://cdn-images-1.medium.com/max/800/1*mqwtnxghOkzMWPqo4JlLhg.png"></figure><p name="42c7" id="42c7" class="graf graf--p graf-after--figure">For each KLT data structure in the list, it points to the <strong class="markup--strong markup--p-strong">LWP</strong> that it corresponds to, its <strong class="markup--strong markup--p-strong">stack</strong>, etc. The LWP and stack portion are actually swappable. What is not shown in this figure is any info about the CPU. Some other pointers are also not shown.</p><figure name="060b" id="060b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*hTy676HfBLpTkMrdPyJGhg.png" data-width="1376" data-height="650" src="https://cdn-images-1.medium.com/max/800/1*hTy676HfBLpTkMrdPyJGhg.png"></figure><p name="9b33" id="9b33" class="graf graf--p graf-after--figure">The <strong class="markup--strong markup--p-strong">pre-process data</strong> for the current KLT is contained in the <code class="markup--code markup--p-code">proc</code> structure. It contains the pointer to a list of KLTs associated with the process, a pointer to the address space, user credentials, and the list of signal handlers. The <code class="markup--code markup--p-code">proc</code> structure also contains the vestigial <code class="markup--code markup--p-code">user</code> structure.</p><figure name="2258" id="2258" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ONBbLU_I-J2XIQxVCQX3mw.png" data-width="1376" data-height="494" src="https://cdn-images-1.medium.com/max/800/1*ONBbLU_I-J2XIQxVCQX3mw.png"></figure><p name="8cf7" id="8cf7" class="graf graf--p graf-after--figure">The <strong class="markup--strong markup--p-strong">lightweight process (LWP)</strong> data structure contains information that’s relevant to one or more of the ULTs that are executing in the context of the process and keeps track of their UL registers and system call arguments. It contains the structure such as the PCB for,</p><ul class="postList"><li name="06ed" id="06ed" class="graf graf--li graf-after--p">UL register values</li><li name="5695" id="5695" class="graf graf--li graf-after--li">system call arguments</li><li name="e64c" id="e64c" class="graf graf--li graf-after--li">signal handling masks</li><li name="662b" id="662b" class="graf graf--li graf-after--li">resource usage information</li><li name="a757" id="a757" class="graf graf--li graf-after--li">profiling pointers</li></ul><p name="1b42" id="1b42" class="graf graf--p graf-after--li">It also contains pointers to the associated KLT and process structures. The information maintained in an LWP data structure is in some ways similar to what we maintain at the user level in the ULT data structure. Instead, this is what’s <strong class="markup--strong markup--p-strong">visible to the kernel</strong>, so when the OS level schedulers need to make scheduling decisions they can see this information and act upon it.</p><figure name="b4ef" id="b4ef" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*7gX_oHl5sIFPN8YSofCpIA.png" data-width="1376" data-height="502" src="https://cdn-images-1.medium.com/max/800/1*7gX_oHl5sIFPN8YSofCpIA.png"></figure><p name="5e45" id="5e45" class="graf graf--p graf-after--figure">The KLT data structure includes kernel level information like,</p><ul class="postList"><li name="38de" id="38de" class="graf graf--li graf-after--p">kernel registers</li><li name="fda4" id="fda4" class="graf graf--li graf-after--li">dispatch queue links</li><li name="f971" id="f971" class="graf graf--li graf-after--li">stack pointers</li><li name="5d5b" id="5d5b" class="graf graf--li graf-after--li">scheduling class</li><li name="3845" id="3845" class="graf graf--li graf-after--li">pointer to the next KLT</li></ul><p name="691f" id="691f" class="graf graf--p graf-after--li">Also has pointers to the various data structures that are associated with this kernel,</p><ul class="postList"><li name="f73a" id="f73a" class="graf graf--li graf-after--p">LWP</li><li name="1b83" id="1b83" class="graf graf--li graf-after--li">actual address space</li><li name="8842" id="8842" class="graf graf--li graf-after--li">CPU where it is running</li></ul><p name="9e9a" id="9e9a" class="graf graf--p graf-after--li">Because the KLT is in the memory, it is <strong class="markup--strong markup--p-strong">not swappable</strong> because we can lose the data forever. In contrast, the LWP data structure does not always have to be present in memory, so if we’re under memory pressure, it is okay to <strong class="markup--strong markup--p-strong">swap the LWP out</strong>.</p><figure name="525a" id="525a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*RP4WkkUlvwdV6K8XqipUrA.png" data-width="1412" data-height="480" src="https://cdn-images-1.medium.com/max/800/1*RP4WkkUlvwdV6K8XqipUrA.png"></figure><p name="7f24" id="7f24" class="graf graf--p graf-after--figure">The pre-processor information is maintained in a structure called <code class="markup--code markup--p-code">cpu</code> , which has the information about,</p><ul class="postList"><li name="3389" id="3389" class="graf graf--li graf-after--p">pointer to currently executing KLT</li><li name="65d2" id="65d2" class="graf graf--li graf-after--li">pointer to idle KLTs for the CPU (means the other KLTs in the list)</li><li name="cc58" id="cc58" class="graf graf--li graf-after--li">dispatch handling information</li><li name="1153" id="1153" class="graf graf--li graf-after--li">interrupt handling information</li></ul><figure name="ca69" id="ca69" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*isn0t5SswOC_0JNB8uJXPA.png" data-width="1412" data-height="282" src="https://cdn-images-1.medium.com/max/800/1*isn0t5SswOC_0JNB8uJXPA.png"></figure><p name="1ae6" id="1ae6" class="graf graf--p graf-after--figure">To speed access to the thread, LWP, process, and CPU structures, the SPARC architecture is used because it contains lots of extra registers.</p><p name="60d2" id="60d2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(4) Basic Thread Management Interaction</strong></p><ul class="postList"><li name="12dc" id="12dc" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Request More KLTs</strong></li></ul><p name="e087" id="e087" class="graf graf--p graf-after--li">Consider we have a multithreaded process. And let’s say that process has 4 ULTs. However, the process is such that, at any given point of time, the actual level of concurrency is just 2. So in the KL, it would be nice if the user-level process actually said, I just really need 2 KLTs.</p><p name="2b31" id="2b31" class="graf graf--p graf-after--p">When the process starts, the kernel will first give it a default number of kernel-level threads and the accompanying lightweight threads. And let’s say that is <strong class="markup--strong markup--p-strong">1 KLT</strong> by default.</p><figure name="09b5" id="09b5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*4jDppzp0UF3opqEmse4-XA.png" data-width="1412" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*4jDppzp0UF3opqEmse4-XA.png"></figure><p name="85a4" id="85a4" class="graf graf--p graf-after--figure">Then, the<strong class="markup--strong markup--p-strong"> </strong>UL<strong class="markup--strong markup--p-strong"> </strong>process must request additional kernel-level threads for the currency problem, and this can be done because the kernel supports a system call called <code class="markup--code markup--p-code">set_concurrency</code>. In response to this system call, the kernel will create additional threads and it will allocate those to this process.</p><figure name="7e3c" id="7e3c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*IAZ_vhoSYeAUGI1HoHUXzg.png" data-width="1412" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*IAZ_vhoSYeAUGI1HoHUXzg.png"></figure><ul class="postList"><li name="4475" id="4475" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Handling KLTs Block</strong></li></ul><p name="e145" id="e145" class="graf graf--p graf-after--li">Suppose the two ULTs are occupied by two of the I/O operations in the user level, they were basically moved onto the wait queue that’s associated with that particular I/O event. So the two corresponding KLTs are blocked as well.</p><p name="bb08" id="bb08" class="graf graf--p graf-after--p">Because we only have 2 KLTs in this case, now we have a situation where the process <strong class="markup--strong markup--p-strong">as a whole is blocked</strong>. However, other ULTs are ready to run and make progress. The reason why this is happening is that the <strong class="markup--strong markup--p-strong">kernel doesn’t know what is happening in the ULTlib</strong>, it doesn’t know that the ULTs are about to block and whether we have runnable ULTs.</p><p name="e42a" id="e42a" class="graf graf--p graf-after--p">In order to deal with this problem, the kernel can send a <strong class="markup--strong markup--p-strong">notification signal</strong> to the ULTlib before it blocks any KLTs. Then the ULTlib can check its running queue and finds out if it has runnable ULTs. If it has multiple runnable ULTs, it still needs to maintain a 2-thread-level concurrency. Thus, a system call to request will be made <strong class="markup--strong markup--p-strong">more KLTs</strong> with associated LWPs.</p><figure name="cae7" id="cae7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*okkR5dkjLowQ4IPd_D2bbQ.png" data-width="1544" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*okkR5dkjLowQ4IPd_D2bbQ.png"></figure><ul class="postList"><li name="6033" id="6033" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Release the Idle KLT</strong></li></ul><p name="e559" id="e559" class="graf graf--p graf-after--li">At a later time when the I/O operation completes, at some point, the kernel will notice that one of the kernel-level threads is pretty much constantly <strong class="markup--strong markup--p-strong">idle</strong> because we said that that’s the natural state of this particular application that needs only 2 KLTs.</p><p name="ac2d" id="ac2d" class="graf graf--p graf-after--p">Then, the kernel can tell the ULTlib that you no longer have access to this kernel-level thread, so you can’t schedule on it. The reason we need to tell the ULTlib is that <strong class="markup--strong markup--p-strong">the ULTlib doesn’t know what’s happening in the kernel</strong>.</p><figure name="3847" id="3847" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*fHaVaWgrJFO_UDkJ7Mx68w.png" data-width="1544" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*fHaVaWgrJFO_UDkJ7Mx68w.png"></figure><p name="dcf2" id="dcf2" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(5) Thread Management Interaction: A PThread Example</strong></p><p name="217c" id="217c" class="graf graf--p graf-after--p">From the PThread library, the function <code class="markup--code markup--p-code">pthread_setconcurrency</code> is provided for the thread management interaction. You can refer to the <a href="https://man7.org/linux/man-pages/man3/pthread_getconcurrency.3.html" data-href="https://man7.org/linux/man-pages/man3/pthread_getconcurrency.3.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">manual page</a> of the function for more information.</p><p name="89db" id="89db" class="graf graf--p graf-after--p">Note that when <code class="markup--code markup--p-code">0</code> is passed as the parameter for this function (i.e. <code class="markup--code markup--p-code">pthread_setconcurrency(0)</code>), it means that the underlying manager should decide how to manage the concurrency level for the particular process (as it deems appropriate).</p><p name="5246" id="5246" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(6) Thread Management Visibility</strong></p><p name="0c34" id="0c34" class="graf graf--p graf-after--p">At the KL, the kernel sees all the,</p><ul class="postList"><li name="8ecd" id="8ecd" class="graf graf--li graf-after--p">KLTs</li><li name="7125" id="7125" class="graf graf--li graf-after--li">CPU</li><li name="9c06" id="9c06" class="graf graf--li graf-after--li">KLS(which is the one making decisions)</li></ul><p name="14f0" id="14f0" class="graf graf--p graf-after--li">At the UL, the ULTlib sees,</p><ul class="postList"><li name="385f" id="385f" class="graf graf--li graf-after--p">ULTs that are part of that process</li><li name="bcaf" id="bcaf" class="graf graf--li graf-after--li">KLTs that are assigned to that process</li></ul><p name="ae11" id="ae11" class="graf graf--p graf-after--li">If we are using the one-to-one model, then every ULT will have a KLT associated with it. Even if it’s not a one-to-one model, the user level library can request that one of its ULTs can be<strong class="markup--strong markup--p-strong"> bound </strong>to a KLT.</p><p name="6623" id="6623" class="graf graf--p graf-after--p">At the KL, if a particular KLT is permanently associated with a CPU, we call this process <strong class="markup--strong markup--p-strong">pinning</strong> because the KLT is pinned to the associated CPU.</p><p name="7a3b" id="7a3b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) Visibility Issue: ULT Locking Problem</strong></p><p name="1f48" id="1f48" class="graf graf--p graf-after--p">Suppose we have 4 threads at the UL and all of these threads use the same lock. If the KLT now is supporting the execution of that critical section code of a thread, all the other threads will be blocked from the same critical section because of the mutex lock.</p><figure name="560d" id="560d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*_0OYK4gDthQDKyydLaJu7Q.png" data-width="1544" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*_0OYK4gDthQDKyydLaJu7Q.png"></figure><p name="5fcd" id="5fcd" class="graf graf--p graf-after--figure">If we have the situation in which the kernel <strong class="markup--strong markup--p-strong">preempted</strong> this executing KLT, and all the current KLT and the corresponding ULT will be delayed because the KLS schedules will then schedule the other KLT.</p><figure name="d408" id="d408" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*nTCaqV0M3hWqaxJ81TdV1w.png" data-width="1544" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*nTCaqV0M3hWqaxJ81TdV1w.png"></figure><p name="daf1" id="daf1" class="graf graf--p graf-after--figure">Now, the execution of this critical section <strong class="markup--strong markup--p-strong">cannot continue</strong> because all the other ULTs will be blocked from the critical section. After the kernel figures out this blocking issue, the previous KLT will be scheduled by the kernel again. Then the critical section will be completed, and the lock will be released. And subsequently, the rest of the ULTs will be able to execute.</p><figure name="0051" id="0051" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*eB0jRHztl85uJPP33NlWNQ.png" data-width="1544" data-height="570" src="https://cdn-images-1.medium.com/max/800/1*eB0jRHztl85uJPP33NlWNQ.png"></figure><p name="f4ee" id="f4ee" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(8) Visibility Issues Reasons for Many-to-many Model</strong></p><p name="812f" id="812f" class="graf graf--p graf-after--p">There are several reasons for the visibility issues,</p><ul class="postList"><li name="1f25" id="1f25" class="graf graf--li graf-after--p">the <strong class="markup--strong markup--li-strong">ULTlib makes scheduling decisions</strong> that the kernel is not aware of, and that will <strong class="markup--strong markup--li-strong">change the user-to-kernel mapping</strong></li><li name="86f9" id="86f9" class="graf graf--li graf-after--li">data structures like <strong class="markup--strong markup--li-strong">mutex</strong> and <strong class="markup--strong markup--li-strong">wait queues</strong> are also invisible to the kernel</li></ul><p name="f340" id="f340" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(9) When does the ULTlib Use?</strong></p><p name="59c4" id="59c4" class="graf graf--p graf-after--p">When a UL process (ULP) needs some features of the kernel, it has to jump to the ULTlib scheduler. A ULP jumps to the ULTlib scheduler when,</p><ul class="postList"><li name="655c" id="655c" class="graf graf--li graf-after--p">ULTs explicitly yield</li><li name="5f28" id="5f28" class="graf graf--li graf-after--li">timer set by ULTlib expires</li><li name="d747" id="d747" class="graf graf--li graf-after--li">ULTs call library functions (i.e. lock/unlock)</li><li name="618d" id="618d" class="graf graf--li graf-after--li">blocking ULTs becomes runnable</li></ul><p name="5bcf" id="5bcf" class="graf graf--p graf-after--li">In addition to being invoked on some operations that are triggered by ULTs, the ULTlib scheduler is also triggered in response to <strong class="markup--strong markup--p-strong">certain events/signals</strong> that come either from timers or directly from the kernel.</p><p name="05a8" id="05a8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(10) Multiple CPUs: Interactive Issues</strong></p><p name="dfcd" id="dfcd" class="graf graf--p graf-after--p">In the previous examples, we only had a single CPU. So all of ULTs run on that CPU, and whatever change in the ULTs will be scheduled were immediately be reflected on that particular CPU.</p><p name="56b9" id="56b9" class="graf graf--p graf-after--p">In a multi CPU system, the KLTs that support a single process may be running in multiple CPUs, even concurrently. So we may have a situation where the ULTlib that is operating on one thread of one CPU may impact what is running on another thread of another CPU.</p><p name="f198" id="f198" class="graf graf--p graf-after--p">Let’s see an example.</p><p name="8386" id="8386" class="graf graf--p graf-after--p">Suppose we have three threads, T3, T2, and T1. The thread priority is that T3&gt;T2&gt;T1. T2 is currently running in the context of one thread on one CPU and currently holds a mutex. T3 with the highest priority is waiting on the mutex and is blocked. T1 is running on the other CPU.</p><figure name="b01f" id="b01f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0Vvk43Lh9IoXPqJooo34zw.png" data-width="1426" data-height="568" src="https://cdn-images-1.medium.com/max/800/1*0Vvk43Lh9IoXPqJooo34zw.png"></figure><p name="7240" id="7240" class="graf graf--p graf-after--figure">At a later point, T2 releases the mutex (but is still running on the CPU), and as a result T3 becomes runnable. When all three threads are runnable, we have to make sure the ones with the highest priority are the ones that get executed. This means T1 needs to be preempted and we need to context switch T1 for T3.</p><figure name="8068" id="8068" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*0Hg9j8Q1OZZTOyyY9CUvYA.png" data-width="1426" data-height="568" src="https://cdn-images-1.medium.com/max/800/1*0Hg9j8Q1OZZTOyyY9CUvYA.png"></figure><p name="8e9c" id="8e9c" class="graf graf--p graf-after--figure">However, T1 is running on a CPU, so we need to notify the CPU to update its registers and program counter. We cannot directly modify the register of one CPU when executing on another CPU.</p><p name="b6ef" id="b6ef" class="graf graf--p graf-after--p">What we need to do instead is send some kind of <strong class="markup--strong markup--p-strong">signal/interrupt</strong> from the context of one KLT on one CPU to the KLT on the other CPU, and tell the other CPU to execute the library code locally.</p><figure name="e1c1" id="e1c1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*NuWG4WyBTkkWOTg_M1KS5Q.png" data-width="1426" data-height="568" src="https://cdn-images-1.medium.com/max/800/1*NuWG4WyBTkkWOTg_M1KS5Q.png"></figure><p name="02d4" id="02d4" class="graf graf--p graf-after--figure">Because the library needs to make a scheduling decision and change who it is executing. Once the signal happens, the ULTlib on the second CPU will determine that it needs to schedule the highest priority thread T3 by blocking the lower priority thread T1.</p><figure name="529f" id="529f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*6kpLoCZB3mrLiHd3JAmgcQ.png" data-width="1426" data-height="568" src="https://cdn-images-1.medium.com/max/800/1*6kpLoCZB3mrLiHd3JAmgcQ.png"></figure><p name="eac9" id="eac9" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(11) Multiple CPUs: Synchronization-Related Issues</strong></p><p name="3e28" id="3e28" class="graf graf--p graf-after--p">Let’s see another issue of the multiple CPUs. Consider a situation where ULT1 is currently running on the KLT1 spinned to the CPU1 owns a mutex. This mutex blocks the ULT2 and ULT3 because they have requested the mutex that ULT1 holds.</p><figure name="3e0f" id="3e0f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FI_BaOuQukF3k4UU5m_mHQ.png" data-width="1426" data-height="660" src="https://cdn-images-1.medium.com/max/800/1*FI_BaOuQukF3k4UU5m_mHQ.png"></figure><p name="c967" id="c967" class="graf graf--p graf-after--figure">Suppose ULT4 running on the KLT2 spun to the CPU2 requests the mutex that ULT1 is holding, then ULT4 should be enqueued into the mutex queue.</p><figure name="1290" id="1290" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*HTkhkstPwhYtL0f3JKx3ag.png" data-width="1426" data-height="660" src="https://cdn-images-1.medium.com/max/800/1*HTkhkstPwhYtL0f3JKx3ag.png"></figure><p name="7bcc" id="7bcc" class="graf graf--p graf-after--figure">However, if the amount of time that T1 will take to finish is less than the amount of time T4 will take to be placed on the queue and context switch, then it makes more sense to just have T4 “<strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">spin, burn some cycles</em></strong>” and wait for the mutex.</p><figure name="e6c8" id="e6c8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9pqhBh-1BKUUq4HBfKKP7A.png" data-width="1294" data-height="662" src="https://cdn-images-1.medium.com/max/800/1*9pqhBh-1BKUUq4HBfKKP7A.png"></figure><p name="994b" id="994b" class="graf graf--p graf-after--figure">Mutex data structures should contain information about the current owner. With that information, a thread can determine if the owner of a mutex is running on a separate CPU. If another CPU is available and there is a short critical section for ULT1, then ULT4 should <strong class="markup--strong markup--p-strong">spin instead of blocking</strong>.</p><p name="aa93" id="aa93" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(12) Destroying threads</strong></p><p name="7d82" id="7d82" class="graf graf--p graf-after--p">Finally, let’s discuss destroying threads.</p><p name="dc10" id="dc10" class="graf graf--p graf-after--p">Once a thread is no longer needed, it can actually be destroyed, and the data structure, stack, etc. should be freed. However, since the thread creation takes some time that is quite expensive for us, it helps if we consider <strong class="markup--strong markup--p-strong">reusing</strong> threads instead of destroying them.</p><p name="7186" id="7186" class="graf graf--p graf-after--p">This is done by when a thread exits, it is not immediately freed. Instead, this thread will be put on <strong class="markup--strong markup--p-strong">death row</strong>. Periodically, a <strong class="markup--strong markup--p-strong">reaper thread</strong> will be executed to destroy some of the threads on death row. Otherwise, if a thread creation request comes in before the threads in the death row are properly destroyed, then its data structure and stack can be reused.</p><figure name="a8f5" id="a8f5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pZWuP0VTXmnirPygwA6WRQ.png" data-width="1294" data-height="360" src="https://cdn-images-1.medium.com/max/800/1*pZWuP0VTXmnirPygwA6WRQ.png"></figure><p name="5e63" id="5e63" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(13) Example: Threads Number For Linux</strong></p><p name="3eac" id="3eac" class="graf graf--p graf-after--p graf--trailing">From the source code <code class="markup--code markup--p-code"><a href="https://elixir.bootlin.com/linux/v3.17/source/kernel/fork.c" data-href="https://elixir.bootlin.com/linux/v3.17/source/kernel/fork.c" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">fork.c</a></code> of the Linux kernel v3.17, we can find out that a minimum of 20 threads are needed to allow a system to boot (line 281–282), and this value can be changed by passing the parameter <code class="markup--code markup--p-code">max_threads</code>.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/879b1154df19"><time class="dt-published" datetime="2021-02-27T14:18:20.324Z">February 27, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/operating-system-12-interactions-between-kernel-level-threads-and-user-level-threads-with-sunos-879b1154df19" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>