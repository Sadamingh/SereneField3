<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Operating System 25 | Introduction to Distributed File System, Introduction to Network File System…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Operating System 25 | Introduction to Distributed File System, Introduction to Network File System…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Series: Operating System
</section>
<section data-field="body" class="e-content">
<section name="921a" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="111e" id="111e" class="graf graf--h3 graf--leading graf--title">Operating System 25 | <strong class="markup--strong markup--h3-strong">Introduction to Distributed File System, Introduction to Network File System, and Introduction to Sprite DFS</strong></h3><figure name="db47" id="db47" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*tS2b-TvTK0kIgPS9.png" data-width="1508" data-height="794" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*tS2b-TvTK0kIgPS9.png"></figure><ol class="postList"><li name="9de4" id="9de4" class="graf graf--li graf-after--figure"><strong class="markup--strong markup--li-strong">Introduction to Distributed File System (DFS)</strong></li></ol><p name="4c95" id="4c95" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(1) Review: File Systems</strong></p><p name="3d8d" id="3d8d" class="graf graf--p graf-after--p">In our previous discussion about file systems, we have said that the modern OS (e.g. Linux) hides the fact that there may be multiple types of internal file system organizations. And this is done by exporting a higher-level <strong class="markup--strong markup--p-strong">virtual file system (VFS) interface</strong>.</p><figure name="4a85" id="4a85" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*4jeg91fcN_Si0BWB.png" data-width="1452" data-height="518" src="https://cdn-images-1.medium.com/max/800/0*4jeg91fcN_Si0BWB.png"></figure><p name="0c89" id="0c89" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(2) Remote File Systems</strong></p><p name="4add" id="4add" class="graf graf--p graf-after--p">Underneath this VFS interface, the OS can also hide the fact there isn’t even local physical storage on a particular machine where the files are stored, but that instead everything is maintained on a remote machine or on a <strong class="markup--strong markup--p-strong">remote file system</strong> that is being accessed over the <strong class="markup--strong markup--p-strong">network</strong>.</p><figure name="7dd6" id="7dd6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9v-hpTaMI4gXJDTMeYTRXw.png" data-width="1522" data-height="576" src="https://cdn-images-1.medium.com/max/800/1*9v-hpTaMI4gXJDTMeYTRXw.png"></figure><p name="8f56" id="8f56" class="graf graf--p graf-after--figure">These kinds of environments where there are multiple machines that are involved in the delivery of the file system service together form a <strong class="markup--strong markup--p-strong">distributed file system</strong> (aka. <strong class="markup--strong markup--p-strong">DFS</strong>).</p><p name="a459" id="a459" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Two Types of DFS Models</strong></p><p name="7816" id="7816" class="graf graf--p graf-after--p">More generally, a distributed file system is a file system that can be organized in two ways.</p><p name="aba5" id="aba5" class="graf graf--p graf-after--p">The first model is when the clients and the file server are on <strong class="markup--strong markup--p-strong">different machines</strong>. Nowadays, the file server is not just single machine but instead, it’s distributed on <strong class="markup--strong markup--p-strong">multiple machines</strong>. This may mean that all the files are replicated, and available, on every single machine, and even if there are some failures on one of the servers, because there are always a replicate file on some other machines. Also, the file requests from the clients can be split among the servers and this helps with the availability.</p><figure name="6540" id="6540" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jSGwzEgAHw1_3CuUHh9QxQ.png" data-width="1522" data-height="664" src="https://cdn-images-1.medium.com/max/800/1*jSGwzEgAHw1_3CuUHh9QxQ.png"></figure><p name="8811" id="8811" class="graf graf--p graf-after--figure">However, in the replicated model, we still need every single server to store all files so if we need to scale the file system to be able to store more files, we’ll have to buy machines with larger disks. Unfortunately, at a certain point, we are likely to reach a limite.</p><figure name="50f5" id="50f5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*p9ptGDt5jSLpWbPE7KFSXw.png" data-width="1522" data-height="1076" src="https://cdn-images-1.medium.com/max/800/1*p9ptGDt5jSLpWbPE7KFSXw.png"></figure><p name="ae39" id="ae39" class="graf graf--p graf-after--figure">The second model is that the file server can be <strong class="markup--strong markup--p-strong">distributed among multiple machines</strong> is by splitting the files, dividing them, or partitioning them. So that different physical machines store different files, and these machines are called <strong class="markup--strong markup--p-strong">peers</strong>. This makes the system more scalable than the replicated model because if you need to store more files, you simply add additional machines.</p><figure name="6a05" id="6a05" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*EavotYypg8d4eWA-2dNk3g.png" data-width="1522" data-height="1070" src="https://cdn-images-1.medium.com/max/800/1*EavotYypg8d4eWA-2dNk3g.png"></figure><p name="e517" id="e517" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(4) Upload-Download Model (UDM)</strong></p><p name="c550" id="c550" class="graf graf--p graf-after--p">Let’s first look at the different extreme services that a remote file service can be provided and we will assume that there is one client and one server.</p><p name="16f6" id="16f6" class="graf graf--p graf-after--p">One extreme model that we have is called the <strong class="markup--strong markup--p-strong">upload-download model</strong>, which means that when the client wants to access the file, it downloads the entire file, performs locally the operations, and then, when done, it uploads the file back to the server.</p><figure name="9d4d" id="9d4d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*OSowhTyG847BhMghnk_xlg.png" data-width="1240" data-height="340" src="https://cdn-images-1.medium.com/max/800/1*OSowhTyG847BhMghnk_xlg.png"></figure><p name="4e35" id="4e35" class="graf graf--p graf-after--figure">The benefit of this model is that once the client has the film, it can perform all the file operations in a very quick way. However, the downsides are as follows,</p><ul class="postList"><li name="b8e9" id="b8e9" class="graf graf--li graf-after--p">client needs to <strong class="markup--strong markup--li-strong">download the entire file</strong></li><li name="982f" id="982f" class="graf graf--li graf-after--li">it <strong class="markup--strong markup--li-strong">takes away file access control</strong> from the server, and the server has no idea what the client will do to the file</li></ul><p name="6d5c" id="6d5c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(5) True Remote File Access Model (TRFAM)</strong></p><p name="3f65" id="3f65" class="graf graf--p graf-after--p">The other extreme is called the <strong class="markup--strong markup--p-strong">true remote file access model</strong>. In this model, the file remains on the server, and every single operation, every read and every write, has to go to the server.</p><figure name="7958" id="7958" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*vX-EfnaqYAax69i7HKJsOQ.png" data-width="1136" data-height="262" src="https://cdn-images-1.medium.com/max/800/1*vX-EfnaqYAax69i7HKJsOQ.png"></figure><p name="7fd6" id="7fd6" class="graf graf--p graf-after--figure">The benefit of this extreme is that the server has full control and knowledge of how the clients are accessing and modifying the shared state and the shared files. This makes it easier to ensure that the state of the <strong class="markup--strong markup--p-strong">file system is consistent</strong> and that there are <strong class="markup--strong markup--p-strong">no </strong>situations where<strong class="markup--strong markup--p-strong"> multiple clients</strong> are overwriting the same portions of the single file at the same time. However, the downsides of this model are as follows,</p><ul class="postList"><li name="8965" id="8965" class="graf graf--li graf-after--p">every single file operation has to incur the <strong class="markup--strong markup--li-strong">cost of remote network latency</strong></li><li name="4bb5" id="4bb5" class="graf graf--li graf-after--li">the server will get <strong class="markup--strong markup--li-strong">overloaded</strong> more quickly and it is not able to support many clients</li></ul><p name="400d" id="400d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(6) Remote File Service Model</strong></p><p name="7cab" id="7cab" class="graf graf--p graf-after--p">The two models UDM and TRFAM are two extremes, but in reality, what makes sense is to have something in between as a compromise. This critical model is called a <strong class="markup--strong markup--p-strong">remote file access model</strong> (or remote file service model) which has the following features,</p><ul class="postList"><li name="a3e1" id="a3e1" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Allow clients to benefit from using their local memories</strong>: this will lead to <strong class="markup--strong markup--li-strong">lower latency</strong> for these local files and some of the <strong class="markup--strong markup--li-strong">workloads</strong> on the server can be simply removed and the server becomes more scalable.</li><li name="75c8" id="75c8" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Force clients to interact with the server</strong>: the clients need to <strong class="markup--strong markup--li-strong">notify</strong> the server of any modifications to the file that they have made and the server needs to <strong class="markup--strong markup--li-strong">broadcast</strong> all the clients if any of the files that they have locally cached has been modified by someone else. Therefore, the server now has some insights into that clients are doing and the server can have control into which accesses can be permitted. So it is easier to maintain file <strong class="markup--strong markup--li-strong">consistency</strong>.</li></ul><p name="40f3" id="40f3" class="graf graf--p graf-after--li">However, there is also a problem with this model because it makes the file server <strong class="markup--strong markup--p-strong">more complex</strong>. It means that the server would have to perform additional tasks and maintain additional states so as to make sure that it can provide consistency guarantees. What’s more, the clients would have to understand somewhat different file sharing semantics compared to what they are used to in a typical local file system.</p><p name="fbbc" id="fbbc" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(7) Stateless Server</strong></p><p name="a596" id="a596" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">stateless server</strong> is one that <strong class="markup--strong markup--p-strong">doesn’t maintain any information</strong> regarding which clients access which files how many different clients are serviced. Every request has to be self-described and it needs to have all of the parameters regarding the files being accessed the absolute offset within that file along with any data that needs to be written. This model is suitable for the UDM and other extreme models but it cannot be used for the more practical models.</p><p name="3eea" id="3eea" class="graf graf--p graf-after--p">The downsides of this model are,</p><ul class="postList"><li name="88f1" id="88f1" class="graf graf--li graf-after--p">we can <strong class="markup--strong markup--li-strong">not achieve consistency</strong> in the DFS</li><li name="6da3" id="6da3" class="graf graf--li graf-after--li">the request has to contain <strong class="markup--strong markup--li-strong">more bits of data</strong> because it is self-described</li></ul><p name="240a" id="240a" class="graf graf--p graf-after--li">The benefits of this model are,</p><ul class="postList"><li name="9f67" id="9f67" class="graf graf--li graf-after--p">no state that’s maintained on the file server, so there will be <strong class="markup--strong markup--li-strong">no consumed resources</strong> needed by the server to maintain the file state data</li><li name="c0d4" id="c0d4" class="graf graf--li graf-after--li">the server just need to simply <strong class="markup--strong markup--li-strong">restart</strong> to recovery from a failure</li></ul><p name="4078" id="4078" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(7) Stated Server</strong></p><p name="baaa" id="baaa" class="graf graf--p graf-after--p">A stateful server is one that maintains information about the clients in its system, for example, the file names we are accessing, which is the access type (i.e. read or write), etc.</p><p name="2cc8" id="2cc8" class="graf graf--p graf-after--p">Because of this stated server,</p><ul class="postList"><li name="276b" id="276b" class="graf graf--li graf-after--p">it becomes possible for the file server to allow data to be <strong class="markup--strong markup--li-strong">cached</strong> on the clients and at the same time to guarantee <strong class="markup--strong markup--li-strong">consistency</strong></li><li name="481d" id="481d" class="graf graf--li graf-after--li">it can support more features like <strong class="markup--strong markup--li-strong">locking</strong> and <strong class="markup--strong markup--li-strong">incremental operations</strong></li></ul><p name="6d3f" id="6d3f" class="graf graf--p graf-after--li">However, there can be some problems,</p><ul class="postList"><li name="089c" id="089c" class="graf graf--li graf-after--p">on failure, all the states on the server should be able to be <strong class="markup--strong markup--li-strong">recovered</strong> for consistency. Therefore, we will need more mechanisms like <strong class="markup--strong markup--li-strong">checkpoints</strong></li><li name="8f7b" id="8f7b" class="graf graf--li graf-after--li">the <strong class="markup--strong markup--li-strong">runtime</strong> of the server will be worse because we have to do overheads on maintaining the state and consistency protocols</li></ul><p name="5cd0" id="5cd0" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(8) File Caching</strong></p><p name="6e95" id="6e95" class="graf graf--p graf-after--p">The first distributed file system mechanism we will look at is <strong class="markup--strong markup--p-strong">caching</strong>. Caching is a general optimization technique in distributed systems where the clients are permitted to locally maintain a portion of the state (e.g. file blocks). And also, the clients are permitted to perform some operations (e.g. open, read, write, etc.) on that cached state locally.</p><p name="ec18" id="ec18" class="graf graf--p graf-after--p">With a single file server and many clients, the file and file blocks can be stored in a DFS at,</p><ul class="postList"><li name="a1e8" id="a1e8" class="graf graf--li graf-after--p">the client’s memory</li><li name="34a3" id="34a3" class="graf graf--li graf-after--li">on the client’s storage device (HDD or SSD)</li><li name="f90f" id="f90f" class="graf graf--li graf-after--li">in buffer cache in the memory of the server</li></ul><p name="2c92" id="2c92" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(9) Caching Coherence Mechanisms</strong></p><p name="9416" id="9416" class="graf graf--p graf-after--p">Keeping the cached portions of the file consistent with the on-server representation of that file requires to have some coherence mechanisms, and these mechanisms are like <strong class="markup--strong markup--p-strong">write-update</strong> and<strong class="markup--strong markup--p-strong"> write-invalidate</strong> for the cache coherence on SMPs (shared memory processors). Recall these mechanisms for an SMP system get triggered whenever a particular variable or a particular memory location gets <strong class="markup--strong markup--p-strong">written to</strong>. For a DFS system, it would make more sense if we trigger these mechanisms <strong class="markup--strong markup--p-strong">on demand</strong> when the client needs to access a file or periodically whenever the client is <strong class="markup--strong markup--p-strong">open</strong>.</p><p name="cf80" id="cf80" class="graf graf--p graf-after--p">And also, when we need to update or invalidate the file state, we have to make sure whether this file is<strong class="markup--strong markup--p-strong"> client-driven</strong> (means that the client needs to find the file and update its context) or <strong class="markup--strong markup--p-strong">server-driven</strong> (means the server needs to notify the client with a cached file that something has changed about their cached state).</p><p name="4fa5" id="4fa5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(10) File Inconsistency Problem for DFS</strong></p><p name="058c" id="058c" class="graf graf--p graf-after--p">To explain the<strong class="markup--strong markup--p-strong"> </strong>file-sharing semantics in DFS, let’s see a <strong class="markup--strong markup--p-strong">file inconsistency</strong> problem in the DFS system.</p><p name="6487" id="6487" class="graf graf--p graf-after--p">In the following figure (a), we have a single node in a Unix environment. When process A write <code class="markup--code markup--p-code">c</code> to a buffer that keeps the file with data <code class="markup--code markup--p-code">ab</code> , the file will immediately become <code class="markup--code markup--p-code">abc</code> and another process that would like to read from this file can only achieve a result of <code class="markup--code markup--p-code">abc</code> . This means that every write of a process will become visible for other processes immediately in Unix.</p><p name="c3c6" id="c3c6" class="graf graf--p graf-after--p">However, for the DFS system, this is not the case. In the following figure (b), we have two clients. The first client writes to the file but the file is not written to the server, so even after the other client #2 read from the file after process A wrote to this file, we will not get a file content of <code class="markup--code markup--p-code">abc</code> and this will create a file inconsistency problem for us.</p><figure name="0b0d" id="0b0d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tXiZZ1RhCj0uUS-bCIcNpg.png" data-width="1138" data-height="522" src="https://cdn-images-1.medium.com/max/800/1*tXiZZ1RhCj0uUS-bCIcNpg.png"></figure><p name="0dac" id="0dac" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">(11) Session Semantics Policy</strong></p><p name="02c8" id="02c8" class="graf graf--p graf-after--p">To deal with the inconsistency problems among clients, we have to introduce some<strong class="markup--strong markup--p-strong"> file-sharing policies</strong>. The first one is called <strong class="markup--strong markup--p-strong">session semantics</strong>.</p><p name="88c6" id="88c6" class="graf graf--p graf-after--p">Whenever a file is closed by <code class="markup--code markup--p-code">close()</code>, the client <strong class="markup--strong markup--p-strong">writes back</strong> to the server all of the changes that it has applied to that file in its cache. Whenever a client needs to open a file by <code class="markup--code markup--p-code">open()</code> , it doesn’t use the cache contents. Instead, it goes and checks with the file server for whether or not there is a more recent version of that file. If there is a more recent version on the server, we will then <strong class="markup--strong markup--p-strong">update</strong> the local file. We call the session semantics with the period between the file open and the file close being referred to as one session. Although the session semantics can be easy to use, it can be inefficiency sometimes.</p><p name="0431" id="0431" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(12) Periodic Updates Policy</strong></p><p name="4520" id="4520" class="graf graf--p graf-after--p">Because the session semantics is inefficient, it makes more sense to introduce some time intervals when these updates happen. This semantics is called <strong class="markup--strong markup--p-strong">periodic updates</strong>. With time intervals, the client updates writes will be <strong class="markup--strong markup--p-strong">periodically written back </strong>to the server by some sort of lease on how long they have to wait in order to use the cached data.</p><p name="9700" id="9700" class="graf graf--p graf-after--p">In the same way, the server notifications the invalidations are also <strong class="markup--strong markup--p-strong">periodically sent out</strong> to the clients. This can establish some time bounds during which the system can potentially be inconsistent, and it will be easier if there are some conflicts.</p><p name="a73a" id="a73a" class="graf graf--p graf-after--p">Since the client doesn’t really have any idea about what are the start and the end times of these synchronization periods, the file system can also provide some explicit operations like the <code class="markup--code markup--p-code">flush()</code> API (flushing the updates to the disk or the local storage) and the <code class="markup--code markup--p-code">sync()</code> API (synchronizing the state to the remote server).</p><p name="933e" id="933e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(13) Immutable Files Policy</strong></p><p name="5db0" id="5db0" class="graf graf--p graf-after--p">There are some other file-sharing policies. For instance, files may be simply <strong class="markup--strong markup--p-strong">immutable</strong> you never really modify a file you simply delete it or you create a new file with a new name. This is useful when we are sharing photos via Instagram or Facebook when we <strong class="markup--strong markup--p-strong">don’t edit</strong> them after the modified photos are uploaded. These types of distributed storage have this kind of semantics called immutable files.</p><p name="6f98" id="6f98" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(14) Transaction Policy</strong></p><p name="3757" id="3757" class="graf graf--p graf-after--p">The file system needs to import some APIs so that the clients can specify some questions like,</p><ul class="postList"><li name="97bf" id="97bf" class="graf graf--li graf-after--p">what is the collection of <strong class="markup--strong markup--li-strong">files </strong>that need to be treated like a certain single transaction</li><li name="4271" id="4271" class="graf graf--li graf-after--li">what is the collection of <strong class="markup--strong markup--li-strong">operations</strong> that need to be treated like a certain single transaction</li></ul><p name="6006" id="6006" class="graf graf--p graf-after--li">And then the file system can make some guarantees that all those changes are <strong class="markup--strong markup--p-strong">atomically committed</strong> visible into the file system.</p><p name="3175" id="3175" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(15) Designing DFS Requirements</strong></p><p name="6d31" id="6d31" class="graf graf--p graf-after--p">When we want to design an efficient DFS system, we can have many options. In order to choose among these different options, we should know the basic requirements of our design. Commonly, we have to answer the following questions,</p><ul class="postList"><li name="b97a" id="b97a" class="graf graf--li graf-after--p">What is the sharing frequency?</li><li name="92a0" id="92a0" class="graf graf--li graf-after--li">What is the writing frequency?</li><li name="7138" id="7138" class="graf graf--li graf-after--li">Is it important for maintaining the consistency view?</li></ul><p name="5594" id="5594" class="graf graf--p graf-after--li">Once we understand these workload properties, the design of the file system must be done by <strong class="markup--strong markup--p-strong">optimizing for the common case</strong>.</p><p name="b9c0" id="b9c0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(16) Regular Files Vs. Directories</strong></p><p name="a950" id="a950" class="graf graf--p graf-after--p">In the system, there can be two types of files. The first one is <strong class="markup--strong markup--p-strong">regular files</strong> and the other one is <strong class="markup--strong markup--p-strong">directories</strong>. These two files have very different access patterns in terms of,</p><ul class="postList"><li name="c54f" id="c54f" class="graf graf--li graf-after--p">what is the locality</li><li name="d86c" id="d86c" class="graf graf--li graf-after--li">what is the lifetime of the files</li><li name="3f9a" id="3f9a" class="graf graf--li graf-after--li">the size distribution</li><li name="bcfc" id="bcfc" class="graf graf--li graf-after--li">how frequently are they accessed</li><li name="64c6" id="64c6" class="graf graf--li graf-after--li">etc.</li></ul><p name="7819" id="7819" class="graf graf--p graf-after--li">So for these reasons, it is quite common to treat these two types of files differently. For instance, we can adopt one type of semantics for the regular files and another type of semantics for the directories. For example, if we use periodic updates as a mechanism for both then we may choose to use less frequent write-backs for the regular files versus for the directories. This is because directories are more frequently shared than individual files in them.</p><p name="6cfb" id="6cfb" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(17) Replication Server File System</strong></p><p name="f659" id="f659" class="graf graf--p graf-after--p">We have said that the clients and the server can be distributed to different machines, but the file server itself can also be distributed. This can be achieved via <strong class="markup--strong markup--p-strong">replication</strong> or <strong class="markup--strong markup--p-strong">partitioning</strong>.</p><p name="65ef" id="65ef" class="graf graf--p graf-after--p">With <strong class="markup--strong markup--p-strong">replication</strong>, the file system can be replicated onto multiple machines such that every single machine holds an exact replica of <strong class="markup--strong markup--p-strong">all of the files</strong> in the system. The benefit of this is that it can have its workload balanced among all the replicated servers (<strong class="markup--strong markup--p-strong">availability</strong>) and we can have <strong class="markup--strong markup--p-strong">fault tolerance</strong>.</p><p name="4b4f" id="4b4f" class="graf graf--p graf-after--p">The downsides are as follows,</p><ul class="postList"><li name="8a97" id="8a97" class="graf graf--li graf-after--p">the writes become more <strong class="markup--strong markup--li-strong">complex</strong> because we have to care about consistency among all the replicated server machines</li><li name="ffec" id="ffec" class="graf graf--li graf-after--li">replicated servers must be <strong class="markup--strong markup--li-strong">reconciled</strong> by mechanisms like voting and etc.</li></ul><p name="a802" id="a802" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">(18) Partitioning Server File System</strong></p><p name="f9df" id="f9df" class="graf graf--p graf-after--p">The other technique to DFS states is by using <strong class="markup--strong markup--p-strong">partitioning</strong>. Every single machine has only a portion of the state and only a subset of all the files in the system. This splitting of the files may be done based on file names. For example, files with names starting with A~M may be located in one server and the others may stay in another server. Or we may choose a policy where different directories are stored on different machines where we would somehow partition the hierarchical namespace of the directory tree structure.</p><p name="9f93" id="9f93" class="graf graf--p graf-after--p">The benefit of this model is that we can easily achieve <strong class="markup--strong markup--p-strong">availability</strong> compared to a single server design and each server will now hold fewer files, and therefore, the file requests for each server will be generally reduced. What’s more, it provides for greater <strong class="markup--strong markup--p-strong">scalability</strong> when we consider the size of the file system the overall size of all the files stored in that file system.</p><p name="36dc" id="36dc" class="graf graf--p graf-after--p">However, there are some downsides,</p><ul class="postList"><li name="2b04" id="2b04" class="graf graf--li graf-after--p">on failure, we can easily <strong class="markup--strong markup--li-strong">lose some portion of the data</strong> because the data is not duplicated among the server machines</li><li name="364d" id="364d" class="graf graf--li graf-after--li">there can be some <strong class="markup--strong markup--li-strong">hot spots</strong>, which means that some files on a machine are more frequently accessed and the other files on another machine are less frequently accessed. So it is much harder to balance the workload among the servers compared with the replication model</li></ul><p name="f146" id="f146" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">2. Introduction to Network File System (NFS)</strong></p><p name="b8a6" id="b8a6" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) NFS History</strong></p><p name="7557" id="7557" class="graf graf--p graf-after--p">NFS has been around since the 80s and has gone through several revisions. The popular NFS versions that are in use today and that come standard with Linux distributions are NFSv3 (stateless) and NFSv4 (stateful), so the NFSv4 supports features like client caching and file logging initially, while NFSv3 has to import some other packages.</p><p name="ef78" id="ef78" class="graf graf--p graf-after--p">With caching, NFS initially behaves with session semantics. And then on opening a check is performed and if necessary the cached parts of the file are actually updated so the new versions of those files are brought in. However, as an additional optimization, NFS also supports periodic updates. In fact, NFS is supporting neither session semantics nor periodic updates semantics. NFSv4 further incorporates a delegation mechanism where the server delegates to the client all rights to manage a file for a period of time and this will avoid any of the update checks that we described here.</p><p name="840c" id="840c" class="graf graf--p graf-after--p">The NFS also supports lease-based locking. NFSv4 also supports more sophisticated mechanisms than just a basic lock like a reader-writer lock called share reservation along with other mechanisms.</p><p name="60fe" id="60fe" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) NFS Design</strong></p><p name="2ce4" id="2ce4" class="graf graf--p graf-after--p">The NFS client interacts via RPC with the NFS server that resides on a remote machine. This is the machine that actually stores the files. The NFS server accepts the request, forms them into a proper file system operation that’s then issued to the local virtual file system and from there it gets passed to the local file system on top of the local storage. On the client’s write operations the data that needs to be written to the file will be carried as part of the RPC request from the client to the server machine.</p><figure name="01f7" id="01f7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qEe5PX-fHoAGhaKBBazjnQ.png" data-width="1706" data-height="618" src="https://cdn-images-1.medium.com/max/800/1*qEe5PX-fHoAGhaKBBazjnQ.png"></figure><p name="8026" id="8026" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">3. Introduction to Sprite DFS</strong></p><p name="9496" id="9496" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(1) Sprite DFS Paper</strong></p><p name="a3eb" id="a3eb" class="graf graf--p graf-after--p">Let’s now look at another distributed file system example, the Sprite Distributed File System, which is described in the research paper <a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-nelson-paper.pdf" data-href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-nelson-paper.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Caching in the Sprite Network File System</em></a> by Nelson. Sprite is mainly for research and it is simply not built for products, even though some people were using it at UC Berkeley at that time.</p><p name="f6b9" id="f6b9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(2) Sprite DFS Workloads</strong></p><p name="e3fe" id="e3fe" class="graf graf--p graf-after--p">In Nelson’s paper, the author described how are the files accessed in the DFS used by their department. This is what they found,</p><ul class="postList"><li name="b241" id="b241" class="graf graf--li graf-after--p">33% of all file accesses are writes: caching can be important for improvements (because 2/3 accesses can be improved) so write through will simply not be a good idea</li><li name="9132" id="9132" class="graf graf--li graf-after--li">75% of the files are open less than 0.5 sec, and 90% of files are open less than 10 sec: this means that with session semantics, the overheads can be too high</li><li name="0932" id="0932" class="graf graf--li graf-after--li">20%-30% of new data deleted within 30 sec and 50% of the new data deleted within 5 minutes: this means that a lot of the data is deleted in a very short period of time after it is created.</li><li name="dc50" id="dc50" class="graf graf--li graf-after--li">file-sharing is rare: this means that multiple clients working on the same file can rarely happen</li></ul><p name="eedf" id="eedf" class="graf graf--p graf-after--li">So because of these observations they made the following decision, the write-back on close (or session semantics) will not be a necessary operation because we rarely have file-sharing situations and most of the data will get deleted in a short period of time anyway. However, all of these features will not be friendly to the DFS with many clients accessing the same file, but there is indeed some file-sharing process that the DFS must support. So we have to make sure that the Sprite DFS can also support file sharing.</p><p name="8298" id="8298" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">(3) Sprite DFS Design</strong></p><p name="e60d" id="e60d" class="graf graf--p graf-after--p">Based on this workload, the authors made the following design decisions in Sprite.</p><ul class="postList"><li name="8137" id="8137" class="graf graf--li graf-after--p">support caching with the write-back policy every 30 seconds if the block is not modified in the last 30 seconds. So it is possible that some other clients open the file on the server and get dirty blocks. This is for optimizing the 33% write accesses.</li><li name="2db1" id="2db1" class="graf graf--li graf-after--li">every open has to go to the server and the directories can not be cached on the client.</li><li name="4fb0" id="4fb0" class="graf graf--li graf-after--li graf--trailing">when there are concurrent writes to the same file, then the Sprite will completely disable the caching for that file</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@adamedelweiss" class="p-author h-card">Adam Edelweiss</a> on <a href="https://medium.com/p/4ac510f99426"><time class="dt-published" datetime="2021-04-26T20:35:05.251Z">April 26, 2021</time></a>.</p><p><a href="https://medium.com/@adamedelweiss/operating-system-25-introduction-to-distributed-file-system-introduction-to-network-file-system-4ac510f99426" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 15, 2021.</p></footer></article></body></html>